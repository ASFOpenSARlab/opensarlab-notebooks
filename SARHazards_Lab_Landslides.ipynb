{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InSAR Time Series Analysis using MintPy and ARIA products\n",
    "\n",
    "**Author:** Eric Fielding, David Bekaert, Heresh Fattahi and Zhang Yunjun \n",
    "\n",
    " This notebook is a second modification by Eric Fielding from an earlier version of the notebook (https://nbviewer.jupyter.org/github/aria-tools/ARIA-tools-docs/blob/master/JupyterDocs/NISAR/L2_interseismic/mintpySF/smallbaselineApp_aria.ipynb) by David Bekaert, Heresh Fattahi and Zhang Yunjun that was originally focused on San Francisco. \n",
    "\n",
    "\n",
    "\n",
    "**Mapping landslide motion with InSAR time series**\n",
    "\n",
    "The Caltech-JPL ARIA project in partnership with NASA Getting Ready for NISAR (GRFN) project has been generated surface displacement products (interferograms) mimicking the GUNW (Geocoded Unwrapped phase interferograms) products that will be provided by the <a href=\"https://nisar.jpl.nasa.gov/\">upcoming NASA-ISRO SAR (NISAR) mission</a>. The interferograms are stored at the <a href=\"https://asf.alaska.edu/\">NASA Alaska Satellite Facility (ASF) DAAC</a>, and are accessible with an Open Source set of tools called ARIA-tools. The Miami Insar Timeseries software in PYthon (MintPy), an open-source package for InSAR time-series analysis, is compatible with the outputs from the ARIA-tools package, and in combination with the ARIA-tools pre-processor can be used to estimate ground displacement time-series. \n",
    "\n",
    "The Jupyter notebook presented here is meant as an practical example on the use of Jupyter for exploring landslide displacements. In the example below, we will demonstrate a time-series derived from ARIA standard InSAR products over the Los Angeles, California area revealing landslide motion on the Palos Verdes peninsula. \n",
    "\n",
    "See the other tutorials on ARIA-tools to learn more about how to use that package.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>To save time, we have pre-run the ARIA-tools package and data loading into MintPy</b> \n",
    "\n",
    "!ariaDownload.py -b '33.5 34.5 -119.0 -117.9' --track 71\n",
    "    \n",
    "!ariaTSsetup.py -f 'products/*.nc' -b '33.65 33.9 -118.45 -118.15' --mask Download\n",
    "    \n",
    "!smallbaselineApp.py -t LASenDT71.txt --dostep load_data\n",
    "    \n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    " \n",
    "<b>The staged data was uploaded in S3 data bucket of openSARlab and can be downloaded using:</b>\n",
    "    \n",
    "!aws s3 cp s3://asf-jupyter-data/Fielding/Stack.zip Stack.zip\n",
    "\n",
    "When users are not leveraging openSARlabs, they should start from ARIA-tools as download from S3 will not work.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"5\" color='rgba(200,0,0,0.2)'> <b>Important Notes about Binder</b> </font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"> <b>The Binder server will automatically shutdown when left idle for more than 10 minutes. Your notebook edits will be lost when this happens. You will need to relaunch the binder to continue working in a fresh copy of the notebook.</b></font>\n",
    "    <br><br>\n",
    "    <font face=\"Calibri\" size=\"4\"><b>How to Save your Notebook Edits</b></font>\n",
    "        <br><br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>The Easy Way</b>\n",
    "    <br>\n",
    "Click on the Jupyter logo at the top left of the screen to access the file manager. Download the notebook, then upload and run it the next time you restart the server.\n",
    "    <br><br>\n",
    "<b>The Better, More Complicated Way</b>\n",
    "    <br>\n",
    "This solution requires some knowledge of git. Fork the <a href=\"https://github.com/asfadmin/asf-jupyter-notebooks\" target=\"_blank\">asf-jupyter-notebook repository</a> and update the url for the Binder launch button to the url of your fork. The url to edit can be found in the first line of the README.md file for this branch. Once you have your own fork, push any notebook changes to it prior to shutting down the server or allowing it to time out.  </font>\n",
    "<br><br>\n",
    "</font>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below is required to be ran each time the notebook is started and ensures correct set-up of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# define the work directory\n",
    "work_dir = f\"{os.path.abspath(os.getcwd())}/data_LA\"\n",
    "print(\"Work directory: \", work_dir)\n",
    "if not os.path.isdir(work_dir):\n",
    "    os.makedirs(work_dir)\n",
    "    print('Create directory: {}'.format(work_dir))\n",
    "print('Go to work directory: {}'.format(work_dir))\n",
    "os.chdir(work_dir)  \n",
    "    \n",
    "if not os.path.isfile('Stack.zip'):\n",
    "    !aws --no-sign-request --region us-east-1 s3 cp s3://asf-jupyter-data/Fielding/Stack.zip Stack.zip \n",
    "        \n",
    "# verify if download was succesfull\n",
    "if os.path.isfile('Stack.zip'):\n",
    "    !unzip -q Stack.zip\n",
    "    print('S3 pre-staged data retrieval was successfull')\n",
    "else:\n",
    "    print(\"Download outside openSarLabs is not supported.\\nAs alternative please start from ARIA-tools with the commandline calls provided at the top of this notebook\")          \n",
    "\n",
    " \n",
    "# verify if mintpy install is complete:\n",
    "try:\n",
    "    import numpy as np\n",
    "    from mintpy.cli import view, tsview, plot_network, plot_transection, plot_coherence_matrix\n",
    "except:\n",
    "    print(\"Looks like mintPy is not fully installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command will download all the ARIA standard products over the LA area, which is 575 products at the time of this writing. This will take more than two hours to complete if the data is not already downloaded. <b>Because of the long time needed for the download, all necessary data set were prepared for you. Uncomment these lines only if you want to use this notebook to work on a different site of your choosing.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data for descending track 71 over Los Angeles area\n",
    "# Note: ARIA-tools is not installed in this notebook's Binder\n",
    "#!ariaDownload.py -b '33.5 34.5 -119.0 -117.9' --track 71"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ARIA time-series setup would cover the whole Los Angeles area and would take a while to process, so we are skipping this setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: ARIA-tools is not installed in this notebook's Binder\n",
    "#!ariaTSsetup.py -f 'products/*.nc' -b '33.5 34.5 -119.0 -117.9' --mask Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following ARIA time-series setup `ariaTSsetup.py` extracts the data that covers only a small area around the Palos Verdes peninsula southwest of Los Angeles to speed the time-series processing, which we specify with the bounding box. We also download the water mask to avoid using data over the ocean. <b>The code in the next code cell is commented out as these steps were already prepared for you.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: ARIA-tools is not installed in this notebook's Binder\n",
    "#!ariaTSsetup.py -f 'products/*.nc' -b '33.65 33.9 -118.45 -118.15' --mask Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Overview of the smallbaselineApp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <i>smallbaselineApp.py</i> application provides a workflow which includes several steps to invert a stack of unwrapped interferograms and apply different corrections to obtain ground displacement timeseries.  \n",
    "<br>\n",
    "The workflow consists of two main processing steps:\n",
    "\n",
    "* correcting unwrapping errors and inverting for the raw phase time-series (blue ovals),\n",
    "* correcting for noise from different sources to obtain the displacement time-series (green ovals).\n",
    "\n",
    "Some steps are optional, which are switched off by default (marked by dashed boundaries). Configuration parameters for each step are initiated with default values in a customizable text file: [smallbaselineApp.cfg](https://github.com/insarlab/MintPy/blob/master/mintpy/defaults/smallbaselineApp.cfg). In this notebook, we will walk through some of these steps, for a complete example see the [MintPy repository](https://github.com/insarlab/MintPy).\n",
    "\n",
    "<p align=\"left\">\n",
    "  <img width=\"600\" src=\"NotebookAddons/MintPyWorkflow.JPG\">\n",
    "</p>     \n",
    "<p style=\"text-align: center;\">\n",
    "    (Figure from Yunjun et al., 2019)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing steps of smallbaselineApp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MintPy **smallbaselineApp.py** application provides a workflow to invert a stack of unwrapped interferograms and apply different (often optional) corrections to obtain ground displacement timeseries. A detailed overview of the options can be retrieved by involking the help option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring processing parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processing parameters for the **smallbaselineApp.py** are controlled through a configuration file. If no file is provided the default [smallbaselineApp.cfg](https://github.com/insarlab/MintPy/blob/master/mintpy/defaults/smallbaselineApp.cfg) configuration is used. Here we use `LASenDT71.txt`, which already constains selected, manually modified configuration parameters for this time-series analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Baseline Time Series Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading ARIA data into MintPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [ARIA-tools package](https://github.com/aria-tools/ARIA-tools) is used as a pre-processor for MintPY. It has a download tool that wraps around the ASF DAAC API, and includes tools for stitching/cropping and time-series preparation. The output of the time-series preparation is compatible with the [data directory](https://mintpy.readthedocs.io/en/latest/dir_structure/) structure from MintPy. To save time, we have already pre-ran these steps. The commands used were:\n",
    "\n",
    "```\n",
    "!ariaDownload.py -b '33.5 34.5 -119.0 -117.9' --track 71\n",
    "!ariaTSsetup.py -f 'products/*.nc' -b '33.65 33.9 -118.45 -118.15' --mask Download\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ariaTSsetup.py` step above (or the pre-processed Stack.zip) extracted the data for the subset we specified and found a total of 439 products that cover our study area. Now we load the data for the subset area into MintPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the MintPy time-series directory\n",
    "mint_dir = work_dir+'/MintPy'\n",
    "print(\"MintPy directory: \", mint_dir)\n",
    "if not os.path.isdir(mint_dir):\n",
    "    os.makedirs(mint_dir)\n",
    "    print('Create directory: {}'.format(mint_dir))\n",
    "\n",
    "# copy the configuration file\n",
    "os.chdir(work_dir)  \n",
    "!cp LASenDT71.txt MintPy\n",
    "\n",
    "print('Go to work directory: {}'.format(mint_dir))\n",
    "os.chdir(mint_dir)  \n",
    "\n",
    "!smallbaselineApp.py LASenDT71.txt --dostep load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the loading step is an \"inputs\" directory containing two HDF5 files:\n",
    "- ifgramStack.h5: This file contains 6 dataset cubes (e.g. unwrapped phase, coherence, connected components etc.) and multiple metadata.  \n",
    "- geometryGeo.h5: This file contains geometrical datasets (e.g., incidence/azimuth angle, masks, etc.). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>info.py :</b> \n",
    "To get general infomation about a MintPy product, run info.py on the file.   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!info.py inputs/ifgramStack.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!info.py inputs/geometryGeo.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the interferogram network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running **plot_network.py** gives an overview of the network and the average coherence of the stack. The program creates multiple files as follows:\n",
    "- ifgramStack_coherence_spatialAvg.txt: Contains interferogram dates, average coherence temporal and spatial baseline separation.\n",
    "- Network.pdf: Displays the network of interferograms on time-baseline coordinates, colorcoded by avergae coherence of the interferograms. \n",
    "- CoherenceMatrix.pdf shows the avergae coherence pairs between all available pairs in the stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py LASenDT71.txt  --dostep modify_network\n",
    "plot_network.main(['inputs/ifgramStack.h5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>EXERCISE</u>:  </font> Analyze the Plots Generated by the Previous Code Cell</b>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Look at the different plots and analyze their content: \n",
    "<ol>\n",
    "    <li><b>First Plot:</b> This plot shows the individual SAR images as circles plotted with time on the x-axis and perpendicular baseline $B_{\\perp}$ on the y-axis. Orange Circles indicate images that were retained and Grey Circles show acquisitions that were dropped based on the coherence of the available interferograms. It can be seen that two images were removed from the stack.</li><br>\n",
    "    <li><b>Second Plot:</b> This plots shows the coherence matrix. The main diagonal corresponds to the 132 SAR images in the stack. Off diagonal elements correspond to coherence values of formed from these SAR images. Colored matrix elements correspond to interferograms that were computed for this stack. White areas are missing interferograms. The color corresponds to the coherence. It can be seen that the coherence is high in most interferograms.</li><br>\n",
    "    <li><b>Third Plot:</b> This plot provides a compressed view of the previous plot by presenting all interferograms used for a specific time step by their maximum and minimum coherence. Again, it can be seen that coherence overall is good for the analyzed area.</li><br>\n",
    "    <li><b>Fourth Plot:</b> This plot shows the SAR images as circles (similar to the first plot) and adds interferograms as lines. E.g., an interferogram formed from the first and third SAR image would be plotted as a line connecting these two images. Dashed lines show interferograms that were dropped due to lower coherence.</li>\n",
    "</ol>\n",
    "</font>\n",
    "</div>\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask files can be can be used to mask pixels in the time-series processing. Below we generate a mask file based on the connected components, which is a metric for unwrapping quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!generate_mask.py  inputs/ifgramStack.h5  --nonzero  -o maskConnComp.h5  --update\n",
    "view.main(['maskConnComp.h5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Note :</b> \n",
    "Red pixels are retained for further analysis. Blue pixels were removed due to low coherence, leading to phase unwrapping errors. Most of the areas in blue are off shore and covered by water.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "#!view.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reference_point\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interferometric phase is relative observation by nature. The phases of each unwrapped interferogram are relative with respect to an arbitrary pixel. Therfore we need to reference all interferograms to a common reference pixel.\n",
    "The step \"reference_point\" selects a common reference pixel for the stack of interferograms. The default approach of mintpy is to choose a pixel with highest spatial coherence in the stack. Other options include specifying the longitude and latitude of the desired reference pixel or the line and column number of the refence pixel.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py LASenDT71.txt --dostep reference_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the \"reference_step\" adds additional attributes \"REF_X, REF_Y\" and \"REF_LON, REF_LAT\" to the ifgramStack.h5 file. To see the attributes of the file run info.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!info.py inputs/ifgramStack.h5 | egrep 'REF_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, I set the reference point latitude and longitude to be in a location close to the Portuguese Bend Landslide, and MintPy calculated the X and Y locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Inverting of the Small Baseline network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we invert the network of differential unwrapped interferograms to estimate the time-series of unwrapped phase with respect to a reference acquisition date. By default mintpy selects the first acquisition. The estimated time-series is converted to distance change from radar to target and is provided in meters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py LASenDT71.txt --dostep invert_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The timeseries file contains three datasets:\n",
    "- the \"time-series\" which is the interferometric range change for each acquisition relative to the reference acquisition,\n",
    "- the \"date\" dataset which contains the acquisition date for each acquisition,\n",
    "- the \"bperp\" dataset which contains the timeseries of the perpendicular baseline.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Estimating the long-term velocity rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ground deformation caused by many geophysical or anthropogenic processes are linear at first order approximation. Therefore it is common to estimate the rate of the ground deformation which is the slope of linear fit to the time-series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py LASenDT71.txt --dostep velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scp_args = 'velocity.h5 velocity -v -1 1'\n",
    "view.main(scp_args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Note :</b> \n",
    "Negative values indicates that target is moving away from the radar (i.e., Subsidence in case of vertical deformation).\n",
    "Positive values indicates that target is moving towards the radar (i.e., uplift in case of vertical deformation). \n",
    "    The line of sight (LOS) for this descending Sentinel-1 track is up and east from ground to radar.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obvious features in the estimated velocity map:\n",
    "\n",
    "1) There are several features with significant velocity in this area. \n",
    "\n",
    "2) The negative LOS feature on the Palos Verdes peninsula (center left of map) is the Portuguese Bend Landslide, moving down and southwest toward the sea.\n",
    "\n",
    "3) There are areas of positive and negative LOS change in the area of Long Beach (east part of map). These are due to the extraction of oil and injection of water in oilfields beneath the city and out in the harbor.\n",
    "\n",
    "4) The block box at 33.76N, 118.36W is the reference pixel for this map, just north of the Portuguese Bend Landslide. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Error analysis (what is signal, what is noise!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncertainty of the ground displacement products derived from InSAR time-series, depends on the quality of the inversion of the stack of interferograms and the accuracy in separating the ground displacement from other components of the InSAR data. Therefore the definition of signal vs noise is different at the two main steps in mintpy:  \n",
    "\n",
    "1) During the inversion: \n",
    "    At this step all systematic components of the interferometric phase (e.g., ground displacement, propagation delay, geometrical residuals caused by DEM or platform's orbit inaccuracy) are considered signal, while the interferometric phase decorrelation, phase unwrapping error and phase inconsistency are considered noise. \n",
    "    \n",
    "2) After inversion: the ground displacement component of the time-serieses is signal, and everything else (including the propagation delay and geometrical residuals) are considered noise\n",
    "\n",
    "Therefore we first discuss the possible sources of error during the inversion and the existing ways in MintPy to evaluate the quality of inversion and to improve the uncertainty of the inversion. Afterwards we explain the different components of the time-series and the different processing steps in MintPy to separate them from ground displacement signal.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Quality of the inversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main sources of noise during the time-series inversion includes decorrelation, phase unwrapping error and the inconsistency of triplets of interferofgrams. Here we mainly focus on the decorrelation and unwrapping errors. We first show the existing quantities in MintPy to evaluate decorrelation and unwrapping errors and then discuss the existing ways in MintPy to reduce the decorrelation and unwrapping errors on the time-series inversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Average spatial coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mintpy computes temporal average of spatial coherence of the entire stack as a potential ancillary measure to choose reliable pixels after time-series inversion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.main(['avgSpatialCoh.h5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Temporal coherence\n",
    "\n",
    "In addition to timeseries.h5 which contains the time-series dataset, invert_network produces other quantities, which contain metrics to evaluate the quality of the inversion including temporalCoherence.h5. Temporal coherence represents the consistency of the timeseries with the network of interferograms. \n",
    "\n",
    "Temporal coherence varies from 0 to 1. Pixels with values closer to 1 are considered reliable and pixels with values closer to zero are considered unreliable. For a dense network of interferograms, a threshold of 0.7 may be used (Yunjun et al, 2019)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "view.main(['temporalCoherence.h5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With both the spatial coherence and temporal coherence, we can see that the InSAR in the ports of Long Beach and Los Angeles have unstable phase, and the InSAR measurements there will be low quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Velocity error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated velocity also comes with an expression of unecrtainty which is simply based on the goodness of fit while fitting a linear model to the time-series. This quantity is saved in \"velocity.h5\" under the velocityStd dataset. \n",
    "\n",
    "**Mintpy supports additional corrections in its processing not included in this demo:**\n",
    "- Unwrapping error correction\n",
    "- Tropospheric delay correction\n",
    "- deramping\n",
    "- Topographic residual correction\n",
    "- Residual RMS for noise evaluation\n",
    "- Changing the reference date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scp_args = 'velocity.h5 velocityStd -v 0 0.2'\n",
    "view.main(scp_args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the plot above is the velocity error, not the velocity. The errors generally increase with distance from the reference point and also increase for points with elevations different from the reference point because of topographically correlated water vapor variations that are especially strong in this area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Plotting a Landslide Motion Transect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scp_args = 'velocity.h5 --start-lalo 33.75 -118.38 --end-lalo 33.72 -118.3'\n",
    "plot_transection.main(scp_args.split())\n",
    "\n",
    "!smallbaselineApp.py smallbaselineApp.cfg --dostep google_earth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " On this transect, the Portuguese Bend Landslide has an average velocity over the last five years that reaches more than 2.5 cm/year in the descending track radar LOS direction (note that the \"zero\" is about -5 so we have to subtract that first). By analyzing the velocity on the ascending track and combining the two LOS directions, then we could find out that the displacments are largely horizontal, westward (and southward that we can't see with InSAR)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Original Notebook withe detailed description by Yunjun and Fattahi at: https://nbviewer.jupyter.org/github/insarlab/MintPy-tutorial/blob/master/smallbaselineApp_aria.ipynb\n",
    "\n",
    "- Mintpy reference: *Yunjun, Z., H. Fattahi, F. Amelung (2019), Small baseline InSAR time series analysis: unwrapping error correction and noise reduction, preprint doi:[10.31223/osf.io/9sz6m](https://eartharxiv.org/9sz6m/).*\n",
    "\n",
    "- University of Miami online time-series viewer: https://insarmaps.miami.edu/\n",
    "\n",
    "- Mintpy Github repository: https://github.com/insarlab/MintPy\n",
    "\n",
    "- ARIA-tools Github Repository: https://github.com/aria-tools/ARIA-tools"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "conda-env-.local-notebook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
