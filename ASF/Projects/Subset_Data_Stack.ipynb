{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![OpenSARlab notebook banner](NotebookAddons/blackboard-banner.png)\n",
    "\n",
    "# Subset Data Stack\n",
    "\n",
    "### Alex Lewandowski; University of Alaska Fairbanks\n",
    "\n",
    "This notebook crops a directory of tiffs to a subset area of interest using an interactive Matplotlib plot of an image in your data stack.\n",
    "\n",
    "<img style=\"padding: 7px\" src=\"NotebookAddons/UAFLogo_A_647.png\" width=\"170\" align=\"right\"/></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Note about JupyterHub**\n",
    "\n",
    "Your JupyterHub server will automatically shutdown when left idle for more than 1 hour. Your notebooks will not be lost but you will have to restart their kernels and re-run them from the beginning. You will not be able to seamlessly continue running a partially run notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import url_widget as url_w\n",
    "notebookUrl = url_w.URLWidget()\n",
    "display(notebookUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "\n",
    "notebookUrl = notebookUrl.value\n",
    "user = !echo $JUPYTERHUB_USER\n",
    "env = !echo $CONDA_PREFIX\n",
    "if env[0] == '':\n",
    "    env[0] = 'Python 3 (base)'\n",
    "if env[0] != '/home/jovyan/.local/envs/rtc_analysis':\n",
    "    display(Markdown(f'<text style=color:red><strong>WARNING:</strong></text>'))\n",
    "    display(Markdown(f'<text style=color:red>This notebook should be run using the \"rtc_analysis\" conda environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>It is currently using the \"{env[0].split(\"/\")[-1]}\" environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Select the \"rtc_analysis\" from the \"Change Kernel\" submenu of the \"Kernel\" menu.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>If the \"rtc_analysis\" environment is not present, use <a href=\"{notebookUrl.split(\"/user\")[0]}/user/{user[0]}/notebooks/conda_environments/Create_OSL_Conda_Environments.ipynb\"> Create_OSL_Conda_Environments.ipynb </a> to create it.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Note that you must restart your server after creating a new environment before it is usable by notebooks.</text>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing Relevant Python Packages\n",
    "\n",
    "In this notebook we will use the following scientific library:\n",
    "\n",
    "- [GDAL](https://www.gdal.org/) is a software library for reading and writing raster and vector geospatial data formats. It includes a collection of programs tailored for geospatial data processing. Most modern GIS systems (such as ArcGIS or QGIS) use GDAL in the background.\n",
    "\n",
    "**Import the necesssary libraries and modules:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from pathlib import Path\n",
    "import json # for loads\n",
    "import shutil\n",
    "\n",
    "from osgeo import gdal\n",
    "gdal.UseExceptions()\n",
    "import pyproj \n",
    "\n",
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "%matplotlib widget\n",
    "    \n",
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "import opensarlab_lib as asfn\n",
    "asfn.jupytertheme_matplotlib_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Write functions to gather and print individual tiff paths:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tiff_paths(paths):\n",
    "    tiff_paths = list(paths.parent.rglob(paths.name))    \n",
    "    tiff_paths.sort()\n",
    "    return tiff_paths\n",
    "\n",
    "def print_tiff_paths(tiff_paths):\n",
    "    print(\"Tiff paths:\")\n",
    "    for p in tiff_paths:\n",
    "        print(f\"{p}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select the directory holding your tiffs**\n",
    "- Click the `Select` button\n",
    "- Navigate to your data directory\n",
    "- Click the `Select` button\n",
    "- Confirm that the desired path appears in green text\n",
    "- Click the `Change` button to alter your selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fc = FileChooser('/home/jovyan/notebooks')\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Determine the path to the analysis directory containing the tiff directory:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_dir = Path(fc.selected_path)\n",
    "analysis_dir = tiff_dir.parent\n",
    "print(f\"analysis_dir: {analysis_dir}\")\n",
    "\n",
    "paths = tiff_dir/\"*.tif*\"\n",
    "tiff_paths = get_tiff_paths(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Determine the UTM zone for your images.** \n",
    "\n",
    "This assumes you have already reprojected multiple UTM projections to a single predominant projection using the Prepare_Data_Stack_Hyp3 notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = gdal.Info(str(tiff_paths[0]), format='json')\n",
    "info = info['coordinateSystem']['wkt']\n",
    "utm = info.split('ID')[-1].split(',')[1][0:-2]\n",
    "print(f\"UTM Zone: {utm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_paths = get_tiff_paths(paths)\n",
    "print_tiff_paths(tiff_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a string containing paths to one image for each area represented in the stack:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_merge = {}\n",
    "for pth in tiff_paths:\n",
    "    info = (gdal.Info(str(pth), options = ['-json']))\n",
    "    info = json.dumps(info)\n",
    "    info = (json.loads(info))['wgs84Extent']['coordinates']\n",
    "    \n",
    "    coords = [info[0][0], info[0][3]]\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 2):\n",
    "            coords[i][j] = round(coords[i][j])\n",
    "    str_coords = f\"{str(coords[0])}{str(coords[1])}\"\n",
    "    if str_coords not in to_merge:\n",
    "        to_merge.update({str_coords: pth})\n",
    "merge_paths = \"\"\n",
    "for pth in to_merge:\n",
    "    merge_paths = f\"{merge_paths} {to_merge[pth]}\"\n",
    "print(merge_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge the images for display in the Area-Of-Interest selector:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_scene = analysis_dir/'full_scene.tif'\n",
    "\n",
    "if full_scene.exists():\n",
    "    full_scene.unlink()\n",
    "    \n",
    "gdal_command = f\"gdal_merge.py -o {full_scene} {merge_paths}\"\n",
    "!{gdal_command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Subset The Tiffs\n",
    "\n",
    "**Create a Virtual Raster Stack:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = f\"{analysis_dir}/raster_stack.vrt\"\n",
    "!gdalbuildvrt -separate $image_file -overwrite $full_scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert the VRT into an array:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = gdal.Open(image_file)\n",
    "rasterstack = img.ReadAsArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the number of bands, pixels, and lines:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.RasterCount) # Number of Bands\n",
    "print(img.RasterXSize) # Number of Pixels\n",
    "print(img.RasterYSize) # Number of Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create an AOI selector from an image in your raster stack:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_xsize = 7\n",
    "fig_ysize = 7\n",
    "aoi = asfn.AOI_Selector(rasterstack, fig_xsize, fig_ysize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gather and define projection details:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geotrans = img.GetGeoTransform()\n",
    "projlatlon = pyproj.Proj('EPSG:4326') # WGS84\n",
    "projimg = pyproj.Proj(f'EPSG:{utm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write a function to convert the pixel, line coordinates from the AOI selector into geographic coordinates in the stack's EPSG projection:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geolocation(x, y, geotrans,latlon=True):\n",
    "    ref_x = geotrans[0]+x*geotrans[1]\n",
    "    ref_y = geotrans[3]+y*geotrans[5]\n",
    "    if latlon:\n",
    "        ref_y, ref_x = pyproj.transform(projimg, projlatlon, ref_x, ref_y)\n",
    "    return [ref_x, ref_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Call geolocation to gather the aoi_coords:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    aoi_coords = [geolocation(aoi.x1, aoi.y1, geotrans, latlon=False), geolocation(aoi.x2, aoi.y2, geotrans, latlon=False)]\n",
    "    print(f\"aoi_coords in EPSG {utm}: {aoi_coords}\")\n",
    "except TypeError:\n",
    "    print('TypeError')\n",
    "    display(Markdown(f'<text style=color:red>This error occurs if an AOI was not selected.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Note that the square tool icon in the AOI selector menu is <b>NOT</b> the selection tool. It is the zoom tool.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Read the tips above the AOI selector carefully.</text>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collect the paths to the tiffs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_paths = get_tiff_paths(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a subdirectory in which to store the subset tiffs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Choose a directory name in which to store the subset geotiffs.\")\n",
    "print(\"Note: this will sit alongside the directory containing your pre-subset geotiffs.\")\n",
    "while True:\n",
    "    sub_name = input()\n",
    "    if sub_name == \"\":\n",
    "        print(\"Please enter a valid directory name\")\n",
    "        continue\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subset the tiffs and move them from the individual product directories into their own directory, /tiffs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_paths = get_tiff_paths(paths)\n",
    "for p in tiff_paths:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_dir = analysis_dir/f'{sub_name}'\n",
    "\n",
    "if not subset_dir.exists():\n",
    "    subset_dir.mkdir()\n",
    "\n",
    "# sometimes, tiff doesn't follow '[0-9]{7}T[0-9]6' format, hence just get the numbers in those cases \n",
    "for i, tiff_path in enumerate(tiff_paths):\n",
    "    print(tiff_path)\n",
    "    date = Path(asfn.date_from_product_name(str(tiff_path))).name.split('T')[0]\n",
    "    polar = asfn.get_polarity_from_path(str(tiff_path))\n",
    "    print(f\"\\nProduct #{i+1}:\")\n",
    "    gdal_command = f\"gdal_translate -projwin {aoi_coords[0][0]} {aoi_coords[0][1]} {aoi_coords[1][0]} {aoi_coords[1][1]} -projwin_srs 'EPSG:{utm}' -co \\\"COMPRESS=DEFLATE\\\" -a_nodata 0 {tiff_path} {subset_dir}/{date}_{polar}.tiff\"\n",
    "    print(f\"Calling the command: {gdal_command}\")\n",
    "    !{gdal_command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Delete any subset tifs that are filled with NaNs and contain no data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_paths = subset_dir/f\"*.tif*\"\n",
    "tiff_paths = get_tiff_paths(subset_paths)\n",
    "\n",
    "asfn.remove_nan_filled_tifs(tiff_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sometimes, when using gdal translate to subset a stack of images, there will be slight differences in sizes of the resulting images, off by a single pixel in either direction. The following code checks the newly subset stack for this problem, and if found, it re-subsets all the images to the size of the smallest image in the stack.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdal_tiff_input = str(tiff_paths[0])\n",
    "\n",
    "corners = [gdal.Info(gdal_tiff_input, format='json')['cornerCoordinates']['upperLeft'],\n",
    "                 gdal.Info(gdal_tiff_input, format='json')['cornerCoordinates']['lowerRight']]\n",
    "\n",
    "sizes = list()\n",
    "for p in tiff_paths:\n",
    "    info = gdal.Info(str(p), format='json')\n",
    "    sizes.append((info['size'][0], info['size'][1]))\n",
    "    corners = [[max(corners[0][0], gdal.Info(gdal_tiff_input, format='json')['cornerCoordinates']['upperLeft'][0]),\n",
    "               min(corners[0][1], gdal.Info(gdal_tiff_input, format='json')['cornerCoordinates']['upperLeft'][1])],\n",
    "               [min(corners[1][0], gdal.Info(gdal_tiff_input, format='json')['cornerCoordinates']['lowerRight'][0]),\n",
    "               max(corners[1][1], gdal.Info(gdal_tiff_input, format='json')['cornerCoordinates']['lowerRight'][1])]]   \n",
    "    \n",
    "if len(sizes) != len(set(sizes)):\n",
    "    print(set(sizes))\n",
    "    print(corners)\n",
    "    temp_path = analysis_dir/f\"temp_subsetting\"\n",
    "    if not temp_path.exists():\n",
    "        subset_dir.rename(temp_path)\n",
    "        \n",
    "        if not subset_dir.exists():\n",
    "            subset_dir.mkdir()\n",
    "            \n",
    "        tiff_paths = list(temp_path.rglob('*.tif*'))\n",
    "\n",
    "    for i, tiff_path in enumerate(tiff_paths):\n",
    "        print(f\"\\nProduct #{i+1}:\")\n",
    "        gdal_command = f\"gdal_translate -projwin {corners[0][0]} {corners[0][1]} {corners[1][0]} {corners[1][1]} -projwin_srs 'EPSG:{utm}' -co \\\"COMPRESS=DEFLATE\\\" -a_nodata 0 {tiff_path} {subset_dir}/{tiff_path.name}\"\n",
    "        print(f\"Calling the command: {gdal_command}\")\n",
    "        !{gdal_command}\n",
    "    shutil.rmtree(temp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decide whether or not to cleanup the original tiffs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup = asfn.select_parameter([\"Save original tiffs\", \"Delete original tiffs\"], '')\n",
    "cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cleanup.value == 'Delete original tiffs':\n",
    "    shutil.rmtree(tiff_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the path to your subset directory:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*GEOS 657 Microwave Remote Sensing - Version 2.0.0 - November 2021*\n",
    "\n",
    "*Version Changes:*\n",
    "- *asf_notebook -> opensarlab-lib*\n",
    "- *html -> markdown\n",
    "- *url-widget*\n",
    "- *%matplotlib widget*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtc_analysis [conda env:.local-rtc_analysis]",
   "language": "python",
   "name": "conda-env-.local-rtc_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
