{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"NotebookAddons/blackboard-banner.jpg\" width=\"100%\" />\n",
    "<font face=\"Calibri\">\n",
    "<br>\n",
    "<font size=\"5\"> <b>SAR Time Series Change Detection over Ecosystems and Deforestation Sites </b> </font>\n",
    "\n",
    "<br>\n",
    "<font size=\"4\"> <b> Franz J Meyer; University of Alaska Fairbanks & Josef Kellndorfer, <a href=\"http://earthbigdata.com/\" target=\"_blank\">Earth Big Data, LLC</a> </b> <br>\n",
    "<img style=\"padding: 7px\" src=\"NotebookAddons/UAFLogo_A_647.png\" width=\"170\" align=\"right\"/>\n",
    "</font>\n",
    "\n",
    "<font size=\"3\"> This notebook applies Change Point Detection on a deep multi-temporal SAR image data stack acquired by Sentinel-1. Specifically, the lab applies the method of Cummulative Sums to perform change detection on a 21-image deep VH-polarized C-band SAR data stack over Madre de Dios in Peru to analyze time series signatures of vegetation covers, water bodies, and areas affected by deforestation.\n",
    "\n",
    "<b>In this notebook we introduce the following data analysis concepts:</b>\n",
    "\n",
    "- Performing Cummulative Sums change detection on an actual data set\n",
    "- Explaining of all steps of the change detection workflow\n",
    "- Identification of change dates for each identified change pixel\n",
    "</font>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"5\" color='rgba(200,0,0,0.2)'> <b>Important Notes about Binder</b> </font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"> <b>The Binder server will automatically shutdown when left idle for more than 10 minutes. Your notebook edits will be lost when this happens. You will need to relaunch the binder to continue working in a fresh copy of the notebook.</b></font>\n",
    "    <br><br>\n",
    "    <font face=\"Calibri\" size=\"4\"><b>How to Save your Notebook Edits</b></font>\n",
    "        <br><br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>The Easy Way</b>\n",
    "    <br>\n",
    "Click on the Jupyter logo at the top left of the screen to access the file manager. Download the notebook, then upload and run it the next time you restart the server.\n",
    "    <br><br>\n",
    "<b>The Better, More Complicated Way</b>\n",
    "    <br>\n",
    "This solution requires some knowledge of git. Fork the <a href=\"https://github.com/asfadmin/asf-jupyter-notebooks\" target=\"_blank\">asf-jupyter-notebook repository</a> and update the url for the Binder launch button to the url of your fork. The url to edit can be found in the first line of the README.md file for this branch. Once you have your own fork, push any notebook changes to it prior to shutting down the server or allowing it to time out.  </font>\n",
    "<br><br>\n",
    "</font>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Relevant Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\"><font size=\"3\">In this notebook we will use the following scientific libraries:\n",
    "<ol type=\"1\">\n",
    "    <li> <b><a href=\"https://pandas.pydata.org/\" target=\"_blank\">Pandas</a></b> is a Python library that provides high-level data structures and a vast variety of tools for analysis. The great feature of this package is the ability to translate rather complex operations with data into one or two commands. Pandas contains many built-in methods for filtering and combining data, as well as the time-series functionality. </li>\n",
    "    <li> <b><a href=\"https://www.gdal.org/\" target=\"_blank\">GDAL</a></b> is a software library for reading and writing raster and vector geospatial data formats. It includes a collection of programs tailored for geospatial data processing. Most modern GIS systems (such as ArcGIS or QGIS) use GDAL in the background.</li>\n",
    "    <li> <b><a href=\"http://www.numpy.org/\" target=\"_blank\">NumPy</a></b> is one of the principal packages for scientific applications of Python. It is intended for processing large multidimensional arrays and matrices, and an extensive collection of high-level mathematical functions and implemented methods makes it possible to perform various operations with these objects. </li>\n",
    "    <li> <b><a href=\"https://matplotlib.org/index.html\" target=\"_blank\">Matplotlib</a></b> is a low-level library for creating two-dimensional diagrams and graphs. With its help, you can build diverse charts, from histograms and scatterplots to non-Cartesian coordinates graphs. Moreover, many popular plotting libraries are designed to work in conjunction with matplotlib. </li>\n",
    "\n",
    "<br>\n",
    "<b>Our first step is to import them:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json # for loads\n",
    "\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "from asf_notebook_ChangeDetection import new_directory\n",
    "from asf_notebook_ChangeDetection import path_exists\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Your Prepared Data Stack Into the Notebook<img src=\"NotebookAddons/Deforest-MadreDeDios.jpg\" width=\"350\" style=\"padding:5px;\" align=\"right\" />\n",
    "\n",
    "<font face=\"Calibri\"><font size=\"3\"> This notebook is using a 21-image deep VH-polarized C-band SAR data stack over Madre de Dios in Peru to analyze time series signatures of vegetation covers, water bodies, and areas affected by deforestation. The C-band data were acquired by ESA's Sentinel-1 SAR sensor constellation and are available to you through the services of the <a href=\"https://www.asf.alaska.edu/\" target=\"_blank\">Alaska Satellite Facility</a>. \n",
    "\n",
    "The site in question is interesting as it has experienced extensive logging over the last 10 years (see image to the right; <a href=\"https://blog.globalforestwatch.org/\" target=\"_blank\">Monitoring of the Andean Amazon Project</a>). Since the 1980s, people have been clearing forests in this area for farming, cattle ranching, logging, and (recently) gold mining. We will apply Cummulative Sums change detection to determine which areas were deforested since the beginning of our time series in February of 2016.\n",
    "</font></font>\n",
    "<br><br>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"><b>We begin by writing a function to retrieve the absolute paths to each of our tiffs:</b>\n",
    "</font> \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tiff_paths(paths):\n",
    "    tiff_paths = !ls $paths | sort -t_ -k5,5\n",
    "    return tiff_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Stacking up of SAR Images:\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\">The following code cell retrieves the prepared Sentinel-1 data stack from an Amazon Web Services (AWS) S3 storage space. It unzips the data and organizes it in a sub-folder. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"MadreDeDios_binder\"\n",
    "path = path = f\"./{name}\"\n",
    "new_directory(path)\n",
    "os.chdir(path)\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "time_series_path = f\"s3://asf-jupyter-data-west/{name}.zip\"\n",
    "time_series = os.path.basename(time_series_path)\n",
    "!aws --no-sign-request --region us-west-2 s3 cp $time_series_path $time_series\n",
    "!unzip -o {name}.zip\n",
    "!rm {name}.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">The following code cell <b>defines a function to extract the tiff dates from the file names of the Sentinel-1 images:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(paths):\n",
    "    dates = []\n",
    "    pths = glob.glob(paths)\n",
    "    for p in pths:\n",
    "        filename = os.path.basename(p).split('_')\n",
    "        for chunk in filename:\n",
    "            if len(chunk) == 15 and 'T' in chunk:\n",
    "                date = chunk.split('T')[0]\n",
    "                dates.append(date)\n",
    "                break\n",
    "            elif len(chunk) == 8:\n",
    "                try:\n",
    "                    int(chunk)\n",
    "                    dates.append(chunk)\n",
    "                    break\n",
    "                except ValueError:\n",
    "                    continue              \n",
    "    dates.sort()\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">Now we <b>call the ```get_dates()``` function to collect the product acquisition dates:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_paths = f\"tiffs/*VH.tif*\"\n",
    "dates = get_dates(tiff_paths)\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Gather the upper-left and lower-right corner coordinates</b> as well as the <b>UTM zone</b> associated with your data stack.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiffies = get_tiff_paths(tiff_paths)\n",
    "coords = [[], []]\n",
    "info = (gdal.Info(tiffies[0], options = ['-json']))\n",
    "info = json.dumps(info)\n",
    "coords[0] = (json.loads(info))['cornerCoordinates']['upperLeft']\n",
    "coords[1] = (json.loads(info))['cornerCoordinates']['lowerRight']\n",
    "print(coords)\n",
    "utm = json.loads(info)['coordinateSystem']['wkt'].split('ID')[-1].split(',')[1][0:-2]\n",
    "print(f\"UTM Zone: {utm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Virtual Raster Table to Create our SAR Data Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"> Now we are finally ready to stack up the data by creating a virtual raster table with links to all subset data files: </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdalbuildvrt -separate raster_stack.vrt $tiff_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Let's Work With Your Data \n",
    "<font face=\"Calibri\"><font size=\"3\"> Now you are ready to perform time series change detection on your data stack.\n",
    "</font> \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Data Directory and Path to VRT \n",
    "<font face=\"Calibri\" size=\"3\"><b>Create a variable containing the VRT filename:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"raster_stack.vrt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create a time index</b> containing all image acquisition dates:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some indices for plotting\n",
    "time_index = pd.DatetimeIndex(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Print the bands and dates for all images in the virtual raster table (VRT):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 1\n",
    "print(f\"Bands and dates for {image_file}\")\n",
    "for i in time_index:\n",
    "    print(\"{:4d} {}\".format(j, i.date()), end=' ')\n",
    "    j += 1\n",
    "    if j%5 == 1: print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Your Data Stack with gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = gdal.Open(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Print the bands, pixels, and lines:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of  bands: {img.RasterCount}\")\n",
    "print(f\"Number of pixels: {img.RasterXSize}\")\n",
    "print(f\"Number of  lines: {img.RasterYSize}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a masked raster stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">Some of our images may have pixels with \"0\" values in them. The value of \"0\" is used to identify no-data areas. To make sure these no-data pixels do not affect our statistical data analysis, we mask all \"0\" values to remove them from further consideration.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_stack = img.ReadAsArray()\n",
    "raster_stack_masked = np.ma.masked_where(raster_stack==0, raster_stack)\n",
    "del raster_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we Perform Cumulative Sums Change Detection\n",
    "<font face=\"Calibri\" size=\"3\">Using numpy arrays we can apply the concept of **cumulative sum change detection** analysis effectively on the entire image stack. We take advantage of array slicing and axis-based computing in numpy. **Axis 0 is the time domain** in our raster stacks.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our time series stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">The following code cells convert our image data into the decibel (dB) scale and plot the first (earliest) layer of the image. This image shows the state of deforestation (dark areas) at the beginning of the time series.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = 10.*np.log10(raster_stack_masked)\n",
    "del raster_stack_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.figure(figsize=(12, 8))\n",
    "band_number = 0\n",
    "vmin = np.percentile(db[band_number], 5)\n",
    "vmax = np.percentile(db[band_number], 95)\n",
    "plt.title('Band  {} {}'.format(band_number+1, time_index[band_number].date()))\n",
    "plt.imshow(db[0], cmap='gray', vmin=vmin, vmax=vmax)\n",
    "cbar = plt.colorbar()\n",
    "_ = cbar.ax.set_xlabel('dB', fontsize='12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Temporal Mean to Prepare for Calculation of Cummulative Sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">As <b><u>First Step</u></b> of the Cummulative Sums approach, we <b>calculate and plot the temporal mean $\\bar{X}$</b> for our data stack:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_mean = np.mean(db, axis=0)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(db_mean, cmap='gray')\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_xlabel('dB', fontsize='12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">As <b><u>Second Step</u></b> we calculate the residuals and plot the residual for the first image band:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = db - db_mean\n",
    "del db\n",
    "del db_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_number = 0   #you can change this variable to visualize different image bands\n",
    "\n",
    "if band_number > (img.RasterCount) -1:\n",
    "    band_number = (img.RasterCount) -1\n",
    "vmin = np.percentile(residuals.flatten(), 3)\n",
    "vmax = np.percentile(residuals.flatten(), 97)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(residuals[band_number], vmin=vmin, vmax=vmax, cmap='RdBu')\n",
    "plt.title('Residuals for Band  {} {}'.format(band_number+1, time_index[band_number].date()))\n",
    "cbar = plt.colorbar()\n",
    "_ = cbar.ax.set_xlabel('dB', fontsize='12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>EXERCISE</u>:  </font> Analyze the Residual Images</b>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> What do the red and blue colors mean. Try to interpret them in the context of radar brightness changes. You will see that dark blue regions of an image were brighter than the temporal mean at the acquisition date you are visualizing. In contrast, red areas were darker. Think about that in the context of deforestation. Change the ```band_number``` variable in the code cell above to visualize different residual images. </font>\n",
    "</div>\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Cummulative Sum as well as Change Magnitude: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">As the <b><u>Third Step</u></b> of the Cummulative Sums process we <b>calculate the cummulative sums $S = S_{max} - S_{min}$ and the change magnitude</b> variables. We then plot $S_{min}$, $S_{min}$, and the change magnitude.</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summation = np.cumsum(residuals, axis=0)\n",
    "summation_max = np.max(summation, axis=0)\n",
    "summation_min = np.min(summation, axis=0)\n",
    "change_mag = summation_max - summation_min\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "vmin = np.percentile(summation_min.flatten(), 3)\n",
    "vmax = np.percentile(summation_max.flatten(), 97)\n",
    "max_plot = ax[0].imshow(summation_max, vmin=vmin, vmax=vmax, cmap='RdBu')\n",
    "ax[0].set_title('$S_{max}$')\n",
    "ax[1].imshow(summation_min, vmin=vmin, vmax=vmax, cmap='RdBu')\n",
    "ax[1].set_title('$S_{min}$')\n",
    "ax[2].imshow(change_mag, vmin=vmin, vmax=vmax, cmap='RdBu')\n",
    "ax[2].set_title('Change Magnitude')\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.02, 0.7])\n",
    "cbar = fig.colorbar(max_plot, cax=cbar_ax)\n",
    "_ = cbar.ax.set_xlabel('dB', fontsize='12')\n",
    "del summation\n",
    "del summation_max\n",
    "del summation_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask Change Magnitude with a-priori Threshold To Idenfity Change Candidates:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">To <b>identified change candidate pixels <u>(Fourth Step)</u></b>, we can threshold $S_{diff}$ to reduce computation of the bootstrapping. For land cover change, we would not expect more than 5-10% change pixels in a landscape. So, if the test region is reasonably large, setting a threshold for expected change to 10% is appropriate. In our example, we'll start out with a very conservative threshold of 15%.\n",
    "<br><br>\n",
    "<b>Plot the histogram and CDF for the change magnitude:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "fig = plt.figure(figsize=(14, 6)) # Initialize figure with a size\n",
    "ax1 = fig.add_subplot(121)  # 121 determines: 2 rows, 2 plots, first plot\n",
    "ax2 = fig.add_subplot(122)\n",
    "# Second plot: Histogram\n",
    "# IMPORTANT: To get a histogram, we first need to *flatten* \n",
    "# the two-dimensional image into a one-dimensional vector.\n",
    "histogram = ax1.hist(change_mag.flatten(), bins=200, range=(0, np.max(change_mag)))\n",
    "ax1.xaxis.set_label_text('Change Magnitude')\n",
    "ax1.set_title('Change Magnitude Histogram')\n",
    "plt.grid()\n",
    "n, bins, patches = ax2.hist(change_mag.flatten(), bins=200, range=(0, np.max(change_mag)), cumulative='True', density='True', histtype='step', label='Empirical')\n",
    "ax2.xaxis.set_label_text('Change Magnitude')\n",
    "ax2.set_title('Change Magnitude CDF')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">Now we threshold at 15% to identify change candidate pixels:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precentile = 0.85\n",
    "out_indicies = np.where(n>precentile)\n",
    "threshold_index = np.min(out_indicies)\n",
    "threshold = bins[threshold_index]\n",
    "print('At the {}% percentile, the threshold value is {:2.2f}'.format(precentile*100, threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">Using this threshold, we can <b>visualize our change candidate areas:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_mag_mask = change_mag < threshold\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Change Candidate Areas (black)')\n",
    "_ = plt.imshow(change_mag_mask, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping to Prepare for Change Point Selection:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">As the <b><u>Fifth Step</u></b> of the cummulative sums approach, we can now perform bootstrapping over the candidate pixels. The workflow is as follows:\n",
    "<ul>\n",
    "    <li>Filter our residuals to the change candidate pixels</li>\n",
    "    <li>Perform bootstrapping over candidate pixels</li>\n",
    "</ul>\n",
    "For efficient computing we permutate the index of the time axis.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_mask = np.broadcast_to(change_mag_mask , residuals.shape)\n",
    "residuals_masked = np.ma.array(residuals, mask=residuals_mask)\n",
    "del residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">On the masked time series stack of residuals, we can re-compute the cumulative sums:\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summation_masked = np.ma.cumsum(residuals_masked, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Plot the masked Smax, Smin, and change magnitude:</b>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summation_masked_max = np.ma.max(summation_masked, axis=0)\n",
    "summation_masked_min = np.ma.min(summation_masked, axis=0)\n",
    "change_mag_masked = summation_masked_max - summation_masked_min\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "vmin = summation_masked_min.min()\n",
    "vmax = summation_masked_max.max()\n",
    "masked_sum_max_plot = ax[0].imshow(summation_masked_max, vmin=vmin, vmax=vmax, cmap='RdBu')\n",
    "ax[0].set_title('Masked $S_{max}$')\n",
    "ax[1].imshow(summation_masked_min, vmin=vmin, vmax=vmax, cmap='RdBu')\n",
    "ax[1].set_title('Masked $S_{min}$')\n",
    "ax[2].imshow(change_mag_masked, vmin=vmin, vmax=vmax, cmap='RdBu')\n",
    "ax[2].set_title('Masked Change Magnitude')\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.02, 0.7])\n",
    "cbar = fig.colorbar(masked_sum_max_plot, cax=cbar_ax)\n",
    "_ = cbar.ax.set_xlabel('dB', fontsize='12')\n",
    "del summation_masked_max\n",
    "del summation_masked_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">Now let's perform <b>bootstrapping</b>:\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = np.random.permutation(residuals_masked.shape[0])\n",
    "residuals_random = residuals_masked[random_index,:,:]\n",
    "del random_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bootstraps = 100  # bootstrap sample size\n",
    "\n",
    "# to keep track of the maxium Sdiff of the bootstrapped sample:\n",
    "change_mag_random_max = np.ma.copy(change_mag_masked) \n",
    "change_mag_random_max[~change_mag_random_max.mask]=0\n",
    "# to compute the Sdiff sums of the bootstrapped sample:\n",
    "change_mag_random_sum = np.ma.copy(change_mag_masked) \n",
    "change_mag_random_sum[~change_mag_random_max.mask]=0\n",
    "# to keep track of the count of the bootstrapped sample\n",
    "n_change_mag_gt_change_mag_random = np.ma.copy(change_mag_masked) \n",
    "n_change_mag_gt_change_mag_random[~n_change_mag_gt_change_mag_random.mask]=0\n",
    "print(\"Running Bootstrapping for %4.1f iterations ...\" % (n_bootstraps))\n",
    "for i in range(n_bootstraps):\n",
    "    # For efficiency, we shuffle the time axis index and use that \n",
    "    #to randomize the masked array\n",
    "    random_index = np.random.permutation(residuals_masked.shape[0])\n",
    "    # Randomize the time step of the residuals\n",
    "    residuals_random = residuals_masked[random_index,:,:] \n",
    "    del random_index\n",
    "    summation_random = np.ma.cumsum(residuals_random, axis=0)\n",
    "    summation_random_max = np.ma.max(summation_random, axis=0)\n",
    "    summation_random_min = np.ma.min(summation_random, axis=0)\n",
    "    change_mag_random = summation_random_max - summation_random_min\n",
    "    del summation_random_max\n",
    "    del summation_random_min\n",
    "    change_mag_random_sum += change_mag_random\n",
    "    change_mag_random_max[np.ma.greater(change_mag_random, change_mag_random_max)] = \\\n",
    "    change_mag_random[np.ma.greater(change_mag_random, change_mag_random_max)]\n",
    "    n_change_mag_gt_change_mag_random[np.ma.greater(change_mag_masked, change_mag_random)] += 1\n",
    "    if ((i+1)/n_bootstraps*100)%10 == 0:\n",
    "        print(\"\\r%4.1f%% completed\" % ((i+1)/n_bootstraps*100), end='\\r', flush=True)\n",
    "print(f\"Bootstrapping Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Confidence Metrics and Select Final Change Points:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">Now as the <b><u>Sixth and Last Step</u></b> of the cummulative sums approach we can select the final change points. For that, we first <b>compute for all pixels the confidence level $CL$, the change point significance metric $CP_{significance}$ and the product of the two as our confidence metric for identified change points:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_level = n_change_mag_gt_change_mag_random / n_bootstraps\n",
    "change_point_significance = 1.- (change_mag_random_sum / n_bootstraps)/change_mag \n",
    "#Plot\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "a = ax[0].imshow(confidence_level*100)\n",
    "cbar0 = fig.colorbar(a, ax=ax[0])\n",
    "_ = cbar0.ax.set_xlabel('%', fontsize='12')\n",
    "ax[0].set_title('Confidence Level %')\n",
    "a = ax[1].imshow(change_point_significance)\n",
    "_ = fig.colorbar(a, ax=ax[1])\n",
    "ax[1].set_title('Significance')\n",
    "a = ax[2].imshow(confidence_level*change_point_significance)\n",
    "_ = fig.colorbar(a, ax=ax[2])\n",
    "_ = ax[2].set_title('CL x S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">Now we can <b>set a change point threshold</b> to identify most likely change pixels in our map of change candidates:\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_point_threshold = 0.37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Plot the detected change pixels based on the change_point_threshold.</b> Selected final change points are show in cyan color.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plt.title('Detected Change Pixels based on Threshold %2.2f' % (change_point_threshold))\n",
    "a = ax.imshow(confidence_level*change_point_significance < change_point_threshold, cmap='cool')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive Timing of Change for Each Change Pixel:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">Our last step in the identification of the change points is to extract the timing of the change. We will produce a raster layer that shows the band number of this first date after a change was detected. We will make use of the numpy indexing scheme. First, we create a combined mask of the first threshold and the identified change points after the bootstrapping. For this we use the numpy \"mask_or\" operation.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a mask of our change points from the new threhold and the previous mask\n",
    "change_point_mask = np.ma.mask_or(confidence_level*change_point_significance < change_point_threshold, confidence_level.mask)\n",
    "#change_point_mask = np.ma.mask_or(confidence_level < change_point_threshold, confidence_level.mask)\n",
    "# Broadcast the mask to the shape of the masked S curves\n",
    "change_point_mask2 = np.broadcast_to(change_point_mask, summation_masked.shape)\n",
    "del change_point_mask\n",
    "# Make a numpy masked array with this mask\n",
    "change_point_raster = np.ma.array(summation_masked.data, mask=change_point_mask2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">To retrieve the dates of the change points we find the band indices in the time series along the time axis where the maximum of the cumulative sums was located. Numpy offers the \"argmax\" function for this purpose.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_point_index = np.ma.argmax(change_point_raster, axis=0)\n",
    "change_indices = list(np.unique(change_point_index))\n",
    "change_indices.remove(0)\n",
    "# Look up the dates from the indices to get the change dates\n",
    "all_dates = time_index\n",
    "change_dates = [str(all_dates[x].date()) for x in change_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">Lastly, we <b>plot the change dates by showing the $CP_{index}$ raster and label the change dates:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticks = change_indices\n",
    "ticklabels = change_dates\n",
    "\n",
    "cmap = plt.cm.get_cmap('jet', ticks[-1])\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "cax = ax.imshow(change_point_index, interpolation='nearest', cmap=cmap)\n",
    "# fig.subplots_adjust(right=0.8)\n",
    "# cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "# fig.colorbar(p,cax=cbar_ax)\n",
    "\n",
    "ax.set_title('Dates of Change')\n",
    "# cbar = fig.colorbar(cax,ticks=ticks)\n",
    "cbar = fig.colorbar(cax, ticks=ticks, orientation='horizontal')\n",
    "_ = cbar.ax.set_xticklabels(ticklabels, size=10, rotation=45, ha='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>EXERCISE</u>:  </font>Analyze the Change Date Image</b>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\">Look at the \"Dates of Change\" image above. What do the different colors show? What does it tell you about the progression of the deforestation activity? Do the colors make sense to you in context of the deforestation activity?</font>\n",
    "</div>\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Version Log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"2\"> <i>Exercise4B-SARTimeSeriesChangeDetection.ipynb - Version 1.0.2 - 10/02/2020\n",
    "\n",
    "Recent Changes:\n",
    "- Cleaned up imports\n",
    "- Replaced some asf_notebook.py functions with built-ins\n",
    "- Some updates to streamline the notebook.\n",
    "</i></font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
