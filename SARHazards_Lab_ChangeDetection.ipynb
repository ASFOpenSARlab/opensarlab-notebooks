{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"NotebookAddons/blackboard-banner.jpg\" width=\"100%\" />\n",
    "<font face=\"Calibri\">\n",
    "<br>\n",
    "<font size=\"5\"> <b>SAR Time Series Change Detection over Ecosystems and Deforestation Sites </b> </font>\n",
    "\n",
    "<br>\n",
    "<font size=\"4\"> <b> Franz J Meyer; University of Alaska Fairbanks & Josef Kellndorfer, <a href=\"http://earthbigdata.com/\" target=\"_blank\">Earth Big Data, LLC</a> </b> <br>\n",
    "<img style=\"padding: 7px\" src=\"NotebookAddons/UAFLogo_A_647.png\" width=\"170\" align=\"right\"/>\n",
    "</font>\n",
    "\n",
    "<font size=\"3\"> This notebook applies Change Point Detection on a deep multi-temporal SAR image data stack acquired by Sentinel-1. Specifically, the lab applies the method of Cummulative Sums to perform change detection on a 47-image deep VH-polarized C-band SAR data stack over Madre de Dios in Peru to analyze time series signatures of vegetation covers, water bodies, and areas affected by deforestation.\n",
    "\n",
    "<b>In this notebook we introduce the following data analysis concepts:</b>\n",
    "\n",
    "- Performing Cummulative Sums change detection on an actual data set\n",
    "- Explaining of all steps of the change detection workflow\n",
    "- Identification of change dates for each identified change pixel\n",
    "</font>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"5\" color='rgba(200,0,0,0.2)'> <b>Important Notes about Binder</b> </font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"> <b>The Binder server will automatically shutdown when left idle for more than 10 minutes. Your notebooks edits will be lost when this happens. You will need to relaunch the binder to continue working in a fresh copy of the notebook.</b></font>\n",
    "    <br><br>\n",
    "    <font face=\"Calibri\" size=\"4\"><b>How to Save your Notebook Edits</b></font>\n",
    "        <br><br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>The Easy Way</b>\n",
    "    <br>\n",
    "Click on the Jupyter logo at the top left of the screen to access the file manager. Download the notebook, then upload and run it the next time you restart the server.\n",
    "    <br><br>\n",
    "<b>The Better, More Complicated Way</b>\n",
    "    <br>\n",
    "This solution requires some knowledge of git. Fork the <a href=\"https://github.com/asfadmin/asf-jupyter-notebooks\" target=\"_blank\">public repository</a> and update the url for the Binder launch button to the url of your fork. The url to edit can be found in the first line of the README.md file for this branch. Once you have your own fork, push any notebook changes to it prior to shutting down the server or allowing it to time out.  </font>\n",
    "<br><br>\n",
    "</font>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\">\n",
    "\n",
    "<font size=\"5\"> <b> 0. Importing Relevant Python Packages </b> </font>\n",
    "\n",
    "<font size=\"3\">In this notebook we will use the following scientific libraries:\n",
    "<ol type=\"1\">\n",
    "    <li> <b><a href=\"https://pandas.pydata.org/\" target=\"_blank\">Pandas</a></b> is a Python library that provides high-level data structures and a vast variety of tools for analysis. The great feature of this package is the ability to translate rather complex operations with data into one or two commands. Pandas contains many built-in methods for filtering and combining data, as well as the time-series functionality. </li>\n",
    "    <li> <b><a href=\"https://www.gdal.org/\" target=\"_blank\">GDAL</a></b> is a software library for reading and writing raster and vector geospatial data formats. It includes a collection of programs tailored for geospatial data processing. Most modern GIS systems (such as ArcGIS or QGIS) use GDAL in the background.</li>\n",
    "    <li> <b><a href=\"http://www.numpy.org/\" target=\"_blank\">NumPy</a></b> is one of the principal packages for scientific applications of Python. It is intended for processing large multidimensional arrays and matrices, and an extensive collection of high-level mathematical functions and implemented methods makes it possible to perform various operations with these objects. </li>\n",
    "    <li> <b><a href=\"https://matplotlib.org/index.html\" target=\"_blank\">Matplotlib</a></b> is a low-level library for creating two-dimensional diagrams and graphs. With its help, you can build diverse charts, from histograms and scatterplots to non-Cartesian coordinates graphs. Moreover, many popular plotting libraries are designed to work in conjunction with matplotlib. </li>\n",
    "\n",
    "</font>\n",
    "<br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>Our first step is to import them:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json # for loads\n",
    "\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "from asf_notebook_ChangeDetection import new_directory\n",
    "from asf_notebook_ChangeDetection import path_exists\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\">\n",
    "\n",
    "<font size=\"5\"> <b> 1. Load Your Prepared Data Stack Into the Notebook </b> </font> <img src=\"NotebookAddons/Deforest-MadreDeDios.jpg\" width=\"350\" style=\"padding:5px;\" align=\"right\" />\n",
    "\n",
    "<font size=\"3\"> This notebook will be using a 47-image deep VH-polarized C-band SAR data stack over Madre de Dios in Peru to analyze time series signatures of vegetation covers, water bodies, and areas affected by deforestation. The C-band data were acquired by ESA's Sentinel-1 SAR sensor constellation and are available to you through the services of the <a href=\"https://www.asf.alaska.edu/\" target=\"_blank\">Alaska Satellite Facility</a>. \n",
    "\n",
    "The site in question is interesting as it has experienced extensive logging over the last 10 years (see image to the right; <a href=\"https://blog.globalforestwatch.org/\" target=\"_blank\">Monitoring of the Andean Amazon Project</a>). Since the 1980s, people have been clearing forests in this area for farming, cattle ranching, logging, and (recently) gold mining. Creating RGB color composites is an easy way to visualize ongoing changes in the landscape.\n",
    "</font></font>\n",
    "<br><br>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"><b>Begin by writing a function to retrieve and the absolute paths to each of our tiffs:</b>\n",
    "</font> \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tiff_paths(paths):\n",
    "    tiff_paths = !ls $paths | sort -t_ -k5,5\n",
    "    return tiff_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Enter the path to the directory holding your tiffs:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"MadreDeDios_binder\"\n",
    "path = path = f\"./{name}\"\n",
    "new_directory(path)\n",
    "os.chdir(path)\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "time_series_path = f\"s3://asf-jupyter-data/{name}.zip\"\n",
    "time_series = os.path.basename(time_series_path)\n",
    "!aws --no-sign-request --region us-east-1 s3 cp $time_series_path $time_series\n",
    "!unzip -o {name}.zip\n",
    "!rm {name}.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Write a function to extract the tiff dates from a wildcard path:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(paths):\n",
    "    dates = []\n",
    "    pths = glob.glob(paths)\n",
    "    for p in pths:\n",
    "        filename = os.path.basename(p).split('_')\n",
    "        for chunk in filename:\n",
    "            if len(chunk) == 15 and 'T' in chunk:\n",
    "                date = chunk.split('T')[0]\n",
    "                dates.append(date)\n",
    "                break\n",
    "            elif len(chunk) == 8:\n",
    "                try:\n",
    "                    int(chunk)\n",
    "                    dates.append(chunk)\n",
    "                    break\n",
    "                except ValueError:\n",
    "                    continue              \n",
    "    dates.sort()\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Call get_dates() to collect the product acquisition dates:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_paths = f\"tiffs/*VH.tif*\"\n",
    "dates = get_dates(tiff_paths)\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Gather the upper-left and lower-right corner coordinates</b> as well as the <b>UTM zone</b> associated with your data stack.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiffies = get_tiff_paths(tiff_paths)\n",
    "coords = [[], []]\n",
    "info = (gdal.Info(tiffies[0], options = ['-json']))\n",
    "coords[0] = (json.loads(info))['cornerCoordinates']['upperLeft']\n",
    "coords[1] = (json.loads(info))['cornerCoordinates']['lowerRight']\n",
    "print(coords)\n",
    "utm = json.loads(info)['coordinateSystem']['wkt'].split('ID')[-1].split(',')[1][0:-2]\n",
    "print(f\"UTM Zone: {utm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which gdal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"3\"> Now we stack up the data by creating a virtual raster table with links to all subset data files: </font>\n",
    "<br><br>\n",
    "<font size=\"3\"><b>Create the virtual raster table for the subset GeoTiffs:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdalbuildvrt -separate raster_stack.vrt $tiff_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\">\n",
    "\n",
    "<font size=\"5\"> <b> 3. Now You Can Work With Your Data </b> </font> \n",
    "\n",
    "<font size=\"3\"> Now you are ready to perform time series change detection on your data stack.\n",
    "</font> \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 3.1 Define Data Directory and Path to VRT </b> </font> \n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>Create a variable containing the VRT filename:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"raster_stack.vrt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create an index of timedelta64 data with Pandas:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some indices for plotting\n",
    "time_index = pd.DatetimeIndex(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Print the bands and dates for all images in the virtual raster table (VRT):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "j = 1\n",
    "print(f\"Bands and dates for {image_file}\")\n",
    "for i in time_index:\n",
    "    print(\"{:4d} {}\".format(j, i.date()), end=' ')\n",
    "    j += 1\n",
    "    if j%5 == 1: print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 3.2 Open Your Data Stack with gdal </b> </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = gdal.Open(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Print the bands, pixels, and lines:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of  bands: {img.RasterCount}\")\n",
    "print(f\"Number of pixels: {img.RasterXSize}\")\n",
    "print(f\"Number of  lines: {img.RasterYSize}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 3.3 Create a masked raster stack:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_stack = img.ReadAsArray()\n",
    "raster_stack_masked = np.ma.masked_where(raster_stack==0, raster_stack)\n",
    "del raster_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<font face=\"Calibri\" size=\"5\"> <b> 4. Cumulative Sum-based Change Detection Across an Entire Image</b> </font> \n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Using numpy arrays we can apply the concept of **cumulative sum change detection** analysis effectively on the entire image stack. We take advantage of array slicing and axis-based computing in numpy. **Axis 0 is the time domain** in our raster stacks.\n",
    "    \n",
    "<hr>\n",
    "<font size=\"4\"><b>4.1 Create our time series stack</b></font> \n",
    "<br><br>\n",
    "<font size=\"3\"><b>Calculate the dB scale:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = 10.*np.log10(raster_stack_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.figure(figsize=(12, 8))\n",
    "band_number = 0\n",
    "vmin = np.percentile(db[band_number], 5)\n",
    "vmax = np.percentile(db[band_number], 95)\n",
    "plt.title('Band  {} {}'.format(band_number+1, time_index[band_number].date()))\n",
    "plt.imshow(db[0], cmap='gray', vmin=vmin, vmax=vmax)\n",
    "cbar = plt.colorbar()\n",
    "_ = cbar.ax.set_xlabel('dB', fontsize='12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 4.2 Calculate Mean Across Time Series to Prepare for Calculation of Cummulative Sum $S$:</b> </font> \n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>Write a function to convert our plots into GeoTiffs:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geotiff_from_plot(source_image, out_filename, extent, utm, cmap=None, vmin=None, vmax=None, interpolation=None, dpi=300):\n",
    "    assert \".\" not in out_filename, 'Error: Do not include the file extension in out_filename'\n",
    "    assert type(extent) == list and len(extent) == 2 and len(extent[0]) == 2 and len(\n",
    "        extent[1]) == 2, 'Error: extent must be a list in the form [[upper_left_x, upper_left_y], [lower_right_x, lower_right_y]]'\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.axis('off')\n",
    "    plt.imshow(source_image, cmap=cmap, vmin=vmin, vmax=vmax, interpolation=interpolation)\n",
    "    temp = f\"{out_filename}_temp.png\"\n",
    "    plt.savefig(temp, dpi=dpi, transparent='true', bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "    cmd = f\"gdal_translate -of Gtiff -a_ullr {extent[0][0]} {extent[0][1]} {extent[1][0]} {extent[1][1]} -a_srs EPSG:{utm} {temp} {out_filename}.tiff\"\n",
    "    !{cmd}\n",
    "    try:\n",
    "        os.remove(temp)\n",
    "    except FileNotFoundError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Plot the time-series mean and save as a png (time_series_mean.png):</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_mean = np.mean(db, axis=0)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(db_mean, cmap='gray')\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_xlabel('dB', fontsize='12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Calculate the residuals and plot residuals[0]. Save it as a png (residuals.png):</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = db - db_mean\n",
    "vmin = np.percentile(residuals.flatten(), 3)\n",
    "vmax = np.percentile(residuals.flatten(), 97)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(residuals[0], vmin=vmin, vmax=vmax, cmap='RdBu')\n",
    "plt.title('Residuals for Band  {} {}'.format(band_number+1, time_index[band_number].date()))\n",
    "cbar = plt.colorbar()\n",
    "_ = cbar.ax.set_xlabel('dB', fontsize='12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<font face=\"Calibri\" size=\"4\"><b> 4.3 Calculate Cummulative Sum $S$ as well as Change Magnitude $S_{diff}$:</b></font> \n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>Plot Smin, Smax, and the change magnitude and save a png of the plots (Smin_Smax_Sdiff.png):</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summation = np.cumsum(residuals, axis=0)\n",
    "summation_max = np.max(summation, axis=0)\n",
    "summation_min = np.min(summation, axis=0)\n",
    "change_mag = summation_max - summation_min\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "vmin = np.percentile(summation_min.flatten(), 3)\n",
    "vmax = np.percentile(summation_max.flatten(), 97)\n",
    "max_plot = ax[0].imshow(summation_max, vmin=vmin, vmax=vmax, cmap='RdBu')\n",
    "ax[0].set_title('$S_{max}$')\n",
    "ax[1].imshow(summation_min, vmin=vmin, vmax=vmax, cmap='RdBu')\n",
    "ax[1].set_title('$S_{min}$')\n",
    "ax[2].imshow(change_mag, vmin=vmin, vmax=vmax, cmap='RdBu')\n",
    "ax[2].set_title('Change Magnitude')\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.02, 0.7])\n",
    "cbar = fig.colorbar(max_plot, cax=cbar_ax)\n",
    "_ = cbar.ax.set_xlabel('dB', fontsize='12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 4.4 Mask $S_{diff}$ With a-priori Threshold To Idenfity Change Candidates:</b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\">To identified change candidate pixels, we can threshold $S_{diff}$ to reduce computation of the bootstrapping. For land cover change, we would not expect more than 5-10% change pixels in a landscape. So, if the test region is reasonably large, setting a threshold for expected change to 10% is appropriate. In our example, we'll start out with a very conservative threshold of 50%.\n",
    "<br><br>\n",
    "<b>Plot and tsave the histogram and CDF for the change magnitude (change_mag_histogram_CDF.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "fig = plt.figure(figsize=(14, 6)) # Initialize figure with a size\n",
    "ax1 = fig.add_subplot(121)  # 121 determines: 2 rows, 2 plots, first plot\n",
    "ax2 = fig.add_subplot(122)\n",
    "# Second plot: Histogram\n",
    "# IMPORTANT: To get a histogram, we first need to *flatten* \n",
    "# the two-dimensional image into a one-dimensional vector.\n",
    "histogram = ax1.hist(change_mag.flatten(), bins=200, range=(0, np.max(change_mag)))\n",
    "ax1.xaxis.set_label_text('Change Magnitude')\n",
    "ax1.set_title('Change Magnitude Histogram')\n",
    "plt.grid()\n",
    "n, bins, patches = ax2.hist(change_mag.flatten(), bins=200, range=(0, np.max(change_mag)), cumulative='True', density='True', histtype='step', label='Empirical')\n",
    "ax2.xaxis.set_label_text('Change Magnitude')\n",
    "ax2.set_title('Change Magnitude CDF')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precentile = 0.85\n",
    "out_indicies = np.where(n>precentile)\n",
    "threshold_index = np.min(out_indicies)\n",
    "threshold = bins[threshold_index]\n",
    "print('At the {}% percentile, the threshold value is {:2.2f}'.format(precentile*100, threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">Using this threshold, we can <b>visualize our change candidate areas and save them as a png (change_candidate.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_mag_mask = change_mag < threshold\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Change Candidate Areas (black)')\n",
    "_ = plt.imshow(change_mag_mask, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 4.5 Bootstrapping to Prepare for Change Point Selection:</b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\">We can now perform bootstrapping over the candidate pixels. The workflow is as follows:\n",
    "<ul>\n",
    "    <li>Filter our residuals to the change candidate pixels</li>\n",
    "    <li>Perform bootstrapping over candidate pixels</li>\n",
    "</ul>\n",
    "For efficient computing we permutate the index of the time axis.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_mask = np.broadcast_to(change_mag_mask , residuals.shape)\n",
    "residuals_masked = np.ma.array(residuals, mask=residuals_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">On the masked time series stack of residuals, we can re-compute the cumulative sums:\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summation_masked = np.ma.cumsum(residuals_masked, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Plot the masked Smax, Smin, and change magnitude. Save them as a png (masked_Smax_Smin_Sdiff.png):</b>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summation_masked_max = np.ma.max(summation_masked, axis=0)\n",
    "summation_masked_min = np.ma.min(summation_masked, axis=0)\n",
    "change_mag_masked = summation_masked_max - summation_masked_min\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "vmin = summation_masked_min.min()\n",
    "vmax = summation_masked_max.max()\n",
    "masked_sum_max_plot = ax[0].imshow(summation_masked_max, vmin=vmin, vmax=vmax, cmap='RdBu')\n",
    "ax[0].set_title('Masked $S_{max}$')\n",
    "ax[1].imshow(summation_masked_min, vmin=vmin, vmax=vmax, cmap='RdBu')\n",
    "ax[1].set_title('Masked $S_{min}$')\n",
    "ax[2].imshow(change_mag_masked, vmin=vmin, vmax=vmax, cmap='RdBu')\n",
    "ax[2].set_title('Masked Change Magnitude')\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.02, 0.7])\n",
    "cbar = fig.colorbar(masked_sum_max_plot, cax=cbar_ax)\n",
    "_ = cbar.ax.set_xlabel('dB', fontsize='12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">Now let's perform <b>bootstrapping</b>:\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = np.random.permutation(residuals_masked.shape[0])\n",
    "residuals_random = residuals_masked[random_index,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bootstraps = 100  # bootstrap sample size\n",
    "\n",
    "# to keep track of the maxium Sdiff of the bootstrapped sample:\n",
    "change_mag_random_max = np.ma.copy(change_mag_masked) \n",
    "change_mag_random_max[~change_mag_random_max.mask]=0\n",
    "# to compute the Sdiff sums of the bootstrapped sample:\n",
    "change_mag_random_sum = np.ma.copy(change_mag_masked) \n",
    "change_mag_random_sum[~change_mag_random_max.mask]=0\n",
    "# to keep track of the count of the bootstrapped sample\n",
    "n_change_mag_gt_change_mag_random = np.ma.copy(change_mag_masked) \n",
    "n_change_mag_gt_change_mag_random[~n_change_mag_gt_change_mag_random.mask]=0\n",
    "print(\"Running Bootstrapping for %4.1f iterations ...\" % (n_bootstraps))\n",
    "for i in range(n_bootstraps):\n",
    "    # For efficiency, we shuffle the time axis index and use that \n",
    "    #to randomize the masked array\n",
    "    random_index = np.random.permutation(residuals_masked.shape[0])\n",
    "    # Randomize the time step of the residuals\n",
    "    residuals_random = residuals_masked[random_index,:,:]  \n",
    "    summation_random = np.ma.cumsum(residuals_random, axis=0)\n",
    "    summation_random_max = np.ma.max(summation_random, axis=0)\n",
    "    summation_random_min = np.ma.min(summation_random, axis=0)\n",
    "    change_mag_random = summation_random_max - summation_random_min\n",
    "    change_mag_random_sum += change_mag_random\n",
    "    change_mag_random_max[np.ma.greater(change_mag_random, change_mag_random_max)] = \\\n",
    "    change_mag_random[np.ma.greater(change_mag_random, change_mag_random_max)]\n",
    "    n_change_mag_gt_change_mag_random[np.ma.greater(change_mag_masked, change_mag_random)] += 1\n",
    "    if ((i+1)/n_bootstraps*100)%10 == 0:\n",
    "        print(\"\\r%4.1f%% completed\" % ((i+1)/n_bootstraps*100), end='\\r', flush=True)\n",
    "print(f\"Bootstrapping Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 4.6 Extract Confidence Metrics and Select Final Change Points:</b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\">We first <b>compute for all pixels the confidence level $CL$, the change point significance metric $CP_{significance}$ and the product of the two as our confidence metric for identified change points. Plot the results and save them as a png (confidenceLevel_CPSignificance.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_level = n_change_mag_gt_change_mag_random / n_bootstraps\n",
    "change_point_significance = 1.- (change_mag_random_sum / n_bootstraps)/change_mag \n",
    "#Plot\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "a = ax[0].imshow(confidence_level*100)\n",
    "cbar0 = fig.colorbar(a, ax=ax[0])\n",
    "_ = cbar0.ax.set_xlabel('%', fontsize='12')\n",
    "ax[0].set_title('Confidence Level %')\n",
    "a = ax[1].imshow(change_point_significance)\n",
    "_ = fig.colorbar(a, ax=ax[1])\n",
    "ax[1].set_title('Significance')\n",
    "a = ax[2].imshow(confidence_level*change_point_significance)\n",
    "_ = fig.colorbar(a, ax=ax[2])\n",
    "_ = ax[2].set_title('CL x S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">Now we can <b>set a change point threshold</b> to identify most likely change pixels in our map of change candidates:\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_point_threshold = 0.53"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Plot the detected change pixels based on the change_point_threshold and save it as a png (detected_change_pixels.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plt.title('Detected Change Pixels based on Threshold %2.2f' % (change_point_threshold))\n",
    "a = ax.imshow(confidence_level*change_point_significance < change_point_threshold, cmap='cool')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 4.7 Derive Timing of Change for Each Change Pixel:</b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\">Our last step in the identification of the change points is to extract the timing of the change. We will produce a raster layer that shows the band number of this first date after a change was detected. We will make use of the numpy indexing scheme. First, we create a combined mask of the first threshold and the identified change points after the bootstrapping. For this we use the numpy \"mask_or\" operation.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a mask of our change points from the new threhold and the previous mask\n",
    "change_point_mask = np.ma.mask_or(confidence_level*change_point_significance < change_point_threshold, confidence_level.mask)\n",
    "#change_point_mask = np.ma.mask_or(confidence_level < change_point_threshold, confidence_level.mask)\n",
    "# Broadcast the mask to the shape of the masked S curves\n",
    "change_point_mask2 = np.broadcast_to(change_point_mask, summation_masked.shape)\n",
    "# Make a numpy masked array with this mask\n",
    "change_point_raster = np.ma.array(summation_masked.data, mask=change_point_mask2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">To retrieve the dates of the change points we find the band indices in the time series along the time axis where the maximum of the cumulative sums was located. Numpy offers the \"argmax\" function for this purpose.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_point_index = np.ma.argmax(change_point_raster, axis=0)\n",
    "change_indices = list(np.unique(change_point_index))\n",
    "change_indices.remove(0)\n",
    "# Look up the dates from the indices to get the change dates\n",
    "all_dates = time_index\n",
    "change_dates = [str(all_dates[x].date()) for x in change_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">Lastly, we <b>plot the change dates by showing the $CP_{index}$ raster and label the change dates. Save the plot as a png (change_dates.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ticks = change_indices\n",
    "ticklabels = change_dates\n",
    "\n",
    "cmap = plt.cm.get_cmap('jet', ticks[-1])\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "cax = ax.imshow(change_point_index, interpolation='nearest', cmap=cmap)\n",
    "# fig.subplots_adjust(right=0.8)\n",
    "# cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "# fig.colorbar(p,cax=cbar_ax)\n",
    "\n",
    "ax.set_title('Dates of Change')\n",
    "# cbar = fig.colorbar(cax,ticks=ticks)\n",
    "cbar = fig.colorbar(cax, ticks=ticks, orientation='horizontal')\n",
    "_ = cbar.ax.set_xticklabels(ticklabels, size=10, rotation=45, ha='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"2\"> <i>Exercise4B-SARTimeSeriesChangeDetection.ipynb - Version 1.0.2 - 10/02/2020\n",
    "\n",
    "Recent Changes:\n",
    "- Cleaned up imports\n",
    "- Replaced some asf_notebook.py functions with built-ins\n",
    "- Some updates to streamline the notebook.\n",
    "</i></font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
