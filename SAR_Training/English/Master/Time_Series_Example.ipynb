{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"NotebookAddons/blackboard-banner.png\" width=\"100%\" />\n",
    "<font face=\"Calibri\">\n",
    "<br>\n",
    "<font size=\"5\"> <b>Exploring SAR Data and SAR Time Series Analysis with Supplied Data</b></font>\n",
    "\n",
    "<br>\n",
    "<font size=\"4\"> <b> Franz J Meyer; University of Alaska Fairbanks & Josef Kellndorfer, <a href=\"http://earthbigdata.com/\" target=\"_blank\">Earth Big Data, LLC</a> </b> <br>\n",
    "<img src=\"NotebookAddons/UAFLogo_A_647.png\" width=\"170\" align=\"right\" /></font>\n",
    "\n",
    "<font size=\"3\">This notebook introduces you to the analysis of deep multi-temporal SAR image data stacks in the framework of *Jupyter Notebooks*. The Jupyter Notebook environment is easy to launch in any web browser for interactive data exploration with provided or new training data. Notebooks are comprised of text written in a combination of executable python code and markdown formatting including latex style mathematical equations. Another advantage of Jupyter Notebooks is that they can easily be expanded, changed, and shared with new data sets or newly available time series steps. Therefore, they provide an excellent basis for collaborative and repeatable data analysis. <br>\n",
    "\n",
    "<b>This notebook covers the following data analysis concepts:</b>\n",
    "\n",
    "- How to load time series stacks into Jupyter Notebooks and how to explore image content using basic functions such as mean value calculation and histogram analysis.\n",
    "- How to apply calibration constants to covert initial digital number (DN) data into calibrated radar cross section information.\n",
    "- How to subset images create time series information of calibrated SAR amplitude values.\n",
    "- How to explore the time-series information in SAR data stacks for environmental analysis.\n",
    "</font>\n",
    "\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"5\" color=\"darkred\"> <b>Important Notes about JupyterHub</b> </font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"> <b>Your JupyterHub server will automatically shutdown when left idle for more than 1 hour. Your notebooks will not be lost but you will have to restart their kernels and re-run them from the beginning. You will not be able to seamlessly continue running a partially run notebook.</b> </font>\n",
    "<br><br>\n",
    "<ol type=\"1\">\n",
    "  <li><font color='rgba(200,0,0,0.2)'> <b> Save your notebook with all of its content</b></font> by selecting <i> File / Save and Checkpoint </i> </li>\n",
    "  <li><font color='rgba(200,0,0,0.2)'> <b>To export in Notebook format</b></font>, click on <i>File / Download as / Notebook (.ipynb)</i>  <font color='gray'>--- Downloading your file may take a bit as the Notebook will be about 100MB in size</font></li>\n",
    "  <li><font color='rgba(200,0,0,0.2)'> <b>To export in PDF format</b></font>, click on <i>File / Download as / PDF vs LaTeX (.pdf) </i></li>\n",
    "</ol>\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%javascript\n",
    "var kernel = Jupyter.notebook.kernel;\n",
    "var command = [\"notebookUrl = \",\n",
    "               \"'\", window.location, \"'\" ].join('')\n",
    "kernel.execute(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "\n",
    "user = !echo $JUPYTERHUB_USER\n",
    "env = !echo $CONDA_PREFIX\n",
    "if env[0] == '':\n",
    "    env[0] = 'Python 3 (base)'\n",
    "if env[0] != '/home/jovyan/.local/envs/rtc_analysis':\n",
    "    display(Markdown(f'<text style=color:red><strong>WARNING:</strong></text>'))\n",
    "    display(Markdown(f'<text style=color:red>This notebook should be run using the \"rtc_analysis\" conda environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>It is currently using the \"{env[0].split(\"/\")[-1]}\" environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Select the \"rtc_analysis\" from the \"Change Kernel\" submenu of the \"Kernel\" menu.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>If the \"rtc_analysis\" environment is not present, use <a href=\"{notebookUrl.split(\"/user\")[0]}/user/{user[0]}/notebooks/conda_environments/Create_OSL_Conda_Environments.ipynb\"> Create_OSL_Conda_Environments.ipynb </a> to create it.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Note that you must restart your server after creating a new environment before it is usable by notebooks.</text>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\">\n",
    "\n",
    "<font size=\"5\"> <b> 0. Importing Relevant Python Packages </b> </font>\n",
    "\n",
    "<font size=\"3\">In this notebook we will use the following scientific libraries:\n",
    "\n",
    "<ol type=\"1\">\n",
    "    <li> <b><a href=\"https://pandas.pydata.org/\" target=\"_blank\">Pandas</a></b> is a Python library that provides high-level data structures and a vast variety of tools for analysis. The great feature of this package is the ability to translate rather complex operations with data into one or two commands. Pandas contains many built-in methods for filtering and combining data, as well as the time-series functionality. </li>\n",
    "    <li> <b><a href=\"https://www.gdal.org/\" target=\"_blank\">GDAL</a></b> is a software library for reading and writing raster and vector geospatial data formats. It includes a collection of programs tailored for geospatial data processing. Most modern GIS systems (such as ArcGIS or QGIS) use GDAL in the background.</li>\n",
    "    <li> <b><a href=\"http://www.numpy.org/\" target=\"_blank\">NumPy</a></b> is one of the principal packages for scientific applications of Python. It is intended for processing large multidimensional arrays and matrices, and an extensive collection of high-level mathematical functions and implemented methods makes it possible to perform various operations with these objects. </li>\n",
    "    <li> <b><a href=\"https://matplotlib.org/index.html\" target=\"_blank\">Matplotlib</a></b> is a low-level library for creating two-dimensional diagrams and graphs. With its help, you can build diverse charts, from histograms and scatterplots to non-Cartesian coordinates graphs. Moreover, many popular plotting libraries are designed to work in conjunction with matplotlib. </li>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd # for DatetimeIndex\n",
    "from osgeo import gdal # for GetRasterBand, Open, ReadAsArray\n",
    "import numpy as np #for log10, mean, percentile, power\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plb # for add_patch, add_subplot, figure, hist, imshow, set_title, xaxis,_label, text \n",
    "import matplotlib.pyplot as plt # for add_subplot, axis, figure, imshow, legend, plot, set_axis_off, set_data,\n",
    "                                # set_title, set_xlabel, set_ylabel, set_ylim, subplots, title, twinx\n",
    "import matplotlib.patches as patches  # for Rectangle\n",
    "import matplotlib.animation as an # for FuncAnimation\n",
    "from matplotlib import rc \n",
    "\n",
    "import asf_notebook as asfn\n",
    "asfn.jupytertheme_matplotlib_format()\n",
    "\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\">\n",
    "\n",
    "<font size=\"5\"> <b> 1. Load Data Stack</b> </font> <img src=\"NotebookAddons/Nepalclimate.jpeg\" width=\"400\" align=\"right\" /> \n",
    "\n",
    "<font size=\"3\"> This notebook will be using a 70-image deep L-band SAR data stack over Nepal for a first experience with time series processing. The L-band data were acquired by the ALOS PALSAR sensor and are available to us through the services of the <a href=\"https://www.asf.alaska.edu/\" target=\"_blank\">Alaska Satellite Facility</a>. \n",
    "\n",
    "Nepal is an interesting site for this analysis due to the significant seasonality of precipitation that is characteristic for this region. Nepal is said to have five seasons: spring, summer, monsoon, autumn and winter. Precipitation is low in the winter (November - March) and peaks dramatically in the summer, with top rain rates in July, August, and September (see figure to the right). As SAR is sensitive to changes in soil moisture, these weather patterns have a noticeable impact on the Radar Cross Section ($\\sigma$) time series information. \n",
    "\n",
    "We will analyze the variation of $\\sigma$ values over time and will interpret them in the context of rainfall rates in the imaged area. \n",
    "</font></font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\">Before we get started, let's first <b>create a working directory for this analysis and change into it:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"/home/jovyan/notebooks/SAR_Training/English/Master/data_time_series_example\")\n",
    "\n",
    "if not path.exists():\n",
    "    path.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">We will <b>retrieve the relevant data</b> from an <a href=\"https://aws.amazon.com/\" target=\"_blank\">Amazon Web Service (AWS)</a> cloud storage bucket <b>using the following command</b>:</font></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = 's3://asf-jupyter-data/time_series.zip'\n",
    "time_series_path = path/Path(s3_path).name\n",
    "\n",
    "!aws --region=us-east-1 --no-sign-request s3 cp $s3_path $time_series_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"> Now, let's <b>unzip the file (overwriting previous extractions) and clean up after ourselves:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if time_series_path.exists():\n",
    "    asfn.asf_unzip(str(path), str(time_series_path))\n",
    "    time_series_path.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"> The following lines set path variables needed for data processing. This step is not necessary but it saves a lot of extra typing later.<b> Define variables for the main data directory as well as for the files containing data and image information:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadirectory = path/'time_series/S32644X696260Y3052060sS1-EBD'\n",
    "datefile = datadirectory/'S32644X696260Y3052060sS1_D_vv_0092_mtfil.dates'\n",
    "imagefile = datadirectory/'S32644X696260Y3052060sS1_D_vv_0092_mtfil.vrt'\n",
    "imagefile_cross = datadirectory/'S32644X696260Y3052060sS1_D_vh_0092_mtfil.vrt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<font face=\"Calibri\" size=\"5\"> <b> 2. Switch to the Data Directory: </b></font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls *.vrt #Uncomment this line to see a List of the files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<font face=\"Calibri\" size=\"5\"> <b> 3. Assess Image Acquisition Dates </b> </font> \n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Before we start analyzing the available image data, we want to examine the content of our data stack. <b>First, we read the image acquisition dates for all files in the time series and create a *pandas* date index.</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if datefile.exists():\n",
    "    with open(str(datefile), 'r') as f:\n",
    "        dates = f.readlines()\n",
    "        tindex = pd.DatetimeIndex(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"> From the date index, we <b>make and print a lookup table for band numbers and dates:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if imagefile.exists():\n",
    "    j = 1\n",
    "    print('Bands and dates for', imagefile)\n",
    "    for i in tindex:\n",
    "        print(\"{:4d} {}\".format(j, i.date()),end=' ')\n",
    "        j += 1\n",
    "        if j%5 == 1: print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<font face=\"Calibri\" size=\"5\"> <b> 4. Explore the Available Image Data </b> </font> \n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> To <b>open an image file using the gdal.Open() function.</b> This returns a variable (img) that can be used for further interactions with the file: </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if imagefile.exists():\n",
    "    img = gdal.Open(str(imagefile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"> To <b>explore the image (number of bands, pixels, lines),</b> you can use several functions associated with the image object (img) created in the last code cell: </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.RasterCount) # Number of Bands\n",
    "print(img.RasterXSize) # Number of Pixels\n",
    "print(img.RasterYSize) # Number of Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 4.1 Reading Data from an Image Band </b> </font> \n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> <b>To access any band in the image</b>, use GDAL's *GetRasterBand(x)* function. Replace the band_num value with the number of the band you wish to access.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_num = 70 \n",
    "band = img.GetRasterBand(band_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"> Once a band is seleted, several functions associated with the band are available for further processing, e.g., <i>band.ReadAsArray(xoff=0,yoff=0,xsize=None,ysize=None)</i>\n",
    "\n",
    "<b>Let's read the entire raster layer for the band:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster = band.ReadAsArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 4.2 Extracting Subsets from a Larger Image Frame </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Because of the potentially large data volume when dealing with time series data stacks, it may be prudent to read only a subset of data. \n",
    "\n",
    "Using GDAL's <i>ReadAsArray()</i> function, subsets can be requested by defining pixel offsets and subset size:\n",
    "\n",
    "**img.ReadAsArray(xoff=0, yoff=0, xsize=None, ysize=None)**\n",
    "\n",
    "- <i>xoff, yoff</i> are the offsets from the upper left corner in pixel/line coordinates. \n",
    "- <i>xsize, ysize</i> specify the size of the subset in x-direction (left to right) and y-direction (top to bottom).\n",
    "\n",
    "For example, we can <b>read only a subset of 5x5 pixels with an offset of 5 pixels and 20 lines:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_sub = band.ReadAsArray(5, 20, 50, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"> The result is a two dimensional numpy array in the datatpye the data were stored in. **We can inspect these data in python by typing the array name on the commandline**: </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 4.3 Displaying Bands in the Time Series of SAR Data </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> From the lookup table we know that bands 20 and 27 in the Nepal data stack are from mid February and late August. **Let's take look at these images**. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_1 = img.GetRasterBand(20).ReadAsArray()\n",
    "raster_2 = img.GetRasterBand(27).ReadAsArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"> <b> <i>4.3.1 Write a Plotting Function</i></b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Matplotlib's plotting functions allow for powerful options to display imagery. We are following some standard approaches for setting up figures.\n",
    "First we are looking at a **raster band** and it's associated **histogram**. </font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"> Our function, *show_image()* takes several parameters:\n",
    "    \n",
    "- raster = a numpy two dimensional array \n",
    "- tindex = a panda index array for dates\n",
    "- bandnbr = the band number the corresponds to the raster \n",
    "- vmin = minimim value to display \n",
    "- vmax = maximum value to display\n",
    "- output_filename = name of output file, if saving the plot\n",
    "\n",
    "Preconditions: matplotlib.pyplot must be imported as plb and matplotlib.pyplot must be imported as plt. \n",
    "<br><br>\n",
    "Note: By default, data will be linearly stretched between vmin and vmax.\n",
    "<br><br>\n",
    "<b>We won't use this function in this notebook but it is a useful utility method, which can be copied and pasted for use in other analyses</b>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_histogram(raster, tindex, band_nbr, vmin=None, vmax=None, output_filename=None):\n",
    "    assert 'plb' in globals(), 'Error: matplotlib.pylab must be imported as \"plb\"'\n",
    "    assert 'plt' in globals(), 'Error: matplotlib.pyplot must be imported as \"plt\"'  \n",
    "    \n",
    "    fig = plb.figure(figsize=(16, 8))\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    \n",
    "    # plot image\n",
    "    ax1.imshow(raster, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    ax1.set_title('Image Band {} {}'.format(band_nbr, tindex[band_nbr-1].date()))\n",
    "    vmin = np.percentile(raster, 2) if vmin==None else vmin\n",
    "    vmax = np.percentile(raster, 98) if vmax==None else vmax\n",
    "    ax1.xaxis.set_label_text('Linear stretch Min={} Max={}'.format(vmin, vmax))\n",
    "    \n",
    "    #plot histogram\n",
    "    h = ax2.hist(raster.flatten(), bins=200, range=(0, 10000))\n",
    "    ax2.xaxis.set_label_text('Amplitude (Uncalibrated DN Values)')\n",
    "    ax2.set_title('Histogram Band {} {}'.format(band_nbr, tindex[band_nbr-1].date()))\n",
    "    \n",
    "    if output_filename:\n",
    "        plt.savefig(f'{output_filename}', dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">We won't be calling our new function elsewhere in this notebook,<b> so test it now:</b></b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the last argument to decide where you want to store image. \n",
    "show_image_histogram(raster_1, tindex, 20, vmin=2000, vmax=10000, output_filename=path/f'show_time_series.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<font face=\"Calibri\" size=\"5\"> <b> 5. SAR Time Series Visualization, Animation, and Analysis </b> </font> \n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> This section introduces you to the handling and analysis of SAR time series stacks. A focus will be put on time series visualization, which allow us to inspect time series in more depth. Note that html animations are not exported into the pdf file, but will display interactively. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 5.1 Reading the SAR Time Series Subset </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Let's read an image subset (offset 400, 400 /  size 600, 600) of the entire time series data stack. The data are linearly scaled amplitudes represented as unsigned 16 bit integer.\n",
    "\n",
    "We use the GDAL *ReadAsArray(xoff,yoff,xsize,ysize)* function where *xoff* is the offset in pixels from upper left; *yoff* is the offset in lines from upper left; *xsize* is the number of pixels and *ysize* is the number of lines of the subset.\n",
    "\n",
    "If *ReadAsArray()* is called without any parameters, the entire image data stack is read. \n",
    "\n",
    "Let's first <b>define a subset and make sure it is in the right geographic location</b>. </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the image and read the first raster band\n",
    "band = img.GetRasterBand(1)\n",
    "\n",
    "# Define the subset\n",
    "subset = (400, 400, 600, 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"> Now we are ready to <b>extract this subset from all slices of the data stack</b>. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one band together with the outline of the selected subset to verify its geographic location.\n",
    "raster = band.ReadAsArray()\n",
    "vmin = np.percentile(raster.flatten(), 5)\n",
    "vmax = np.percentile(raster.flatten(), 95)\n",
    "fig = plb.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(raster, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "# plot the subset as rectangle\n",
    "_ = ax.add_patch(patches.Rectangle((subset[0], subset[1]), subset[2], subset[3], fill=False, edgecolor='red'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster0 = band.ReadAsArray(*subset)\n",
    "bandnbr = 0 # Needed for updates\n",
    "rasterstack = img.ReadAsArray(*subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Close img, as it is no longer needed in the notebook:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 5.2 Calibration and Data Conversion between dB and Power Scales </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Focused SAR image data natively come in uncalibrated digital numbers (DN) and need to be calibrated to correspond to proper radar cross section information. \n",
    "\n",
    "Calibration coefficients for SAR data are often defined in the decibel (dB) scale due to the high dynamic range of the imaging system. For the L-band ALOS PALSAR data at hand, the conversion from uncalibrated DN values to calibrated radar cross section values in dB scale is performed by applying a standard **calibration factor of -83 dB**. \n",
    "<br> <br>\n",
    "$\\gamma^0_{dB} = 20 \\cdot log10(DN) -83$\n",
    "\n",
    "The data at hand are radiometrically terrain corrected images, which are often expressed as terrain flattened $\\gamma^0$ backscattering coefficients. For forest and land cover monitoring applications $\\gamma^o$ is the preferred metric.\n",
    "\n",
    "Let's <b>apply the calibration constant for our data and export it in *dB* scale</b>: </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caldB = 20*np.log10(rasterstack) - 83"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"> While **dB**-scaled images are often \"visually pleasing\", they are often not a good basis for mathematical operations on data. For instance, when we compute the mean of observations, it makes a difference whether we do that in power or dB scale. Since dB scale is a logarithmic scale, we cannot simply average data in that scale. \n",
    "    \n",
    "Please note that the **correct scale** in which operations need to be performed **is the power scale.** This is critical, e.g. when speckle filters are applied, spatial operations like block averaging are performed, or time series are analyzed.\n",
    "\n",
    "To **convert from dB to power**, apply: $\\gamma^o_{pwr} = 10^{\\frac{\\gamma^o_{dB}}{10}}$ </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calPwr = np.power(10., caldB/10.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 5.3 Create a Time Series Animation </b> </font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\">First, <b>Create a directory in which to store our plots and move into it:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_path = path/'plots_and_animations'\n",
    "if not product_path.exists():\n",
    "    product_path.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"> Now we are ready to <b>create a time series animation</b> from the calibrated SAR data. </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.axis('off')\n",
    "vmin = np.percentile(caldB.flatten(), 5)\n",
    "vmax = np.percentile(caldB.flatten(), 95)\n",
    "r0dB = 20*np.log10(raster0) - 83\n",
    "im = ax.imshow(r0dB,cmap='gray', vmin=vmin, vmax=vmax)\n",
    "ax.set_title(\"{}\".format(tindex[0].date()))\n",
    "\n",
    "def animate(i):\n",
    "    ax.set_title(\"{}\".format(tindex[i].date()))\n",
    "    im.set_data(caldB[i])\n",
    "\n",
    "# Interval is given in milliseconds\n",
    "ani = an.FuncAnimation(fig, animate, frames=rasterstack.shape[0], interval=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Configure matplotlib's RC settings for the animation:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc('animation', embed_limit=40971520.0)  # We need to increase the limit maybe to show the entire animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create a javascript animation of the time-series running inline in the notebook:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Save the animation (animation.gif):</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.save(f'{product_path}/animation.gif', writer='pillow', fps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 5.3 Plot the Time Series of Means Calculated Across the Subset </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> To create the time series of means, we will go through the following steps:\n",
    "1. Compute means using the data in **power scale** ($\\gamma^o_{pwr}$) .\n",
    "3. Convert the resulting mean values into dB scale for visualization.\n",
    "4. Plot time series of means. </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Compute the means:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_means_pwr = np.mean(calPwr,axis=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Convert the resulting mean value time-series to dB scale for visualization and check that we got the means over time:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_means_dB = 10.*np.log10(rs_means_pwr)\n",
    "rs_means_pwr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Plot and save the time series of means (time_series_means.png):</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Now let's plot the time series of means\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(tindex, rs_means_pwr)\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('$\\overline{\\gamma^o}$ [power]')\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(tindex, rs_means_dB, color='red')\n",
    "ax2.set_ylabel('$\\overline{\\gamma^o}$ [dB]')\n",
    "fig.legend(['power', 'dB'], loc=1)\n",
    "plt.title('Time series profile of average band backscatter $\\gamma^o$ ')\n",
    "plt.savefig(f'{product_path}/time_series_means', dpi=72, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 5.4 Create Two-Panel Figure with Animated Global Mean $\\mu_{\\gamma^0_{dB}}$ </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> We use a few Matplotlib functions to <b>create a side-by-side animation of the dB-scaled imagery and the respective global means $\\mu_{\\gamma^0_{dB}}$.</b> </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 4), gridspec_kw={'width_ratios':[1, 3]})\n",
    "\n",
    "vmin = np.percentile(rasterstack.flatten(), 5)\n",
    "vmax = np.percentile(rasterstack.flatten(), 95)\n",
    "im = ax1.imshow(raster0, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "ax1.set_title(\"{}\".format(tindex[0].date()))\n",
    "ax1.set_axis_off()\n",
    "\n",
    "ax2.axis([tindex[0].date(), tindex[-1].date(), rs_means_dB.min(), rs_means_dB.max()])\n",
    "ax2.set_ylabel('$\\overline{\\gamma^o}$ [dB]')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylim((-10, -5))\n",
    "l, = ax2.plot([], [])\n",
    "\n",
    "def animate(i):\n",
    "    ax1.set_title(\"{}\".format(tindex[i].date()))\n",
    "    im.set_data(rasterstack[i])\n",
    "    ax2.set_title(\"{}\".format(tindex[i].date()))\n",
    "    l.set_data(tindex[:(i+1)], rs_means_dB[:(i+1)])\n",
    "\n",
    "# Interval is given in milliseconds\n",
    "ani = an.FuncAnimation(fig, animate, frames=rasterstack.shape[0], interval=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create a javascript animation of the time-series running inline in the notebook:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Save the animated time-series and histogram (animation_histogram.gif):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.save(f'{product_path}/animation_histogram.gif', writer='pillow', fps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"2\"> <i>Time_Series_Example.ipynb - Version 1.5.1 - October 2021 </i>\n",
    "    <br>\n",
    "    <b>Version Changes</b>\n",
    "    <ul>\n",
    "        <li>Replaced all `os` and obsolete `asfn` methods with `pathlib` counterparts.</li>\n",
    "        <li>Specified location of where animation and graph should be stored</li>\n",
    "        <li>Removed any cells that provoked directory movement.</li>\n",
    "        <li>Cleaned code and removed redundancy</li>\n",
    "    </ul>\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtc_analysis [conda env:.local-rtc_analysis]",
   "language": "python",
   "name": "conda-env-.local-rtc_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
