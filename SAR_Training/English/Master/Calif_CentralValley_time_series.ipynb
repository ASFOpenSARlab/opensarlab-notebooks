{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InSAR Time Series Analysis using MintPy and ARIA products\n",
    "## Mapping Subsidence in the California Central Valley with InSAR time series\n",
    "\n",
    "**Authors:** Eric Fielding, David Bekaert, Heresh Fattahi and Zhang Yunjun \n",
    "\n",
    " This notebook is a modification by Eric Fielding from the notebook \n",
    " (https://opensciencelab.asf.alaska.edu/lab/opensarlab/hub/user-redirect/lab/tree/notebooks/SAR_Training/English/Hazards/LosAngeles_time_series.ipynb)\n",
    " \n",
    "That Los Angeles time series note was a second modification of the \n",
    " (https://opensciencelab.asf.alaska.edu/lab/opensarlab/hub/user-redirect/lab/tree/NISAR_ST_demo/ARIA-tools-docs/JupyterDocs/NISAR/L2_interseismic/mintpySF/smallbaselineApp_aria.ipynb)\n",
    " by David Bekaert, Heresh Fattahi and Zhang Yunjun that was originally focused on San Francisco. \n",
    "\n",
    " This notebook is a modification from the [original](https://nbviewer.jupyter.org/github/insarlab/MintPy-tutorial/blob/master/smallbaselineApp_aria.ipynb) by Heresh Fattahi and Zhang Yunjun. \n",
    "\n",
    "Additional Python code from the NISAR Solid Earth Level 2 science Secular Deformation requirement validation notebook has been added from the **Notebooks for NISAR Solid Earth Algorithm Theoretical Basis Documents**. See https://github.com/nisar-solid/ATBD for the full set of notebooks and explanation. We use an example dataset that was prepared for the NISAR validation.\n",
    "\n",
    "**ARIA S1 GUNW**\n",
    "\n",
    "The Caltech-JPL ARIA project in partnership with NASA Getting Ready for NISAR (GRFN) project has been generated surface displacement products (interferograms) mimicking the NISAR L2 GUNW (Geocoded Unwrapped phase interferograms) product formatting. The interferograms are stored at the NASA ASF DAAC, and are accessible with an Open Source set of tools called ARIA-tools. The Miami Insar Timeseries software in PYthon (MintPy), an open-source package for InSAR time-series analysis, is compatible with the outputs from the ARIA-tools package, and in combination with the ARIA-tools pre-processor can be used to estimate ground displacement time-series. \n",
    "\n",
    "The Jupyter notebook presented here is meant as an practical example on the use of Jupyter for exploring landslide displacements. In the example below, we will demonstrate a time-series derived from ARIA standard InSAR products over the southern Central Valley of California, also called the San Joaquin Valley revealing rapid subsidence due to large amounts of groundwater withdrawal. \n",
    "\n",
    "See the other tutorials on ARIA-tools to learn more about how to use that package.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>To save time, we have pre-ran the ARIA-tools pacakge and data loading into MintPy</b> \n",
    "\n",
    "!ariaDownload.py -b '36.18 36.26 -119.91 -119.77' --track 144 -s 20180101 -e 20190101\n",
    "    \n",
    "!!ariaTSsetup.py -f 'products/*.nc' -b '35.77 36.75 -120.61 -118.06'  --mask Download\n",
    "    \n",
    "!smallbaselineApp.py -t Central_Valley.cfg --dostep load_data\n",
    "    \n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    " \n",
    "<b>The staged data was uploaded in S3 data bucket of openSARlab and can be downloaded using:</b>\n",
    "    \n",
    "!aws s3 cp ss3://asf-jupyter-data-west/NISAR_SE/CentralValleyA144.zip CentralValleyA144.zip\n",
    "\n",
    "This data should be available from openSARlabs or other computer systems as long as the AWS command line tools are installed to download from S3.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Notebook setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below is required to be ran each time the notebook is started and ensures correct set-up of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import subprocess\n",
    "\n",
    "# define the work Top directory\n",
    "worktop_dir = os.path.abspath(os.getcwd())\n",
    "print(\"Top directory: \", worktop_dir)\n",
    "if not os.path.isdir(worktop_dir):\n",
    "    os.makedirs(worktop_dir)\n",
    "    print('Create directory: {}'.format(worktop_dir))\n",
    "print('Go to work directory: {}'.format(worktop_dir))\n",
    "os.chdir(worktop_dir)  \n",
    "    \n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "# utils function to create the MintPy analysis configuration file\n",
    "def write_config_file(out_file, CONFIG_TXT, mode='a'): \n",
    "    \"\"\"Write configuration files for MintPy to process ARIA sample products\"\"\"\n",
    "    if not os.path.isfile(out_file) or mode == 'w':\n",
    "        with open(out_file, \"w\") as fid:\n",
    "            fid.write(CONFIG_TXT)\n",
    "        print('write configuration to file: {}'.format(out_file))\n",
    "    else:\n",
    "        with open(out_file, \"a\") as fid:\n",
    "            fid.write(\"\\n\" + CONFIG_TXT)\n",
    "        print('add the following to file: \\n{}'.format(CONFIG_TXT))\n",
    "\n",
    " \n",
    "# verify if mintpy install is version 1.3.2 and older:\n",
    "try:\n",
    "    from mintpy import view, tsview, plot_network, plot_transection, plot_coherence_matrix\n",
    "except:\n",
    "    print(\"Looks like mintPy 1.3.x is not installed\")\n",
    "    \n",
    "# verify if mintpy install is version 1.5 and newer:\n",
    "try:\n",
    "    from mintpy.utils import readfile, utils as ut, plot as pp\n",
    "    from mintpy.cli import view, tsview, plot_network, plot_transection\n",
    "    from mintpy.view import prep_slice, plot_slice\n",
    "except:\n",
    "    print(\"Looks like mintPy 1.5.x is not completely installed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save time for this demonstration, we will use a staged (pre-processed and saved online) dataset from the NISAR Solid Earth Science Team covering an area of the Central Valley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a site and track direction\n",
    "# Available NISAR Solid Earth secular displacement validation sites are: \n",
    "# ['RidgecrestA64','MojaveD173','MojaveD173_3year','CentralValleyA144']\n",
    "# We use the CentralValleyA144 site in the Central Valley for this demonstration\n",
    "\n",
    "site='CentralValleyA144'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "################# Set Directories ##########################################\n",
    "print('\\nCurrent directory:',os.getcwd())\n",
    "\n",
    "if 'work_dir' not in locals():\n",
    "    work_dir = Path.cwd()/'work'/site\n",
    "\n",
    "print(\"Work directory:\", work_dir)\n",
    "work_dir.mkdir(parents=True, exist_ok=True)\n",
    "# Change to Workdir\n",
    "os.chdir(work_dir)\n",
    "\n",
    "gunw_dir = work_dir/'products'\n",
    "gunw_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(\"   GUNW    dir:\", gunw_dir) \n",
    "\n",
    "mintpy_dir = work_dir/'MintPy' \n",
    "mintpy_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(\"   MintPy  dir:\", mintpy_dir)\n",
    "### Change to MintPy workdir\n",
    "os.chdir(mintpy_dir)\n",
    "vel_file = os.path.join(mintpy_dir, 'velocity.h5')\n",
    "msk_file = os.path.join(mintpy_dir, 'maskConnComp.h5')  # maskTempCoh.h5 maskConnComp.h5\n",
    "############################################################################\n",
    "### List of CalVal Sites:\n",
    "'''\n",
    "Set NISAR calval sites:\n",
    "    CentralValleyA144  : Central Valley track 144\n",
    "    OklahomaA107       : Oklahoma\n",
    "    PuertoRicoD98      : Puerto Rico (Earthquake M6.4 on 20200107) - Descending track \n",
    "    PuertoRicoA135     : Puerto Rico (Earthquake M6.4 on 20200107 & large aftershock on 20200703) - Ascending track\n",
    "    RidgecrestD71      : Ridgecrest  (Earthquake M7.2 on 20190705) - Descending track\n",
    "    RidgecrestA64      : Ridgecrest  (Earthquake M7.2 on 20190705) - Ascending track\n",
    "    MojaveD173         : Mojave desert (Ridgecrest Earthquake M7.2 on 20190705) - Descending track\n",
    "    MojaveD173_3year   : Mojave desert (Ridgecrest Earthquake M7.2 on 20190705) - Descending track\n",
    "\n",
    "ARIA & MintPy parameters:\n",
    "    calval_location : name\n",
    "    download_region : download box in S,N,W,E format\n",
    "    analysis_region : analysis box in S,N,W,E format (must be within download_region)\n",
    "    reference_lalo : latitute,longitude in geographic coordinates (default: auto)\n",
    "    download_start_date : download start date as YYYMMDD  \n",
    "    download_end_date   : download end date as YYYMMDD\n",
    "    earthquakeDate :  arbitrary date for testing with the central_valley dataset\n",
    "    sentinel_track : sentinel track to download\n",
    "    gps_ref_site_name : Name of the GPS site for InSAR re-referencing\n",
    "    tempBaseMax' : maximum number of days, 'don't use interferograms longer than this value \n",
    "    ifgExcludeList : default is not to exclude any interferograms\n",
    "    maskWater' :  interior locations don't need to mask water\n",
    "'''\n",
    "sites = {\n",
    "    ##########  CENTRAL VALLEY ##############\n",
    "    'CentralValleyA144' : {'calval_location' : 'Central_Valley',\n",
    "            'download_region' : '\"36.18 36.26 -119.91 -119.77\"', # download box in S,N,W,E format\n",
    "            'analysis_region' : '\"35.77 36.75 -120.61 -118.06\"', # analysis box in S,N,W,E format (must be within download_region)\n",
    "            'reference_lalo' : 'auto',\n",
    "            'download_start_date' : '20180101',\n",
    "            'download_end_date' : '20190101',\n",
    "            'earthquakeDate' : '20180412',                       # arbitrary date for testing with the central_valley dataset\n",
    "            'sentinel_track' : '144',\n",
    "            'gps_ref_site_name' : 'CAWO',\n",
    "            'tempBaseMax' : 'auto',\n",
    "            'ifgExcludeList' : 'auto',\n",
    "            'maskWater' : False},                       # reference site for this area\n",
    "    ##########  OKLAHOMA ##############\n",
    "    'OklahomaA107' : {'calval_location' : 'Oklahoma',\n",
    "            'download_region' : '\"31.7 37.4 -103.3 -93.5\"',      # download box in S,N,W,E format\n",
    "            'analysis_region' : '\"35.25 36.5 -100.5 -98.5\"',     # analysis box in S,N,W,E format (must be within download_region)\n",
    "            'reference_lalo' : 'auto',\n",
    "            'download_start_date' : '20210101',\n",
    "            'download_end_date' : '20210801',\n",
    "            'earthquakeDate' : '20210328',                       # arbitrary date for testing with the Oklahoma dataset\n",
    "            'sentinel_track' : '107',\n",
    "            'gps_ref_site_name' : 'OKCL',\n",
    "            'tempBaseMax' : 'auto',\n",
    "            'ifgExcludeList' : 'auto',\n",
    "            'maskWater' : False},\n",
    "    ##########  PUERTO RICO ##############\n",
    "    'PuertoRicoD98' : {'calval_location' : 'PuertoRicoDesc',\n",
    "            'download_region' : '\"17.5 18.9 -67.5 -66.0\"',       # download box in S,N,W,E format\n",
    "            'analysis_region' : '\"17.9 18.5 -67.3 -66.2\"',       # analysis box in S,N,W,E format (must be within download_region)\n",
    "            'reference_lalo' : 'auto',\n",
    "            'download_start_date' : '20190701',\n",
    "            'download_end_date' : '20200930',\n",
    "            'earthquakeDate' : '20200107',                       # date of M6.4 quake\n",
    "            'sentinel_track' : '98',                             # descending track\n",
    "            'gps_ref_site_name' : 'PRLT',\n",
    "            'tempBaseMax' : 24,                                  # don't use interferograms longer than 24 days\n",
    "            'ifgExcludeList' : 'auto', \n",
    "            'maskWater' : True},                                 # need to mask ocean around Puerto Rico island\n",
    "    'PuertoRicoA135' : {'calval_location' : 'PuertoRicoAsc',\n",
    "             'download_region' : '\"17.5 18.9 -67.5 -66.0\"',      # download box in S,N,W,E format\n",
    "             'analysis_region' : '\"17.9 18.5 -67.3 -66.2\"',      # analysis box in S,N,W,E format (must be within download_region)\n",
    "             'reference_lalo' : 'auto',\n",
    "             'download_start_date' : '20190701',\n",
    "             'download_end_date' : '20200930',\n",
    "             'earthquakeDate' : '20200107',                      # date of M6.4 quake\n",
    "             'earthquakeDate2' : '20200703',                     # date of large aftershock\n",
    "             'sentinel_track' : '135',                           # ascending track\n",
    "             'gps_ref_site_name' : 'PRLT',\n",
    "             'tempBaseMax' : 24,                                 # don't use interferograms longer than 24 days\n",
    "             'ifgExcludeList' : 'auto',\n",
    "             'maskWater' : True},                                # need to mask ocean around Puerto Rico island\n",
    "    ##########  RIDGECREST ##############\n",
    "    'RidgecrestD71': {'calval_location' : 'RidgecrestD71',\n",
    "                      'download_region' : '\"34.5 37.5 -119.0 -116.0\"', # download box in S,N,W,E format\n",
    "                      'analysis_region' : '\"34.7 37.2 -118.9 -116.1\"', # analysis box in S,N,W,E format (must be within download_region)\n",
    "                      'reference_lalo' : 'auto',\n",
    "                      'download_start_date' : '20190601',\n",
    "                      'download_end_date' : '20190831',\n",
    "                      'earthquakeDate' : '20190705',                   # M7.2 quake date at Ridgecrest\n",
    "                      'sentinel_track' : '71',\n",
    "                      'gps_ref_site_name' : 'ISLK',\n",
    "                      'tempBaseMax' : 'auto',\n",
    "                      'ifgExcludeList' : 'auto',\n",
    "                      'maskWater' : False},\n",
    "    'RidgecrestA64': {'calval_location' : 'RidgecrestA64',\n",
    "                      'download_region' : '\"34.5 37.5 -119.0 -116.0\"', # download box in S,N,W,E format\n",
    "                      'analysis_region' : '\"34.7 37.2 -118.9 -116.1\"', # analysis box in S,N,W,E format (must be within download_region)\n",
    "                      'reference_lalo' : 'auto',\n",
    "                      'download_start_date' : '20190101',\n",
    "                      'download_end_date' : '20190701',\n",
    "                      'earthquakeDate' : '20190705',                   # M7.2 quake date at Ridgecrest\n",
    "                      'sentinel_track' : '64',\n",
    "                      'gps_ref_site_name' : 'ISLK',\n",
    "                      'tempBaseMax' : 'auto',\n",
    "                      'ifgExcludeList' : 'none',   # list of bad ifgs to exclude from time-series analysis\n",
    "                      'maskWater' : False},\n",
    "    ##########  MOJAVE ##############\n",
    "    'MojaveD173': {'calval_location' : 'MojaveD173',\n",
    "                      'download_region' : '\"34.5 35.6 -116.62 -114.39\"', # download box in S,N,W,E format\n",
    "                      'analysis_region' : '\"34.66 35.60 -116.62 -114.39\"', # analysis box in S,N,W,E format (must be within download_region)\n",
    "                      'reference_lalo' : '35.20495,-115.81229',\n",
    "                      'download_start_date' : '20180101',\n",
    "                      'download_end_date' : '20181231',\n",
    "                      'earthquakeDate' : '20190705',                   # M7.2 quake date at Ridgecrest\n",
    "                      'sentinel_track' : '173',\n",
    "                      'gps_ref_site_name' : 'P619',\n",
    "                      'tempBaseMax' : 'auto',\n",
    "                      'ifgExcludeList' : 'auto',\n",
    "                      'maskWater' : False},\n",
    "    'MojaveD173_3year': {'calval_location' : 'MojaveD173_3year',\n",
    "                      'download_region' : '\"34.5 35.6 -116.62 -114.39\"', # download box in S,N,W,E format\n",
    "                      'analysis_region' : '\"34.66 35.60 -116.62 -114.39\"', # analysis box in S,N,W,E format (must be within download_region)\n",
    "                      'reference_lalo' : '35.20495,-115.81229',\n",
    "                      'download_start_date' : '20160101',\n",
    "                      'download_end_date' : '20181231',\n",
    "                      'earthquakeDate' : '20190705',                   # M7.2 quake date at Ridgecrest\n",
    "                      'sentinel_track' : '173',\n",
    "                      'gps_ref_site_name' : 'P619',\n",
    "                      'tempBaseMax' : 'auto',\n",
    "                      'ifgExcludeList' : 'auto',\n",
    "                      'maskWater' : False}\n",
    "}\n",
    "\n",
    "# only the following four sites have the pre-processed data staged with a zip file\n",
    "secular_available_sites = ['RidgecrestA64','MojaveD173','MojaveD173_3year','CentralValleyA144']\n",
    "\n",
    "# the following checks whether the site is available. \n",
    "# You can comment out this check if you want to run another site and do your own ARIA-tools download\n",
    "if site not in secular_available_sites:\n",
    "    msg = '\\nSelected site not available! Please select one of the following sites:: \\n{}'.format(secular_available_sites)\n",
    "    raise Exception(msg)\n",
    "else:\n",
    "    print('\\nSelected site: {}'.format(site))\n",
    "    for key, value in sites[site].items():\n",
    "        print('   '+ key, ' : ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# option to control the use of pre-staged data; [False/True]\n",
    "Use_Staged_Data = True\n",
    "     \n",
    "######### DO NOT CHANGE LINES BELOW ########\n",
    "\n",
    "if Use_Staged_Data:\n",
    "     # Check if a stage file from S3 already exist, if not try and download it\n",
    "    if len(glob.glob('MintPy/inputs/*.h5')) == 0:\n",
    "        os.chdir(work_dir.parents[0])\n",
    "        zip_name = site + '.zip'\n",
    "        print('Downloading:',  Path.cwd()/zip_name)\n",
    "        if not os.path.isfile(zip_name):\n",
    "            try:\n",
    "                command = \"aws s3 cp --no-sign-request s3://asf-jupyter-data-west/NISAR_SE/\" + site + '.zip ' + zip_name\n",
    "                subprocess.run(command, shell=True, check = True)\n",
    "            except:\n",
    "                command = 'wget --no-check-certificate --no-proxy \"http://asf-jupyter-data-west.s3.amazonaws.com/NISAR_SE/' + site + '.zip\" -q --show-progress'\n",
    "                print('\\nDownloading staged data ... ')\n",
    "                subprocess.run(command, stdout=None, stderr=subprocess.PIPE, shell=True)\n",
    "            finally:\n",
    "                if (work_dir.parents[0]/zip_name).is_file():\n",
    "                    print('Finished downloading!')\n",
    "                else:\n",
    "                    raise RuntimeError('Failed downloading Staged data!!! Install aws or wget to proceed')\n",
    "\n",
    "        command = 'unzip ' + str(work_dir.parents[0]/zip_name) +'; rm ' + str(work_dir.parents[0]/zip_name)\n",
    "        process = subprocess.run(command, shell=True)\n",
    "    if not os.path.exists(work_dir):\n",
    "        raise Exception(\"Staged data for site {} not sucessfully generated. Please delete site-name folder {} and rerun this cell\".format(site, work_dir))\n",
    "    print('Finish preparing staged data for MintPy!!')\n",
    "\n",
    "else:\n",
    "    ##################### 1. Download (Aria) Interferograms from ASF ################\n",
    "    os.chdir(work_dir)\n",
    "    print('NEEDED To Download ARIA GUNWs: \\n Link to create account : https://urs.earthdata.nasa.gov/')\n",
    "    earthdata_user = input('Please type your Earthdata username:')\n",
    "    earthdata_password = input('Please type your Earthdata password:')\n",
    "    print('NEEDED To Download DEMs: \\n Link to create account : https://portal.opentopography.org/login')\n",
    "    if os.path.exists('~/.topoapi'): # if OpenTopo API key already installed\n",
    "        print('OpenTopo API key appears to be installed, using that')\n",
    "    else:\n",
    "        print('API key location: My Account > myOpenTopo Authorizations and API Key > Request API key')\n",
    "        opentopography_api_key = input('Please type your OpenTopo API key:')\n",
    "\n",
    "    ######################## USE ARIA-TOOLS TO DOWNLOAD GUNW ########################\n",
    "    '''\n",
    "    REFERENCE: https://github.com/aria-tools/ARIA-tools\n",
    "    '''\n",
    "    aria_download = '''ariaDownload.py -b {bbox} -u {user} -p {password} -s {start}  -e {end} -t {track} -o Count'''\n",
    "\n",
    "    ###############################################################################\n",
    "    print('CalVal site {}'.format(site))\n",
    "    print('  Searching for available GUNW products:\\n')\n",
    "\n",
    "    command = aria_download.format(bbox = sites[site]['download_region'],\n",
    "                                   start = sites[site]['download_start_date'],\n",
    "                                   end = sites[site]['download_end_date'],\n",
    "                                   track = sites[site]['sentinel_track'],\n",
    "                                   user = earthdata_user,\n",
    "                                   password = earthdata_password)\n",
    "      \n",
    "    process = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text = True, shell = True)\n",
    "    print(process.stdout)\n",
    "\n",
    "    ############## Download GUNW ##################\n",
    "    print(\"Start downloading GUNW files ...\")\n",
    "    process = subprocess.run(command.split(' -o')[0], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, shell=True)\n",
    "    # Missing progressbar\n",
    "    print(\"Downloaded {} GUNW files in: {}\\n\".format(len([(x) for x in os.listdir(gunw_dir) if x.endswith('.nc')]), gunw_dir))\n",
    "\n",
    "    ############## DO little CLEANING ###########\n",
    "    data_to_clean = [\"avg_rates.csv\", \"ASFDataDload0.py\", \"AvgDlSpeed.png\", \"error.log\"]\n",
    "\n",
    "    for i, file in enumerate(data_to_clean):\n",
    "        print('Cleaning unnecessary data {} in {}'.format(file, gunw_dir))\n",
    "        (gunw_dir/file).unlink(missing_ok=True)\n",
    "\n",
    "    #Delete error log file from workdir\n",
    "    print('Cleaning unnecessary data error.log in {}'.format(work_dir))\n",
    "    (work_dir/\"error.log\").unlink(missing_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command will download all the ARIA standard products over part of the California Central Valley for the year 2018, which is 90 products. This will take some time to complete if the data is not already downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data for descending track 144 over part of San Joaquin Valley in southern Central Valley\n",
    "#!ariaDownload.py -b '36.18 36.26 -119.91 -119.77' --track 144 -s 20180101 -e 20190101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ARIA time-series setup would cover the whole Sentinel-1 scene and would take a while to process, so we are skipping this setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ariaTSsetup.py -f 'products/*.nc' -b '36.18 36.26 -119.91 -119.77' --mask Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following ARIA time-series setup `ariaTSsetup.py` extracts the data that covers only a small area around the city of Corcoran in the San Joaquin Valley where the most rapid subsidence occurred in 2018 to speed the time-series processing, which we specify with the bounding box. We also download the water mask to avoid using data over the ocean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ariaTSsetup.py -f 'products/*.nc' -b '35.77 36.75 -120.61 -118.06'  --mask Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. smallbaselineApp.py overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This application provides a workflow which includes several steps to invert a stack of unwrapped interferograms and apply different corrections to obtain ground displacement timeseries.  \n",
    "The workflow consists of two main blocks:\n",
    "\n",
    "* correcting unwrapping errors and inverting for the raw phase time-series (blue ovals),\n",
    "* correcting for noise from different sources to obtain the displacement time-series (green ovals).\n",
    "\n",
    "Some steps are optional, which are switched off by default (marked by dashed boundaries). Configuration parameters for each step are initiated with default values in a customizable text file: [smallbaselineApp.cfg](https://github.com/insarlab/MintPy/blob/master/mintpy/defaults/smallbaselineApp.cfg). In this notebook, we will walk through some of these steps, for a complete example see the [MintPy repository](https://github.com/insarlab/MintPy).\n",
    "\n",
    "<p align=\"left\">\n",
    "  <img width=\"600\" src=\"docs/smallbaselineApp_workflow.png\">\n",
    "</p>     \n",
    "<p style=\"text-align: center;\">\n",
    "    (Figure from Yunjun et al., 2019)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Processing steps of smallbaselineApp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MintPy **smallbaselineApp.py** application provides a workflow to invert a stack of unwrapped interferograms and apply different (often optional) corrections to obtain ground displacement timeseries. A detailed overview of the options can be retrieved by involking the help option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Configuring processing parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processing parameters for the **smallbaselineApp.py** are controlled through a configuration file. If no file is provided the default [smallbaselineApp.cfg](https://github.com/insarlab/MintPy/blob/master/mintpy/defaults/smallbaselineApp.cfg) configuration is used. Here we use the configuration parameters generated below (or included with the staged data), which already contains selected, manually modified configuration parameters for this time-series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_file = Path(mintpy_dir)/(sites[site]['calval_location'] + '.cfg')\n",
    "\n",
    "if not Use_Staged_Data:\n",
    "    ####################################################################\n",
    "    ### Write smallbaseline.py config file\n",
    "    config_file_content = \"\"\"\n",
    "    mintpy.load.processor = aria\n",
    "    mintpy.compute.numWorker = auto\n",
    "    mintpy.load.unwFile = ../stack/unwrapStack.vrt\n",
    "    mintpy.load.corFile = ../stack/cohStack.vrt\n",
    "    mintpy.load.connCompFile = ../stack/connCompStack.vrt\n",
    "    mintpy.load.demFile = ../DEM/SRTM_3arcsec.dem\n",
    "    mintpy.load.incAngleFile = ../incidenceAngle/*.vrt\n",
    "    mintpy.load.azAngleFile = ../azimuthAngle/*.vrt\n",
    "    mintpy.load.waterMaskFile = {mask_file}\n",
    "    mintpy.topographicResidual.pixelwiseGeometry = no\n",
    "    mintpy.troposphericDelay.method = no\n",
    "    mintpy.topographicResidual = no\n",
    "    mintpy.network.tempBaseMax = {tempmax}\n",
    "    mintpy.network.startDate = {startdatenet}\n",
    "    mintpy.network.endDate = {enddatenet}\n",
    "    mintpy.velocity.startDate = {startdatevel}\n",
    "    mintpy.velocity.endDate = {enddatevel}\n",
    "    mintpy.reference.lalo = {reference_lalo}\n",
    "    mintpy.network.excludeIfgIndex = {excludeIfg}\"\"\".format(mask_file = mask_file,\n",
    "                                                            tempmax=sites[site]['tempBaseMax'],\n",
    "                                                            excludeIfg=sites[site]['ifgExcludeList'],\n",
    "                                                            startdatenet=sites[site]['download_start_date'],\n",
    "                                                            enddatenet=sites[site]['download_end_date'],\n",
    "                                                            startdatevel=sites[site]['download_start_date'],\n",
    "                                                            enddatevel=sites[site]['download_end_date'],\n",
    "                                                            reference_lalo=sites[site]['reference_lalo'])\n",
    "\n",
    "    config_file.write_text(config_file_content)\n",
    "\n",
    "print('MintPy config file:\\n    {}:'.format(config_file))\n",
    "print(config_file.read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Small Baseline Time Series Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Loading ARIA data into MintPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [ARIA-tools package](https://github.com/aria-tools/ARIA-tools) is used as a pre-processor for MintPY. It has a download tool that wraps around the ASF DAAC API, and includes tools for stitching/cropping and time-series preparation. The output of the time-series preparation is compatible with the [data directory](https://mintpy.readthedocs.io/en/latest/dir_structure/) structure from MintPy. To save time, we have already pre-ran these steps. The commands used were:\n",
    "\n",
    "```\n",
    "!ariaDownload.py -b '36.18 36.26 -119.91 -119.77' --track 144 -s 20180101 -e 20190101\n",
    "#!ariaTSsetup.py -f 'products/*.nc' -b '35.77 36.75 -120.61 -118.06'  --mask Download\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ariaTSsetup.py` step above (or the pre-processed `CentralValleyA144.zip`) extracted the data for the subset we specified and found a total of 86 products that cover our study area. Now we load the data for the subset area into MintPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step loads the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Go to work directory: {}'.format(mintpy_dir))\n",
    "os.chdir(mintpy_dir)  \n",
    "\n",
    "command = 'smallbaselineApp.py ' + str(config_file) + ' --dostep load_data'\n",
    "process = subprocess.run(command, shell=True)\n",
    "print('Mintpy input files:')\n",
    "[x for x in os.listdir('inputs') if x.endswith('.h5')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the loading step is an \"inputs\" directory containing two HDF5 files:\n",
    "- ifgramStack.h5: This file contains 6 dataset cubes (e.g. unwrapped phase, coherence, connected components etc.) and multiple metadata.  \n",
    "- geometryGeo.h5: This file contains geometrical datasets (e.g., incidence/azimuth angle, masks, etc.). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>info.py :</b> \n",
    "To get general infomation about a MintPy product, run info.py on the file.   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!info.py inputs/ifgramStack.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!info.py inputs/geometryGeo.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Plotting the interferogram network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running **plot_network.py** gives an overview of the network and the average coherence of the stack. The program creates multiple files as follows:\n",
    "- ifgramStack_coherence_spatialAvg.txt: Contains interferogram dates, average coherence temporal and spatial baseline separation.\n",
    "- Network.pdf: Displays the network of interferograms on time-baseline coordinates, colorcoded by avergae coherence of the interferograms. \n",
    "- CoherenceMatrix.pdf shows the avergae coherence pairs between all available pairs in the stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = 'smallbaselineApp.py ' + str(config_file) + ' --dostep modify_network'\n",
    "process = subprocess.run(command, shell=True)\n",
    "#!smallbaselineApp.py Central_Valley.cfg  --dostep modify_network\n",
    "plot_network.main(['inputs/ifgramStack.h5'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.  Mask generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask files can be can be used to mask pixels in the time-series processing. Below we generate a mask file based on the connected components, which is a metric for unwrapping quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!generate_mask.py  inputs/ifgramStack.h5  --nonzero  -o maskConnComp.h5  --update\n",
    "view.main(['maskConnComp.h5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "#!view.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reference_point\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interferometric phase is relative observation by nature. The phases of each unwrapped interferogram are relative with respect to an arbitrary pixel. Therfore we need to reference all interferograms to a common reference pixel.\n",
    "The step \"reference_point\" selects a common reference pixel for the stack of interferograms. The default approach of mintpy is to choose a pixel with highest spatial coherence in the stack. Other options include specifying the longitude and latitude of the desired reference pixel or the line and column number of the refence pixel.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = 'smallbaselineApp.py ' + str(config_file) + ' --dostep reference_point'\n",
    "process = subprocess.run(command, shell=True)\n",
    "#!smallbaselineApp.py Central_Valley.cfg --dostep reference_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the \"reference_step\" adds additional attributes \"REF_X, REF_Y\" and \"REF_LON, REF_LAT\" to the ifgramStack.h5 file. To see the attributes of the file run info.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!info.py inputs/ifgramStack.h5 | egrep 'REF_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, I set the reference point latitude and longitude to be in a location, and MintPy calculated the X and Y locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Inverting of the Small Baseline network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we invert the network of differential unwrapped interferograms to estimate the time-series of unwrapped phase with respect to a reference acquisition date. By default mintpy selects the first acquisition. The estimated time-series is converted to distance change from radar to target and is provided in meters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = 'smallbaselineApp.py ' + str(config_file) + ' --dostep invert_network'\n",
    "process = subprocess.run(command, shell=True)\n",
    "#!smallbaselineApp.py Central_Valley.cfg  --dostep invert_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The timeseries file contains three datasets:\n",
    "- the \"time-series\" which is the interferometric range change for each acquisition relative to the reference acquisition,\n",
    "- the \"date\" dataset which contains the acquisition date for each acquisition,\n",
    "- the \"bperp\" dataset which contains the timeseries of the perpendicular baseline.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Estimating the long-term velocity rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ground deformation caused by many geophysical or anthropogenic processes are linear at first order approximation. Therefore it is common to estimate the rate of the ground deformation which is the slope of linear fit to the time-series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = 'smallbaselineApp.py ' + str(config_file) + ' --dostep velocity'\n",
    "process = subprocess.run(command, shell=True)\n",
    "#!smallbaselineApp.py Central_Valley.cfg  --dostep velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scp_args = 'velocity.h5 velocity -v -30 30'\n",
    "view.main(scp_args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Note :</b> \n",
    "Negative values indicates that target is moving away from the radar (i.e., Subsidence in case of vertical deformation).\n",
    "Positive values indicates that target is moving towards the radar (i.e., uplift in case of vertical deformation). \n",
    "    The line of sight (LOS) for this descending Sentinel-1 track is up and east from ground to radar.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obvious features in the estimated velocity map:\n",
    "\n",
    "1) We use a color scale for this velocity with a range of +/-30 cm/year due to the rapid subsidence velocity in this area. \n",
    "\n",
    "2) The negative LOS feature near the city of Corcoran (center left of map) is rapid subsidence due to groundwater extraction in the central part of the San Joaquin Valley, moving down and away from the radar satellite.\n",
    "\n",
    "3) The block box at 36.63N, 119.26W is the reference pixel for this map, in a more stable part of the Central Valley. \n",
    "\n",
    "4) Most of the map is a green color as it is close to zero displacement with the large color scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Error analysis (what is signal, what is noise!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncertainty of the ground displacement products derived from InSAR time-series, depends on the quality of the inversion of the stack of interferograms and the accuracy in separating the ground displacement from other components of the InSAR data. Therefore the definition of signal vs noise is different at the two main steps in mintpy:  \n",
    "\n",
    "1) During the inversion: \n",
    "    At this step all systematic components of the interferometric phase (e.g., ground displacement, propagation delay, geometrical residuals caused by DEM or platform's orbit inaccuracy) are considered signal, while the interferometric phase decorrelation, phase unwrapping error and phase inconsistency are considered noise. \n",
    "    \n",
    "2) After inversion: the ground displacement component of the time-serieses is signal, and everything else (including the propagation delay and geometrical residuals) are considered noise\n",
    "\n",
    "Therefore we first discuss the possible sources of error during the inversion and the existing ways in MintPy to evaluate the quality of inversion and to improve the uncertainty of the inversion. Afterwards we explain the different components of the time-series and the different processing steps in MintPy to separate them from ground displacement signal.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Quality of the inversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main sources of noise during the time-series inversion includes decorrelation, phase unwrapping error and the inconsistency of triplets of interferofgrams. Here we mainly focus on the decorrelation and unwrapping errors. We first show the existing quantities in MintPy to evaluate decorrelation and unwrapping errors and then discuss the existing ways in MintPy to reduce the decorrelation and unwrapping errors on the time-series inversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Average spatial coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mintpy computes temporal average of spatial coherence of the entire stack as a potential ancillary measure to choose reliable pixels after time-series inversion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.main(['avgSpatialCoh.h5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Temporal coherence\n",
    "\n",
    "In addition to timeseries.h5 which contains the time-series dataset, invert_network produces other quantities, which contain metrics to evaluate the quality of the inversion including temporalCoherence.h5. Temporal coherence represents the consistency of the timeseries with the network of interferograms. \n",
    "\n",
    "Temporal coherence varies from 0 to 1. Pixels with values closer to 1 are considered reliable and pixels with values closer to zero are considered unreliable. For a dense network of interferograms, a threshold of 0.7 may be used (Yunjun et al, 2019)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "view.main(['temporalCoherence.h5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With both the spatial coherence and temporal coherence, we can see that the InSAR in the area of the Sierra Nevada (east of about 119W has unstable phase, and the InSAR measurements there will be low quality. There is also an area of low coherence in the low-elevation Tulare Lake bed near 119.6W, 36.0N, where the land changes a lot during the year. A much larger area flooded in the spring of 2023 when heavy rains caused high river flows that drained into the lake.\n",
    "\n",
    "The velocity maps have a mask based on the temporal coherence so those low coherence areas are white."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Velocity error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated velocity also comes with an expression of unecrtainty which is simply based on the goodness of fit while fitting a linear model to the time-series. This quantity is saved in \"velocity.h5\" under the velocityStd dataset. \n",
    "\n",
    "**Mintpy supports additional corrections in its processing not included in this demo:**\n",
    "- Unwrapping error correction\n",
    "- Tropospheric delay correction\n",
    "- deramping\n",
    "- Topographic residual correction\n",
    "- Residual RMS for noise evaluation\n",
    "- Changing the reference date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scp_args = 'velocity.h5 velocityStd -v 0 1.5'\n",
    "view.main(scp_args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the plot above is the velocity error, not the velocity. The errors generally increase with distance from the reference point and also increase for points with elevations different from the reference point because of topographically correlated water vapor variations that are especially strong in this area. Variations of the ground subsidence away from a linear trend in time also cause an increase in the standard deviation of the velocity, so the strong seasonal variation in subsidence causes larger standard deviations in the subsidence bowl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Plotting a Subsidence Transect "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we take a profile or transect through the subsidence signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scp_args = 'velocity.h5 --start-lalo 35.8 -119.8 --end-lalo 36.5 -118.9 '\n",
    "plot_transection.main(scp_args.split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this transect, the subsidence has an average velocity over the year 2018 that reaches more than 30 cm/year in the descending track 144 radar LOS direction. By analyzing the velocity on the ascending track and combining the two LOS directions, then we could find out that the displacements are almost all vertical due to extraction of groundwater from aquifers beneath the valley. \n",
    "\n",
    "If we assume the displacement is purely vertical, we can estimate the vertical component of displacement by dividing the LOS rate by the cosine of the incidence angle, or about 40 degrees for Sentinel-1. This means that the 30 cm/year LOS velocity is close to 39 cm/year vertical velocity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All HDF5 files can be plotted using view.py and/or tsview.py.\n",
    "\n",
    "view.py: 2D plot(s) for:\n",
    "the stack of interferogram, coherence,\n",
    "velocity, temporal coherence, etc\n",
    "DEM, products overlaid on DEM and many more\n",
    "tsview.py: 1D time series plot\n",
    "plot_transection.py: plot 1D profile along a line of a 2D matrix\n",
    "plot_coherence_matrix.py: plot coherence matrix for one pixel\n",
    "save_kmz.py: Google Earth points/raster for 2D displacement\n",
    "save_kmz_timeseries.py: Google Earth points for 3D displacement time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `smallbaselineApp.py` script also has a step to run the `save_kmz.py` and generate a KMZ for viewing in Google Earth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py smallbaselineApp.cfg --dostep google_earth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Original MintPy Notebook withe detailed description by Yunjun and Fattahi at: https://nbviewer.jupyter.org/github/insarlab/MintPy-tutorial/blob/master/smallbaselineApp_aria.ipynb\n",
    "\n",
    "- Mintpy reference: *Yunjun, Z., H. Fattahi, F. Amelung (2019), Small baseline InSAR time series analysis: unwrapping error correction and noise reduction, preprint doi:[10.31223/osf.io/9sz6m](https://eartharxiv.org/9sz6m/).*\n",
    "\n",
    "- MintPy published reference: *Yunjun, Z., H. Fattahi, and F. Amelung (2019), Small baseline InSAR time series analysis: Unwrapping error correction and noise reduction, Computers & Geosciences, 133, 104331, doi:10.1016/j.cageo.2019.104331.* \n",
    "\n",
    "\n",
    "- University of Miami online time-series viewer: https://insarmaps.miami.edu/\n",
    "\n",
    "- Mintpy Github repository: https://github.com/insarlab/MintPy\n",
    "\n",
    "- ARIA-tools Github Repository: https://github.com/aria-tools/ARIA-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osl_mintpy [conda env:.local-osl_mintpy]",
   "language": "python",
   "name": "conda-env-.local-osl_mintpy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
