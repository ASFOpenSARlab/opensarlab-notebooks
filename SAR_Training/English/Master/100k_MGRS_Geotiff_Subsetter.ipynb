{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"NotebookAddons/blackboard-banner.png\" width=\"100%\" />\n",
    "\n",
    "# Tile Data Stack to MGRS (Military Grid Reference System)\n",
    "\n",
    "<img style=\"padding: 7px\" src=\"NotebookAddons/UAFLogo_A_647.png\" width=\"170\" align=\"right\"/></font>\n",
    "\n",
    "**Alex Lewandowski; University of Alaska Fairbanks**\n",
    "\n",
    "This notebook subsets a tiff stack into MGRS tiles\n",
    "\n",
    "* Takes a directory of geotiffs\n",
    "* Creates directories named by MGRS tile, filled with MGRS tile subsets\n",
    "* Allows for saving or deletion of original geotiffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Note about JupyterHub\n",
    "\n",
    "**Your JupyterHub server will automatically shutdown when left idle for more than 1 hour. Your notebooks will not be lost but you will have to restart their kernels and re-run them from the beginning. You will not be able to seamlessly continue running a partially run notebook.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import url_widget as url_w\n",
    "notebookUrl = url_w.URLWidget()\n",
    "display(notebookUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "\n",
    "notebookUrl = notebookUrl.value\n",
    "user = !echo $JUPYTERHUB_USER\n",
    "env = !echo $CONDA_PREFIX\n",
    "if env[0] == '':\n",
    "    env[0] = 'Python 3 (base)'\n",
    "if env[0] != '/home/jovyan/.local/envs/rtc_analysis':\n",
    "    display(Markdown(f'<text style=color:red><strong>WARNING:</strong></text>'))\n",
    "    display(Markdown(f'<text style=color:red>This notebook should be run using the \"rtc_analysis\" conda environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>It is currently using the \"{env[0].split(\"/\")[-1]}\" environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Select the \"rtc_analysis\" from the \"Change Kernel\" submenu of the \"Kernel\" menu.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>If the \"rtc_analysis\" environment is not present, use <a href=\"{notebookUrl.split(\"/user\")[0]}/user/{user[0]}/notebooks/conda_environments/Create_OSL_Conda_Environments.ipynb\"> Create_OSL_Conda_Environments.ipynb </a> to create it.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Note that you must restart your server after creating a new environment before it is usable by notebooks.</text>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import Relevant Python Packages\n",
    "\n",
    "We will use the following scientific library:\n",
    "- [GDAL](https://www.gdal.org/) is a software library for reading and writing raster and vector geospatial data formats. It includes a collection of programs tailored for geospatial data processing. Most modern GIS systems (such as ArcGIS or QGIS) use GDAL in the background.\n",
    "\n",
    "**mport the necesssary libraries and modules:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from pathlib import Path\n",
    "from math import ceil\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Tuple, Union\n",
    "\n",
    "import mgrs\n",
    "from mgrs.core import MGRSError\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "from pyproj import CRS, Transformer\n",
    "\n",
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "import opensarlab_lib as asfn\n",
    "asfn.jupytertheme_matplotlib_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Enter the path to the directory holding your tiffs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = FileChooser('/home/jovyan/notebooks')\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find the paths of all geotiffs in the data directory:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(fc.selected_path)\n",
    "tiff_paths = list(data_dir.glob('*.tif*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Subset to MGRS Tiles\n",
    "\n",
    "**Create some necessary lookup tables**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'I' and 'O' are omitted from MGRS grids to avoid confusion with '0' and '1' when printed on paper maps.\n",
    "# This makes char math difficult but we can use lookup tables to deal with it.\n",
    "\n",
    "GNUM = {\n",
    "    'A': 1, 'B': 2, 'C': 3,\n",
    "    'D': 4, 'E': 5, 'F': 6,\n",
    "    'G': 7, 'H': 8, 'J': 9,\n",
    "    'K': 10, 'L': 11, 'M': 12,\n",
    "    'N': 13, 'P': 14, 'Q': 15,\n",
    "    'R': 16, 'S': 17, 'T': 18,\n",
    "    'U': 19, 'V': 20, 'W': 21,\n",
    "    'X': 22, 'Y': 23, 'Z': 24\n",
    "}\n",
    "\n",
    "GLET = {v: k for (k,v) in GNUM.items()}\n",
    "\n",
    "# Valid 100k rows follow a regular pattern for odd and even UTMs \n",
    "# (represented by the zero-padded, two-digit number at the start of an MGRS tile)\n",
    "\n",
    "ZONE_ROWS = {\n",
    "    'odd': {\n",
    "        'X': ['V', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P'],\n",
    "        'W': ['M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V'],\n",
    "        'V': ['C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L'],\n",
    "        'U': ['P', 'Q', 'R', 'S', 'T', 'U', 'V', 'A', 'B', 'C'],\n",
    "        'T': ['E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P'],\n",
    "        'S': ['R', 'S', 'T', 'U', 'V', 'A', 'B', 'C', 'D', 'E'],\n",
    "        'R': ['G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R'],\n",
    "        'Q': ['T', 'U', 'V', 'A', 'B', 'C', 'D', 'E', 'F', 'G'],\n",
    "        'P': ['J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T'],\n",
    "        'N': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J'],\n",
    "        'M': ['M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V'],\n",
    "        'L': ['C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M'],\n",
    "        'K': ['P', 'Q', 'R', 'S', 'T', 'U', 'V', 'A', 'B', 'C'],\n",
    "        'J': ['E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P'],\n",
    "        'H': ['R', 'S', 'T', 'U', 'V', 'A', 'B', 'C', 'D', 'E'],\n",
    "        'G': ['G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R'],\n",
    "        'F': ['T', 'U', 'V', 'A', 'B', 'C', 'D', 'E', 'F', 'G'],        \n",
    "        'E': ['K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T'],\n",
    "        'D': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K'],\n",
    "        'C': ['M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'A'],        \n",
    "    },\n",
    "    'even': {\n",
    "        'X': ['E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U'],\n",
    "        'W': ['S', 'T', 'U', 'V', 'A', 'B', 'C', 'D', 'E'],\n",
    "        'V': ['H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R'],\n",
    "        'U': ['U', 'V', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'],\n",
    "        'T': ['K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U'],\n",
    "        'S': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K'],\n",
    "        'R': ['M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'A'],\n",
    "        'Q': ['C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M'],\n",
    "        'P': ['P', 'Q', 'R', 'S', 'T', 'U', 'V', 'A', 'B', 'C'],\n",
    "        'N': ['F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P'],\n",
    "        'M': ['S', 'T', 'U', 'V', 'A', 'B', 'C', 'D', 'E'],\n",
    "        'L': ['H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S'],\n",
    "        'K': ['U', 'V', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'],\n",
    "        'J': ['K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U'],\n",
    "        'H': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K'],\n",
    "        'G': ['M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'A'],\n",
    "        'F': ['C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M'],        \n",
    "        'E': ['Q', 'R', 'S', 'T', 'U', 'V', 'A', 'B', 'C'],\n",
    "        'D': ['F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q'],\n",
    "        'C': ['S', 'T', 'U', 'V', 'A', 'B', 'C', 'D', 'E', 'F'],                \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write functions to do the work of identifying all MGRS tiles touching a geotiff**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utm_to_latlon(easting: float, northing: float, epsg: str) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    converts coordinates from any EPSG into lat-lon (EPSG: 4326)\n",
    "    \"\"\"\n",
    "    transformer = Transformer.from_crs(f\"epsg:{epsg}\", \"epsg:4326\", always_xy=True)\n",
    "    return transformer.transform(easting, northing)\n",
    "\n",
    "def get_epsg(path: Union[str, Path]) -> str:\n",
    "    \"\"\"\n",
    "    returns the EPSG of a geotiff\n",
    "    \"\"\"\n",
    "    info = gdal.Info(str(path), format='json')\n",
    "    return info['coordinateSystem']['wkt'].split('ID')[-1].split(',')[1][0:-2]\n",
    "\n",
    "def get_corners(path: Union[str, Path]) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    returns the corner coordinate metadata of a geotiff\n",
    "    \"\"\"\n",
    "    return gdal.Info(str(path), format='json')['cornerCoordinates']\n",
    "\n",
    "\n",
    "def get_mgrs_corners(path: Union[str, Path]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    returns the 100k MGRS tiles containing each corner of a geotiff\n",
    "    \"\"\"\n",
    "    epsg = get_epsg(path)\n",
    "    corners = get_corners(path)\n",
    "\n",
    "    ul = utm_to_latlon(corners['upperLeft'][0], corners['upperLeft'][1], epsg)\n",
    "    lr = utm_to_latlon(corners['lowerRight'][0], corners['lowerRight'][1], epsg)\n",
    "\n",
    "    corners = dict()\n",
    "    m = mgrs.MGRS()\n",
    "    corners.update({'ul': m.toMGRS(ul[1], ul[0], MGRSPrecision=0)})\n",
    "    corners.update({'ll': m.toMGRS(lr[1], ul[0], MGRSPrecision=0)})\n",
    "    corners.update({'ur': m.toMGRS(ul[1], lr[0], MGRSPrecision=0)})\n",
    "    corners.update({'lr': m.toMGRS(lr[1], lr[0], MGRSPrecision=0)})\n",
    "    return corners\n",
    "\n",
    "def valid_utm_columns(utm: int) -> List[str]:\n",
    "    \"\"\"\n",
    "    utm: the zero-padded, two-digit number at the start of an MGRS tile\n",
    "    returns a list of valid column letters for a given utm\n",
    "    \"\"\"\n",
    "    if utm in range(1, 61, 3):\n",
    "        return ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
    "    if utm in range(2, 61, 3):\n",
    "        return ['J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R']\n",
    "    if utm in range(3, 61, 3):\n",
    "        return ['S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "\n",
    "def get_zones(mgrs_corners: Dict[str, str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    returns a list of all MGRS zones in area bounded by mgrs_corners\n",
    "    MGRS zone: the uppercase letter at index 2 of an MGRS tile string\n",
    "    \"\"\"\n",
    "    zones = list(range(GNUM[mgrs_corners['lr'][2]], GNUM[mgrs_corners['ur'][2]]+1))\n",
    "    return [GLET[i] for i in zones] \n",
    "\n",
    "def get_utms(mgrs_corners: Dict[str, str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    returns a list of all UTMs (as zero-padded strings) in area bounded by mgrs_corners\n",
    "    UTM: the zero-padded, two-digit number at the start of an MGRS tile\n",
    "    \"\"\"\n",
    "    utms = list(range(int(mgrs_corners['ul'][:2]), int(mgrs_corners['ur'][:2])+1))\n",
    "    if len(utms) == 0:\n",
    "        utms = list(range(1, int(mgrs_corners['ur'][:2])+1))\n",
    "        utms += list(range(int(mgrs_corners['ul'][:2]), 61))\n",
    "    return [f\"{i:02d}\" for i in utms]   \n",
    "\n",
    "    \n",
    "def get_utm_zones(mgrs_corners: Dict[str, str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    returns a list of a valid UTM zones in area bounded by mgrs_corners\n",
    "    UTM zones: indices [0:3] of 100k MGRS grid string\n",
    "    \"\"\"\n",
    "    utms = get_utms(mgrs_corners)\n",
    "    zones = get_zones(mgrs_corners)\n",
    "    \n",
    "    utm_zones = list()\n",
    "    for utm in utms:\n",
    "        for zone in zones:\n",
    "            utm_zones.append(f\"{utm}{zone}\")\n",
    "    return utm_zones\n",
    "\n",
    "def get_utm_zones_cols(utm_zones: List[str], mgrs_corners: Dict[str, str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    returns a list of all valid UTM Zones and 100k MGRS columns in area bounded by mgrs_corners:\n",
    "    indices [0:4] of 100k MGRS grid strings\n",
    "    \n",
    "    UTM zones: list of indices [0:3] of 100k MGRS grid string\n",
    "    100k MGRS column: index 3 of 100k MGRS grid string\n",
    "    \"\"\"\n",
    "    utm_zones_cols = list()\n",
    "    for g in utm_zones:\n",
    "        valid_cols = valid_utm_columns(int(g[:2]))\n",
    "        if g[:2] == mgrs_corners['ur'][:2]:\n",
    "            east_col = mgrs_corners['ur'][3]\n",
    "            index = valid_cols.index(east_col)\n",
    "            for col in valid_cols[:index+1]:\n",
    "                utm_zones_cols.append(f\"{g}{col}\")\n",
    "        elif g[:2] == mgrs_corners['ul'][:2]:\n",
    "            west_col = mgrs_corners['ul'][3]\n",
    "            index = valid_cols.index(west_col)\n",
    "            for col in valid_cols[index:]:\n",
    "                utm_zones_cols.append(f\"{g}{col}\")\n",
    "        else:\n",
    "            for col in valid_cols:\n",
    "                utm_zones_cols.append(f\"{g}{col}\")\n",
    "    return utm_zones_cols              \n",
    "                \n",
    "def get_utm_zones_cols_rows(utm_zones_cols: List[str], mgrs_corners: Dict[str, str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    returns a list of all 100k MGRS grid tiles in area bounded by mgrs_corners\n",
    "    utm_zones_cols: list of indices [0:4] of 100k MGRS grid strings\n",
    "    \"\"\"\n",
    "    utm_zones_cols_rows = list()\n",
    "    eastern_utm_even = int(mgrs_corners['ur'][:2]) % 2 == 0\n",
    "    \n",
    "    for col in utm_zones_cols:\n",
    "        col_utm = int(col[:2])\n",
    "        col_utm_even = col_utm % 2 == 0\n",
    "        \n",
    "        n_eastern_rows_even = ZONE_ROWS['even'][mgrs_corners['ur'][2]]\n",
    "        s_eastern_rows_even = ZONE_ROWS['even'][mgrs_corners['lr'][2]]\n",
    "        n_eastern_rows_odd = ZONE_ROWS['odd'][mgrs_corners['ur'][2]]\n",
    "        s_eastern_rows_odd = ZONE_ROWS['odd'][mgrs_corners['lr'][2]]\n",
    "        \n",
    "        if col_utm_even:\n",
    "            valid_rows = ZONE_ROWS['even'][col[2]]\n",
    "            if eastern_utm_even:\n",
    "                index_north = n_eastern_rows_even.index(mgrs_corners['ur'][4])\n",
    "                index_south = s_eastern_rows_even.index(mgrs_corners['lr'][4])\n",
    "            else:\n",
    "                index_north = n_eastern_rows_odd.index(mgrs_corners['ur'][4])\n",
    "                index_south = s_eastern_rows_odd.index(mgrs_corners['lr'][4])\n",
    "        else:\n",
    "            valid_rows = ZONE_ROWS['odd'][col[2]]\n",
    "            if not eastern_utm_even:\n",
    "                index_north = n_eastern_rows_odd.index(mgrs_corners['ur'][4])\n",
    "                index_south = s_eastern_rows_odd.index(mgrs_corners['lr'][4])\n",
    "            else:\n",
    "                index_north = n_eastern_rows_even.index(mgrs_corners['ur'][4])\n",
    "                index_south = s_eastern_rows_even.index(mgrs_corners['lr'][4])\n",
    "            \n",
    "        if col[2] == mgrs_corners['ur'][2] and col[2] == mgrs_corners['lr'][2]:\n",
    "            valid_rows = valid_rows[index_south:index_north+1]\n",
    "        elif col[2] == mgrs_corners['ur'][2]:\n",
    "            valid_rows = valid_rows[:index_north+1]\n",
    "        elif col[2] == mgrs_corners['lr'][2]:\n",
    "            valid_rows = valid_rows[index_south:]\n",
    "        for row in valid_rows:\n",
    "            utm_zones_cols_rows.append(f\"{col}{row}\")\n",
    "    return utm_zones_cols_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subset the tiffs by MGRS tile, saving them into directories named `<data_directory>/<UTM tile><MGRS tile>/`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_side_len = 100000 #for 100km tiles\n",
    "resolution = int(gdal.Info(str(tiff_paths[0]), format='json')['geoTransform'][1])\n",
    "padding  = int(((ceil(tile_side_len / resolution) * resolution) - tile_side_len))\n",
    "\n",
    "reproj_paths = list()\n",
    "reproj_dirs = list()\n",
    "for tif in tqdm(tiff_paths):\n",
    "    print(f\"\\ngeotiff: {tif}\")\n",
    "    \n",
    "    tif_epsg = get_epsg(tif)\n",
    "    gdal.Warp(str(tif), str(tif),\n",
    "                          dstSRS=f'EPSG:{tif_epsg}',\n",
    "                          xRes=resolution, yRes=resolution, targetAlignedPixels=True)\n",
    "    \n",
    "    mgrs_corners = get_mgrs_corners(tif)\n",
    "#     print(f\"mgrs_corners: {mgrs_corners}\")\n",
    "    \n",
    "    utm_zones = get_utm_zones(mgrs_corners)\n",
    "#     print(f\"utm_zones: {utm_zones}\")\n",
    "    \n",
    "    utm_zones_cols = get_utm_zones_cols(utm_zones, mgrs_corners)\n",
    "#     print(f\"utm_zones_cols: {utm_zones_cols}\")\n",
    "    \n",
    "    tiles = get_utm_zones_cols_rows(utm_zones_cols, mgrs_corners)\n",
    "    print(f\"MGRS Tiles: {tiles}\")\n",
    "    \n",
    "    for tile in tiles:\n",
    "        tile_dir = data_dir/f\"{tile}\"\n",
    "        if not tile_dir.exists():\n",
    "            tile_dir.mkdir()\n",
    "        dest = tile_dir/f\"{tif.stem}_{tile}.tif\"\n",
    "        \n",
    "        m = mgrs.MGRS()\n",
    "        print(tile)\n",
    "        utm = m.MGRSToUTM(tile)\n",
    "\n",
    "        ulx = utm[2] - padding\n",
    "        uly = utm[3] + tile_side_len + padding \n",
    "        lrx = utm[2] + tile_side_len + padding\n",
    "        lry = utm[3] - padding\n",
    "        \n",
    "        \n",
    "        if utm[1] == 'N':\n",
    "            hemisphere = 'north'\n",
    "        else:\n",
    "            hemisphere = 'south'\n",
    "            \n",
    "        \n",
    "        crs = CRS.from_string(f'+proj=utm +zone={utm[0]} +{hemisphere}')\n",
    "        tile_epsg = crs.to_authority()[1]\n",
    "        if tile_epsg != tif_epsg:\n",
    "            reproj_path = tif.parent/f\"{tile_epsg}_reproj/{tif.stem}_{tile_epsg}.tif\"\n",
    "            reproj_paths.append(reproj_path)\n",
    "            reproj_dirs.append(reproj_path.parent)\n",
    "            if not reproj_path.exists():\n",
    "                if not reproj_path.parent.exists():\n",
    "                    reproj_path.parent.mkdir()\n",
    "                gdal.Warp(str(reproj_path), str(tif),\n",
    "                          srcSRS=f'EPSG:{tif_epsg}', dstSRS=f'EPSG:{tile_epsg}',\n",
    "                          xRes=resolution, yRes=resolution, targetAlignedPixels=True)\n",
    "            \n",
    "            dest = tile_dir/f\"{tif.stem}_{tile}.tif\"\n",
    "            \n",
    "            gdal.Translate(destName=str(dest), srcDS=str(reproj_path), projWin=[ulx, uly, lrx, lry])\n",
    "        else:\n",
    "            gdal.Translate(destName=str(dest), srcDS=str(tif), projWin=[ulx, uly, lrx, lry])\n",
    "            pass\n",
    "        \n",
    "for p in set(reproj_paths):\n",
    "    p.unlink()\n",
    "for p in set(reproj_dirs):\n",
    "    p.rmdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleanup temporary files and tiles containing no data**\n",
    "\n",
    "No-data filled tiles can occur if the portion of the original geotiff in an MGRS tile contained no-data to start with.\n",
    "\n",
    "*An improvement to this notebook would be to check for no-data prior to creating a tile, instead of deleting it later.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Do you wish to save or delete the original geotiffs?\")\n",
    "orig_tiffs = asfn.select_parameter(['save', 'delete'], '')\n",
    "display(orig_tiffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_paths = list(data_dir.glob('*/*.tif*'))\n",
    "\n",
    "removed = []\n",
    "for f in tile_paths:\n",
    "    raster = gdal.Open(str(f))\n",
    "    band = raster.ReadAsArray()\n",
    "    if np.count_nonzero(band) < 1:\n",
    "        f.unlink()\n",
    "        removed.append(f)\n",
    "\n",
    "if len(removed) == 0:\n",
    "    print(\"No tiles were removed due to no-data.\")\n",
    "else:\n",
    "    print(f\"{len(removed)} no-data tiles removed:\")\n",
    "    for f in removed:\n",
    "        print(f)     \n",
    "\n",
    "removed = set([p.parent for p in removed])\n",
    "for p in removed:\n",
    "    print(p.iterdir())\n",
    "    if len(list(p.iterdir())) == 0:\n",
    "        p.rmdir()\n",
    "        \n",
    "if orig_tiffs.value == 'delete':\n",
    "    for tif in tiff_paths:\n",
    "        tif.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the paths to the directories holding your MGRS tiles:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [i for i in list(data_dir.iterdir()) if not i.name.startswith('.')]:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MGRS_Tile_Data_Stack - Version 1.1.0 - November 2021*\n",
    "\n",
    "*Changes:*\n",
    "\n",
    "- *asf_notebook.py -> opensarlab-lib*\n",
    "- *url-widget*\n",
    "- *remove unused imports*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtc_analysis [conda env:.local-rtc_analysis]",
   "language": "python",
   "name": "conda-env-.local-rtc_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
