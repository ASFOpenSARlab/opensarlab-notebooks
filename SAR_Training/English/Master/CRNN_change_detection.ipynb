{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning in Earth Observation: Taizhou Change Detection\n",
    "\n",
    "![OpenSARlab notebook banner](NotebookAddons/blackboard-banner.png)\n",
    "\n",
    "### Lichao Mou, German Aerospace Center; Xiaoxiang Zhu, German Aerospace Center & Technical University Munich \n",
    "\n",
    "<img src=\"NotebookAddons/dlr-logo-png-transparent.png\" width=\"170\" align=\"right\" border=\"2\"/> <font size=\"3\"> \n",
    "    \n",
    "This notebook introduces you to the basic concepts of Deep Learning in Earth Observation. Specifically, it uses Convolutional Recurrent Neural Networks (CRNNs) to perform a multi-temporal change detection on multispectral data collected over Taizhou, China. The images are both 400 Ã— 400 pixels in size and show significant changes mainly related to city expansion, soil change, and varying water areas.\n",
    "\n",
    "This notebook will introduce the following data analysis concepts:\n",
    "\n",
    "- How to set up a convolutional recurrent deep network within the Python-based *keras/tensorflow* environment\n",
    "- How to use CRNNs to perform change detection on multi-temporal remote sensing data \n",
    "\n",
    "\n",
    "**Important Note about JupyterHub**\n",
    "\n",
    "Your JupyterHub server will automatically shutdown when left idle for more than 1 hour. Your notebooks will not be lost but you will have to restart their kernels and re-run them from the beginning. You will not be able to seamlessly continue running a partially run notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import url_widget as url_w\n",
    "notebookUrl = url_w.URLWidget()\n",
    "display(notebookUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "\n",
    "notebookUrl = notebookUrl.value\n",
    "user = !echo $JUPYTERHUB_USER\n",
    "env = !echo $CONDA_PREFIX\n",
    "if env[0] == '':\n",
    "    env[0] = 'Python 3 (base)'\n",
    "if env[0] != '/home/jovyan/.local/envs/machine_learning':\n",
    "    display(Markdown(f'<text style=color:red><strong>WARNING:</strong></text>'))\n",
    "    display(Markdown(f'<text style=color:red>This notebook should be run using the \"machine_learning\" conda environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>It is currently using the \"{env[0].split(\"/\")[-1]}\" environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Select \"machine_learning\" from the \"Change Kernel\" submenu of the \"Kernel\" menu.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>If the \"machine_learning\" environment is not present, use <a href=\"{notebookUrl.split(\"/user\")[0]}/user/{user[0]}/notebooks/conda_environments/Create_OSL_Conda_Environments.ipynb\"> Create_OSL_Conda_Environments.ipynb </a> to create it.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Note that you must restart your server after creating a new environment before it is usable by notebooks.</text>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 0. Importing Relevant Python Packages\n",
    "\n",
    "Our first step is to **import the necessary python libraries into your Jupyter Notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from pathlib import Path\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Nadam\n",
    "from keras.models import Model\n",
    "from keras.src.engine.input_layer import Input\n",
    "from keras.layers import Conv2D, Reshape, Activation, Concatenate, GRU, Dense, LSTM, SimpleRNN\n",
    "\n",
    "import opensarlab_lib as asfn\n",
    "asfn.jupytertheme_matplotlib_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Create a working directory for the analysis and change into it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path.cwd()/\"data_CRNN_change_detection\"\n",
    "\n",
    "if not base_path.exists():\n",
    "    base_path.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Preparation\n",
    "\n",
    "**load T1 and T2 images, training map, and test map. Save the images (T1.png and T2.png):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve DL-data from AWS\n",
    "\n",
    "work_dir = Path.cwd()/'DL-data'\n",
    "\n",
    "if not work_dir.exists():\n",
    "    work_dir.mkdir() \n",
    "    \n",
    "dl_data_path = work_dir/'Taizhou_3x3'\n",
    "!aws --region=us-west-2 --no-sign-request s3 cp s3://asf-jupyter-data-west/DL-data/Taizhou_3x3/ {dl_data_path} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 3\n",
    "num_bands = 6\n",
    "print('########## load data... ##########')\n",
    "data = sio.loadmat(str(dl_data_path/'TaizhouTm2000_norm.mat'))\n",
    "imgT1 = np.float32(data['imgT1'])\n",
    "data = sio.loadmat(str(dl_data_path/'TaizhouTm2003_norm.mat'))\n",
    "imgT2 = np.float32(data['imgT2'])\n",
    "\n",
    "data = sio.loadmat(str(dl_data_path/'TaizhouTraMapBinary.mat'))\n",
    "tra_map = np.uint8(data['tra_map_binary'])\n",
    "data = sio.loadmat(str(dl_data_path/'TaizhouTestMapBinary.mat'))\n",
    "test_map = np.uint8(data['test_map_binary'])\n",
    "\n",
    "print('the shape of T1 image is: {}'.format(imgT1.shape))\n",
    "print('the shape of T2 image is: {}'.format(imgT2.shape))\n",
    "\n",
    "plt.imshow(imgT1[:, :, [3, 2, 1]])\n",
    "plt.savefig(f\"{base_path}/T1.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(imgT2[:, :, [3, 2, 1]])\n",
    "plt.savefig(f\"{base_path}/T2.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "[rows, cols] = np.nonzero(tra_map)\n",
    "num_samples = len(rows)\n",
    "rows = np.reshape(rows, (num_samples, 1))\n",
    "cols = np.reshape(cols, (num_samples, 1))\n",
    "temp = np.concatenate((rows, cols), axis=1)\n",
    "np.random.shuffle(temp)\n",
    "rows = temp[:, 0].reshape((num_samples,))\n",
    "cols = temp[:, 1].reshape((num_samples,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 3x3 patches as training samples according to the training map\n",
    "\n",
    "**Create numpy arrays temporarily filled with zeros to hold our 3x3 patches:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tra_t1 = np.float32(\n",
    "    np.zeros([num_samples, patch_size, patch_size, num_bands]))\n",
    "x_tra_t2 = np.float32(\n",
    "    np.zeros([num_samples, patch_size, patch_size, num_bands]))\n",
    "\n",
    "y_tra = np.uint8(np.zeros([num_samples, ])) # ground truths for training samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Populate the zero-filled arrays with appropriate values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_samples):\n",
    "    patch = imgT1[rows[i]-int((patch_size-1)/2): rows[i]+int((patch_size-1)/2)+1,\n",
    "                  cols[i]-int((patch_size-1)/2): cols[i]+int((patch_size-1)/2)+1, :]\n",
    "    x_tra_t1[i, :, :, :] = patch\n",
    "    patch = imgT2[rows[i]-int((patch_size-1)/2): rows[i]+int((patch_size-1)/2)+1,\n",
    "                  cols[i]-int((patch_size-1)/2): cols[i]+int((patch_size-1)/2)+1, :]\n",
    "    x_tra_t2[i, :, :, :] = patch\n",
    "    y_tra[i] = tra_map[rows[i], cols[i]]-1\n",
    "\n",
    "[rows, cols] = np.nonzero(test_map)\n",
    "num_samples = len(rows)\n",
    "rows = np.reshape(rows, (num_samples, 1))\n",
    "cols = np.reshape(cols, (num_samples, 1))\n",
    "temp = np.concatenate((rows, cols), axis=1)\n",
    "np.random.shuffle(temp)\n",
    "rows = temp[:, 0].reshape((num_samples,))\n",
    "cols = temp[:, 1].reshape((num_samples,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample 3x3 patches as test samples according to the test map:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test samples from T1 image\n",
    "x_test_t1 = np.float32(\n",
    "    np.zeros([num_samples, patch_size, patch_size, num_bands]))\n",
    "# test samples from T2 image\n",
    "x_test_t2 = np.float32(\n",
    "    np.zeros([num_samples, patch_size, patch_size, num_bands]))\n",
    "# ground truths for test samples\n",
    "y_test = np.uint8(np.zeros([num_samples, ]))  \n",
    "for i in range(num_samples):\n",
    "    patch = imgT1[rows[i]-int((patch_size-1)/2): rows[i]+int((patch_size-1)/2)+1,\n",
    "                  cols[i]-int((patch_size-1)/2): cols[i]+int((patch_size-1)/2)+1, :]\n",
    "    x_test_t1[i, :, :, :] = patch\n",
    "    patch = imgT2[rows[i]-int((patch_size-1)/2): rows[i]+int((patch_size-1)/2)+1,\n",
    "                  cols[i]-int((patch_size-1)/2): cols[i]+int((patch_size-1)/2)+1, :]\n",
    "    x_test_t2[i, :, :, :] = patch\n",
    "    y_test[i] = test_map[rows[i], cols[i]]-1\n",
    "\n",
    "print('the shape of input tensors on training set is: {}'.format(x_tra_t1.shape))\n",
    "print('the shape of target tensor on training set is: {}'.format(y_tra.shape))\n",
    "print('the shape of input tensors on training set is: {}'.format(x_test_t1.shape))\n",
    "print('the shape of target tensor on training set is: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Building up the recurrent convolutional network \n",
    "\n",
    "**Write a function to build the network:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network():\n",
    "    # the T1 branch of the convolutional sub-network\n",
    "    input1 = Input(shape=(3, 3, 6))\n",
    "    x1 = Conv2D(filters=32, kernel_size=3, strides=1, padding='valid')(input1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Reshape(target_shape=(1, 32))(x1)\n",
    "\n",
    "    # the T2 branch of the convolutional sub-network\n",
    "    input2 = Input(shape=(3, 3, 6))\n",
    "    x2 = Conv2D(filters=32, kernel_size=3, strides=1, padding='valid')(input2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x2 = Reshape(target_shape=(1, 32))(x2)\n",
    "\n",
    "    # the recurrent sub-network\n",
    "    x = Concatenate(axis=1)([x1, x2])\n",
    "    #x = SimpleRNN(units = 128)(x)\n",
    "    x = LSTM(units=128)(x)\n",
    "    #x = GRU(units = 128)(x)\n",
    "    x = Dense(units=32, activation='relu')(x)\n",
    "    y = Dense(units=1, activation='sigmoid')(x)\n",
    "\n",
    "    net = Model(inputs=[input1, input2], outputs=y)\n",
    "\n",
    "    net.summary()\n",
    "\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Network training\n",
    "\n",
    "**Build the network:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('########## train the network... ##########')\n",
    "batch_size = 32\n",
    "nb_epoch = 200\n",
    "net = build_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the network:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nadam = Nadam(learning_rate=0.00002)\n",
    "net.compile(optimizer=nadam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "net_info = net.fit([x_tra_t1, x_tra_t2], y_tra,\n",
    "                   batch_size=batch_size, validation_split=0.1, epochs=nb_epoch)\n",
    "\n",
    "loss = net_info.history['loss']\n",
    "loss_val = net_info.history['val_loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot and save the results (loss.png):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss)\n",
    "plt.plot(loss_val)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.savefig(f\"{base_path}/loss.png\", bbox_inches='tight', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Test\n",
    "\n",
    "**Run the network on the test dataset. Save the change map probability and the change map binary (change_map_probability.png and change_map_binary.png):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('########## test... ##########')\n",
    "# testing on test set\n",
    "score = net.evaluate([x_test_t1, x_test_t2], y_test)\n",
    "print(score[1])\n",
    "\n",
    "print('########## running on the whole image... ##########')\n",
    "cnt = 0\n",
    "x_t1 = np.float32(np.zeros([400*400, patch_size, patch_size, num_bands]))\n",
    "x_t2 = np.float32(np.zeros([400*400, patch_size, patch_size, num_bands]))\n",
    "print('sampling patches...')\n",
    "for i in range(1, imgT1.shape[0]-1, 1):\n",
    "    for j in range(1, imgT1.shape[1]-1, 1):\n",
    "        patch = imgT1[i-int((patch_size-1)/2): i+int((patch_size-1)/2)+1,\n",
    "                      j-int((patch_size-1)/2): j+int((patch_size-1)/2)+1, :]\n",
    "        x_t1[cnt, :, :, :] = patch\n",
    "        patch = imgT2[i-int((patch_size-1)/2): i+int((patch_size-1)/2)+1,\n",
    "                      j-int((patch_size-1)/2): j+int((patch_size-1)/2)+1, :]\n",
    "        x_t2[cnt, :, :, :] = patch\n",
    "        cnt = cnt + 1\n",
    "print('sampling done.')\n",
    "pred = net.predict([x_t1, x_t2])\n",
    "change_map_prob = np.reshape(pred, (400, 400))\n",
    "plt.imshow(change_map_prob)\n",
    "plt.savefig(f\"{base_path}/change_map_probability.png\", dpi=200)\n",
    "plt.show()\n",
    "\n",
    "change_map_binary = np.where(change_map_prob < 0.5, 0, 1)\n",
    "plt.imshow(change_map_binary)\n",
    "plt.savefig(f\"{base_path}/change_map_binary.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*CRNN_change_detection.ipynb - Version 1.4.0 - February 2024*\n",
    "\n",
    "*Version Changes:*\n",
    "\n",
    "- *from keras.src.engine.input_layer import Input*\n",
    "- *Nadam(lr) -> Nadam(learning_rate)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.local-machine_learning]",
   "language": "python",
   "name": "conda-env-.local-machine_learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
