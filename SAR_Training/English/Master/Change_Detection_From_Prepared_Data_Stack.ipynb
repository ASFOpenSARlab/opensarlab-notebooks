{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![OpenSARlab notebook banner](NotebookAddons/blackboard-banner.png)\n",
    "\n",
    "# Change Point Detection in SAR Amplitude Time Series Data\n",
    "\n",
    "### Franz J Meyer; University of Alaska Fairbanks & Josef Kellndorfer, [Earth Big Data, LLC](http://earthbigdata.com/)\n",
    "<img src=\"NotebookAddons/UAFLogo_A_647.png\" width=\"170\" align=\"right\" />\n",
    "\n",
    "\n",
    "This notebook applies Change Point Detection on a deep multi-temporal SAR image data stack acquired by Sentinel-1. Specifically, the lab applies the method of *Cumulative Sums* to perform change detection on a 60 image deep Sentinel-1 data stack over Niamey, Niger.  \n",
    "\n",
    "**In this notebook we introduce the following data analysis concepts:**\n",
    "\n",
    "- How to use your own HyP3-generated data stack in a change detection effort\n",
    "- The concepts of time series slicing by month, year, and date.\n",
    "- The concepts and workflow of Cumulative Sum-based change point detection.\n",
    "- The identification of change dates for each identified change point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Important Note about JupyterHub**\n",
    "\n",
    "Your JupyterHub server will automatically shutdown when left idle for more than 1 hour. Your notebooks will not be lost but you will have to restart their kernels and re-run them from the beginning. You will not be able to seamlessly continue running a partially run notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%javascript\n",
    "var kernel = Jupyter.notebook.kernel;\n",
    "var command = [\"notebookUrl = \",\n",
    "               \"'\", window.location, \"'\" ].join('')\n",
    "kernel.execute(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "\n",
    "user = !echo $JUPYTERHUB_USER\n",
    "env = !echo $CONDA_PREFIX\n",
    "if env[0] == '':\n",
    "    env[0] = 'Python 3 (base)'\n",
    "if env[0] != '/home/jovyan/.local/envs/rtc_analysis':\n",
    "    display(Markdown(f'<text style=color:red><strong>WARNING:</strong></text>'))\n",
    "    display(Markdown(f'<text style=color:red>This notebook should be run using the \"rtc_analysis\" conda environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>It is currently using the \"{env[0].split(\"/\")[-1]}\" environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Select the \"rtc_analysis\" from the \"Change Kernel\" submenu of the \"Kernel\" menu.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>If the \"rtc_analysis\" environment is not present, use <a href=\"{notebookUrl.split(\"/user\")[0]}/user/{user[0]}/notebooks/conda_environments/Create_OSL_Conda_Environments.ipynb\"> Create_OSL_Conda_Environments.ipynb </a> to create it.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Note that you must restart your server after creating a new environment before it is usable by notebooks.</text>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing Relevant Python Packages\n",
    "\n",
    "Our first step is to **import the necessary python libraries into your Jupyter Notebook:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from pathlib import Path\n",
    "import json # for loads\n",
    "\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "\n",
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import opensarlab_lib as asfn\n",
    "asfn.jupytertheme_matplotlib_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Your Prepared Data Stack Into the Notebook\n",
    "\n",
    "This notebook assumes that you've prepared your own data stack of **RTC image products** over your personal area of interest. This can be done using the **Prepare_Data_Stack_Hyp3_v2** and **Subset_Data_Stack notebooks**.\n",
    "    \n",
    "This notebook expects [Radiometric Terrain Corrected](https://media.asf.alaska.edu/uploads/RTC/rtc_atbd_v1.2_final.pdf) (RTC) image products as input, so be sure to select an RTC process when creating the subscription for your input data within HyP3. Prefer a **unique orbit geometry** (ascending or descending) to keep geometric differences between images low. \n",
    "\n",
    "**Begin by writing a function to retrieve and the absolute paths to each of our tiffs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tiff_paths(paths):\n",
    "    tiff_paths = !ls $paths | sort -t_ -k5,5\n",
    "    return tiff_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select the directory holding your tiffs**\n",
    "- Click the `Select` button\n",
    "- Navigate to your data directory\n",
    "- Click the `Select` button\n",
    "- Confirm that the desired path appears in green text\n",
    "- Click the `Change` button to alter your selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = FileChooser('/home/jovyan/notebooks')\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Determine the path to the analysis directory containing the tiff directory:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_dir = Path(fc.selected_path)\n",
    "analysis_dir = tiff_dir.parent\n",
    "print(f\"analysis_dir: {analysis_dir}\")\n",
    "\n",
    "paths = tiff_dir/\"*.tif*\"\n",
    "tiff_paths = get_tiff_paths(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a wildcard path to the tiffs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildcard_path = f\"{tiff_dir}/*.tif*\"\n",
    "print(wildcard_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write a function to extract the tiff dates from a wildcard path:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(paths):\n",
    "    dates = []\n",
    "    pths = list(tiff_dir.rglob('*.tif*'))\n",
    "\n",
    "    for p in pths:\n",
    "        filename = p.name.split('_')\n",
    "    \n",
    "        for chunk in filename:\n",
    "            if len(chunk) == 15 and 'T' in chunk:\n",
    "                date = chunk.split('T')[0]\n",
    "                dates.append(date)\n",
    "                break\n",
    "            elif len(chunk) == 8:\n",
    "                try:\n",
    "                    int(chunk)\n",
    "                    dates.append(chunk)\n",
    "                    break\n",
    "                except ValueError:\n",
    "                    continue              \n",
    "    dates.sort()\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Call get_dates() to collect the product acquisition dates:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = get_dates(tiff_dir)\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gather the upper-left and lower-right corner coordinates of the data stack:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = [[], []]\n",
    "info = (gdal.Info(tiff_paths[0], options = ['-json']))\n",
    "info = json.dumps(info)\n",
    "coords[0] = (json.loads(info))['cornerCoordinates']['upperLeft']\n",
    "coords[1] = (json.loads(info))['cornerCoordinates']['lowerRight']\n",
    "print(coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grab the stack's UTM zone.**\n",
    "\n",
    "Note that any UTM zone conflicts should already have been handled in the Prepare_Data_Stack_Hyp3 notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utm = json.loads(info)['coordinateSystem']['wkt'].split('ID')[-1].split(',')[1][0:-2]\n",
    "print(f\"UTM Zone: {utm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now we stack up the data by creating a virtual raster table with links to all subset data files.\n",
    "\n",
    "**Create the virtual raster table for the subset GeoTiffs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = Path(f\"{analysis_dir}/raster_stack.vrt\")\n",
    "!gdalbuildvrt -separate $image_file $wildcard_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Now You Can Work With Your Data\n",
    "\n",
    "Now you are ready to perform time series change detection on your data stack.\n",
    "\n",
    "### 3.1 Create an index of timedelta64 data with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some indices for plotting\n",
    "time_index = pd.DatetimeIndex(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the bands and dates for all images in the virtual raster table (VRT):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 1\n",
    "print(f\"Bands and dates for {image_file}\")\n",
    "for i in time_index:\n",
    "    print(\"{:4d} {}\".format(j, i.date()), end=' ')\n",
    "    j += 1\n",
    "    if j%5 == 1: print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### 3.2 Open Your Data Stack with gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = gdal.Open(str(image_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the bands, pixels, and lines:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of  bands: {img.RasterCount}\")\n",
    "print(f\"Number of pixels: {img.RasterXSize}\")\n",
    "print(f\"Number of  lines: {img.RasterYSize}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.3 Create a masked raster stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_stack = img.ReadAsArray()\n",
    "raster_stack_masked = np.ma.masked_where(raster_stack==0, raster_stack)\n",
    "del raster_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Cumulative Sum-based Change Detection Across an Entire Image\n",
    "\n",
    "Using numpy arrays we can apply the concept of **cumulative sum change detection** analysis effectively on the entire image stack. We take advantage of array slicing and axis-based computing in numpy. **Axis 0 is the time domain** in our raster stacks.\n",
    "    \n",
    "---\n",
    "### 4.1 Create our time series stack\n",
    "\n",
    "**Calculate the dB scale:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = 10.*np.ma.log10(raster_stack_masked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it makes sense to **extract a reduced time span** from the full time series to reduce the number of different change objects in a scene. In the following, we extract a shorter time span:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_picker = asfn.gui_date_picker(dates)\n",
    "date_picker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_dates = date_picker.value\n",
    "subset_dates = pd.DatetimeIndex(subset_dates)\n",
    "date_index_subset = np.where((time_index>=subset_dates[0]) & (time_index<=subset_dates[1]))\n",
    "db_subset = np.squeeze(db[date_index_subset, :, :])\n",
    "time_index_subset = time_index[date_index_subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "band_number = 0\n",
    "vmin = np.percentile(db_subset[band_number], 5)\n",
    "vmax = np.percentile(db_subset[band_number], 95)\n",
    "plt.title('Band  {} {}'.format(band_number+1, time_index_subset[band_number].date()))\n",
    "plt.imshow(db_subset[0], cmap='gray', vmin=vmin, vmax=vmax)\n",
    "cbar = plt.colorbar()\n",
    "_ = cbar.ax.set_xlabel('dB', fontsize='12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4.2 Calculate Mean Across Time Series to Prepare for Calculation of Cummulative Sum $S$:\n",
    "\n",
    "**Write a function to convert our plots into GeoTiffs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geotiff_from_plot(source_image, out_filename, extent, utm, cmap=None, vmin=None, vmax=None, interpolation=None, dpi=300):\n",
    "    assert \".\" not in out_filename, 'Error: Do not include the file extension in out_filename'\n",
    "    assert type(extent) == list and len(extent) == 2 and len(extent[0]) == 2 and len(\n",
    "        extent[1]) == 2, 'Error: extent must be a list in the form [[upper_left_x, upper_left_y], [lower_right_x, lower_right_y]]'\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.axis('off')\n",
    "    plt.imshow(source_image, cmap=cmap, vmin=vmin, vmax=vmax, interpolation=interpolation)\n",
    "    temp = Path(f\"{out_filename}_temp.png\")\n",
    "    plt.savefig(temp, dpi=dpi, transparent='true', bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "    cmd = f\"gdal_translate -of Gtiff -a_ullr {extent[0][0]} {extent[0][1]} {extent[1][0]} {extent[1][1]} -a_srs EPSG:{utm} {temp} {out_filename}.tiff\"\n",
    "    !{cmd}\n",
    "    try:\n",
    "        temp.unlink()\n",
    "    except FileNotFoundError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a directory in which to store our plots and animations:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = analysis_dir/'plots_and_animations'\n",
    "\n",
    "if not output_path.exists():\n",
    "    output_path.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the time-series mean and save as a png (time_series_mean.png):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_mean = np.mean(db_subset, axis=0)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(db_mean, cmap='gray')\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_xlabel('dB', fontsize='12')\n",
    "plt.savefig(f\"{output_path}/time_series_mean.png\", dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the time-series mean as a GeoTiff (time_series_mean.tiff):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(db_mean, f\"{output_path}/time_series_mean\", coords, utm, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate the residuals and plot residuals\\[0\\]. Save it as a png (residuals.png):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = db_subset - db_mean\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(residuals[0])\n",
    "plt.title('Residuals for Band  {} {}'.format(band_number+1, time_index_subset[band_number].date()))\n",
    "cbar = plt.colorbar()\n",
    "_ = cbar.ax.set_xlabel('dB', fontsize='12')\n",
    "plt.savefig(f\"{output_path}/residuals.png\", dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the residuals\\[0\\] as a GeoTiff (residuals.tiff):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(residuals[0], f\"{output_path}/residuals\", coords, utm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4.3 Calculate Cummulative Sum $S$ as well as Change Magnitude $S_{diff}$:\n",
    "\n",
    "**Plot Smin, Smax, and the change magnitude and save a png of the plots (Smin_Smax_Sdiff.png):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summation = np.cumsum(residuals, axis=0)\n",
    "summation_max = np.max(summation, axis=0)\n",
    "summation_min = np.min(summation, axis=0)\n",
    "change_mag = summation_max - summation_min\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "vmin = np.percentile(summation_min.flatten(), 3)\n",
    "vmax = np.percentile(summation_max.flatten(), 97)\n",
    "max_plot = ax[0].imshow(summation_max, vmin=vmin, vmax=vmax)\n",
    "ax[0].set_title('$S_{max}$')\n",
    "ax[1].imshow(summation_min, vmin=vmin, vmax=vmax)\n",
    "ax[1].set_title('$S_{min}$')\n",
    "ax[2].imshow(change_mag, vmin=vmin, vmax=vmax)\n",
    "ax[2].set_title('Change Magnitude')\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.02, 0.7])\n",
    "cbar = fig.colorbar(max_plot, cax=cbar_ax)\n",
    "_ = cbar.ax.set_xlabel('dB', fontsize='12')\n",
    "plt.savefig(f\"{output_path}/Smin_Smax_Sdiff.png\", dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Smax as a GeoTiff (Smax.tiff):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(summation_max, f\"{output_path}/Smax\", coords, utm, vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Smin as a GeoTiff (Smin.tiff):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(summation_min, f\"{output_path}/Smin\", coords, utm, vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the change magnitude as a GeoTiff (Sdiff.tiff):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(change_mag, f\"{output_path}/Sdiff\", coords, utm, vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4.4 Mask $S_{diff}$ With a-priori Threshold To Idenfity Change Candidates:\n",
    "\n",
    "To identified change candidate pixels, we can threshold $S_{diff}$ to reduce computation of the bootstrapping. For land cover change, we would not expect more than 5-10% change pixels in a landscape. So, if the test region is reasonably large, setting a threshold for expected change to 10% is appropriate. In our example, we'll start out with a very conservative threshold of 50%.\n",
    "\n",
    "**Plot and tsave the histogram and CDF for the change magnitude (change_mag_histogram_CDF.png):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "fig = plt.figure(figsize=(14, 6)) # Initialize figure with a size\n",
    "ax1 = fig.add_subplot(121)  # 121 determines: 2 rows, 2 plots, first plot\n",
    "ax2 = fig.add_subplot(122)\n",
    "# Second plot: Histogram\n",
    "# IMPORTANT: To get a histogram, we first need to *flatten* \n",
    "# the two-dimensional image into a one-dimensional vector.\n",
    "histogram = ax1.hist(change_mag.flatten(), bins=200, range=(0, np.max(change_mag)))\n",
    "ax1.xaxis.set_label_text('Change Magnitude')\n",
    "ax1.set_title('Change Magnitude Histogram')\n",
    "plt.grid()\n",
    "n, bins, patches = ax2.hist(change_mag.flatten(), bins=200, range=(0, np.max(change_mag)), cumulative='True', density='True', histtype='step', label='Empirical')\n",
    "ax2.xaxis.set_label_text('Change Magnitude')\n",
    "ax2.set_title('Change Magnitude CDF')\n",
    "plt.grid()\n",
    "plt.savefig(f\"{output_path}/change_mag_histogram_CDF\", dpi=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precentile = 0.5\n",
    "out_indicies = np.where(n>precentile)\n",
    "threshold_index = np.min(out_indicies)\n",
    "threshold = bins[threshold_index]\n",
    "print('At the {}% percentile, the threshold value is {:2.2f}'.format(precentile*100, threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this threshold, we can **visualize our change candidate areas and save them as a png (change_candidate.png):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_mag_mask = change_mag < threshold\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Change Candidate Areas (black)')\n",
    "_ = plt.imshow(change_mag_mask, cmap='gray')\n",
    "plt.savefig(f\"{output_path}/change_candidate.png\", dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the change candidate areas as a GeoTiff (change_canididate.tiff):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(change_mag_mask, f\"{output_path}/change_canididate\", coords, utm, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4.5 Bootstrapping to Prepare for Change Point Selection:\n",
    "\n",
    "We can now perform bootstrapping over the candidate pixels. The workflow is as follows:\n",
    "\n",
    "- Filter our residuals to the change candidate pixels\n",
    "- Perform bootstrapping over candidate pixels\n",
    "\n",
    "For efficient computing we permutate the index of the time axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_mask = np.broadcast_to(change_mag_mask , residuals.shape)\n",
    "residuals_masked = np.ma.array(residuals, mask=residuals_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On the masked time series stack of residuals, we can re-compute the cumulative sums:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summation_masked = np.ma.cumsum(residuals_masked, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the masked Smax, Smin, and change magnitude. Save them as a png (masked_Smax_Smin_Sdiff.png):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summation_masked_max = np.ma.max(summation_masked, axis=0)\n",
    "summation_masked_min = np.ma.min(summation_masked, axis=0)\n",
    "change_mag_masked = summation_masked_max - summation_masked_min\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "vmin = summation_masked_min.min()\n",
    "vmax = summation_masked_max.max()\n",
    "masked_sum_max_plot = ax[0].imshow(summation_masked_max, vmin=vmin, vmax=vmax)\n",
    "ax[0].set_title('Masked $S_{max}$')\n",
    "ax[1].imshow(summation_masked_min, vmin=vmin, vmax=vmax)\n",
    "ax[1].set_title('Masked $S_{min}$')\n",
    "ax[2].imshow(change_mag_masked, vmin=vmin, vmax=vmax)\n",
    "ax[2].set_title('Masked Change Magnitude')\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.02, 0.7])\n",
    "cbar = fig.colorbar(masked_sum_max_plot, cax=cbar_ax)\n",
    "_ = cbar.ax.set_xlabel('dB', fontsize='12')\n",
    "plt.savefig(f\"{output_path}/masked_Smax_Smin_Sdiff.png\", dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the masked Smax as a GeoTiff (masked_Smax.tiff):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(summation_masked_max, f\"{output_path}/masked_Smax\", coords, utm, vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the masked Smin as a GeoTiff (masked_Smin.tiff):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(summation_masked_min, f\"{output_path}/masked_Smin\", coords, utm, vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the masked change magnitude as a GeoTiff (masked_Sdiff.tiff):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(change_mag_masked, f\"{output_path}/masked_Sdiff\", coords, utm, vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let's perform bootstrapping:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = np.random.permutation(residuals_masked.shape[0])\n",
    "residuals_random = residuals_masked[random_index,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bootstraps = 100  # bootstrap sample size\n",
    "\n",
    "# to keep track of the maxium Sdiff of the bootstrapped sample:\n",
    "change_mag_random_max = np.ma.copy(change_mag_masked) \n",
    "change_mag_random_max[~change_mag_random_max.mask]=0\n",
    "# to compute the Sdiff sums of the bootstrapped sample:\n",
    "change_mag_random_sum = np.ma.copy(change_mag_masked) \n",
    "change_mag_random_sum[~change_mag_random_max.mask]=0\n",
    "# to keep track of the count of the bootstrapped sample\n",
    "n_change_mag_gt_change_mag_random = np.ma.copy(change_mag_masked) \n",
    "n_change_mag_gt_change_mag_random[~n_change_mag_gt_change_mag_random.mask]=0\n",
    "print(\"Running Bootstrapping for %4.1f iterations ...\" % (n_bootstraps))\n",
    "for i in range(n_bootstraps):\n",
    "    # For efficiency, we shuffle the time axis index and use that \n",
    "    #to randomize the masked array\n",
    "    random_index = np.random.permutation(residuals_masked.shape[0])\n",
    "    # Randomize the time step of the residuals\n",
    "    residuals_random = residuals_masked[random_index,:,:]  \n",
    "    summation_random = np.ma.cumsum(residuals_random, axis=0)\n",
    "    summation_random_max = np.ma.max(summation_random, axis=0)\n",
    "    summation_random_min = np.ma.min(summation_random, axis=0)\n",
    "    change_mag_random = summation_random_max - summation_random_min\n",
    "    change_mag_random_sum += change_mag_random\n",
    "    change_mag_random_max[np.ma.greater(change_mag_random, change_mag_random_max)] = \\\n",
    "    change_mag_random[np.ma.greater(change_mag_random, change_mag_random_max)]\n",
    "    n_change_mag_gt_change_mag_random[np.ma.greater(change_mag_masked, change_mag_random)] += 1\n",
    "    if ((i+1)/n_bootstraps*100)%10 == 0:\n",
    "        print(\"\\r%4.1f%% completed\" % ((i+1)/n_bootstraps*100), end='\\r', flush=True)\n",
    "print(f\"Bootstrapping Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4.6 Extract Confidence Metrics and Select Final Change Points:\n",
    "\n",
    "**We first compute for all pixels the confidence level $CL$, the change point significance metric $CP_{significance}$ and the product of the two as our confidence metric for identified change points. Plot the results and save them as a png (confidenceLevel_CPSignificance.png):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_level = n_change_mag_gt_change_mag_random / n_bootstraps\n",
    "change_point_significance = 1.- (change_mag_random_sum / n_bootstraps)/change_mag \n",
    "#Plot\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "a = ax[0].imshow(confidence_level*100)\n",
    "cbar0 = fig.colorbar(a, ax=ax[0])\n",
    "_ = cbar0.ax.set_xlabel('%', fontsize='12')\n",
    "ax[0].set_title('Confidence Level %')\n",
    "a = ax[1].imshow(change_point_significance)\n",
    "_ = fig.colorbar(a, ax=ax[1])\n",
    "ax[1].set_title('Significance')\n",
    "a = ax[2].imshow(confidence_level*change_point_significance)\n",
    "_ = fig.colorbar(a, ax=ax[2])\n",
    "_ = ax[2].set_title('CL x S')\n",
    "plt.savefig(f\"{output_path}/confidenceLevel_CPSignificance.png\", dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the confidence level as a GeoTiff (confidence_level.tiff):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(confidence_level*100, f\"{output_path}/confidence_level\", coords, utm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the change point significance as a GeoTiff (cp_significance.tiff):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(change_point_significance, f\"{output_path}/cp_significance\", coords, utm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the change point significance as a GeoTiff (cp_significance.tiff):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(confidence_level*change_point_significance, f\"{output_path}/confidenceLevel_x_CPSignificance\", coords, utm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we can set a change point threshold to identify most likely change pixels in our map of change candidates:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_point_threshold = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the detected change pixels based on the change_point_threshold and save it as a png (detected_change_pixels.png):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plt.title('Detected Change Pixels based on Threshold %2.2f' % (change_point_threshold))\n",
    "a = ax.imshow(confidence_level*change_point_significance < change_point_threshold, cmap='cool')\n",
    "plt.savefig(f\"{output_path}/detected_change_pixels.png\", dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the detected_change_pixels as a GeoTiff (detected_change_pixels.tiff):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(confidence_level*change_point_significance < change_point_threshold, f\"{output_path}/detected_change_pixels\", coords, utm, cmap='cool')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### 4.7 Derive Timing of Change for Each Change Pixel:\n",
    "\n",
    "Our last step in the identification of the change points is to extract the timing of the change. We will produce a raster layer that shows the band number of this first date after a change was detected. We will make use of the numpy indexing scheme. First, we create a combined mask of the first threshold and the identified change points after the bootstrapping. For this we use the numpy \"mask_or\" operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a mask of our change points from the new threhold and the previous mask\n",
    "change_point_mask = np.ma.mask_or(confidence_level*change_point_significance < change_point_threshold, confidence_level.mask)\n",
    "# Broadcast the mask to the shape of the masked S curves\n",
    "change_point_mask2 = np.broadcast_to(change_point_mask, summation_masked.shape)\n",
    "# Make a numpy masked array with this mask\n",
    "change_point_raster = np.ma.array(summation_masked.data, mask=change_point_mask2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve the dates of the change points we find the band indices in the time series along the time axis where the maximum of the cumulative sums was located. Numpy offers the \"argmax\" function for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_point_index = np.ma.argmax(change_point_raster, axis=0)\n",
    "change_indices = list(np.unique(change_point_index))\n",
    "print(change_indices)\n",
    "change_indices.remove(0)\n",
    "print(change_indices)\n",
    "# Look up the dates from the indices to get the change dates\n",
    "all_dates = time_index_subset\n",
    "change_dates = [str(all_dates[x].date()) for x in change_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lastly, we plot the change dates by showing the $CP_{index}$ raster and label the change dates. Save the plot as a png (change_dates.png):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ticks = change_indices\n",
    "ticklabels = change_dates\n",
    "\n",
    "cmap = plt.cm.get_cmap('tab20', ticks[-1])\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "cax = ax.imshow(change_point_index, interpolation='nearest', cmap=cmap)\n",
    "# fig.subplots_adjust(right=0.8)\n",
    "# cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "# fig.colorbar(p,cax=cbar_ax)\n",
    "\n",
    "ax.set_title('Dates of Change')\n",
    "# cbar = fig.colorbar(cax,ticks=ticks)\n",
    "cbar = fig.colorbar(cax, ticks=ticks, orientation='horizontal')\n",
    "_ = cbar.ax.set_xticklabels(ticklabels, size=10, rotation=45, ha='right')\n",
    "plt.savefig(f\"{output_path}/change_dates.png\", dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the change dates as a GeoTiff (change_dates.tiff):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(change_point_index, f\"{output_path}/change_dates\", coords, utm, cmap=cmap, interpolation='nearest', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*GEOS 657 Microwave Remote Sensing - Version 1.4.1 - November 2021*\n",
    " \n",
    "*Version Changes*\n",
    "\n",
    "- asf_notebook -> opensarlab_lib\n",
    "- html -> markdown"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtc_analysis",
   "language": "python",
   "name": "conda-env-.local-rtc_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
