{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"NotebookAddons/blackboard-banner.jpg\" width=\"100%\" />\n",
    "<font face=\"Calibri\">\n",
    "<br>\n",
    "<font size=\"5\"> <b>Exploring SAR Time Series Data for Flood Monitoring</b></font>\n",
    "\n",
    "<br>\n",
    "<font size=\"4\"> <b> Franz J Meyer; University of Alaska Fairbanks & Josef Kellndorfer, <a href=\"http://earthbigdata.com/\" target=\"_blank\">Earth Big Data, LLC</a> </b> <br>\n",
    "<img style=\"padding:7px;\" src=\"NotebookAddons/UAFLogo_A_647.png\" width=\"170\" align=\"right\" /></font>\n",
    "\n",
    "<font size=\"3\">This notebook introduces you to the time series signatures associated with flooding. The data analysis is doen in the framework of *Jupyter Notebooks*. The Jupyter Notebook environment is easy to launch in any web browser for interactive data exploration with provided or new training data. Notebooks are comprised of text written in a combination of executable python code and markdown formatting including latex style mathematical equations. Another advantage of Jupyter Notebooks is that they can easily be expanded, changed, and shared with new data sets or newly available time series steps. Therefore, they provide an excellent basis for collaborative and repeatable data analysis. <br>\n",
    "\n",
    "<b>This notebook covers the following data analysis concepts:</b>\n",
    "\n",
    "- How to load time series stacks into Jupyter Notebooks and how to explore image content using basic functions such as mean value calculation and histogram analysis.\n",
    "- How to extract time series information for individual pixels of an image.\n",
    "- Typical time series signatures over forests and deforestation sites.\n",
    "</font>\n",
    "\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"5\" color='rgba(200,0,0,0.2)'> <b>Important Notes about JupyterHub</b> </font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"> <b>Your JupyterHub server will automatically shutdown when left idle for more than 1 hour. Your notebooks will not be lost but you will have to restart their kernels and re-run them from the beginning. You will not be able to seamlessly continue running a partially run notebook.</b> </font>\n",
    "<br><br>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "\n",
    "env = !echo $CONDA_PREFIX\n",
    "if env[0] == '':\n",
    "    env[0] = 'Python 3 (base)'\n",
    "if env[0] != '/home/jovyan/.local/envs/rtc_analysis':\n",
    "    display(Markdown(f'<text style=color:red><strong>WARNING:</strong></text>'))\n",
    "    display(Markdown(f'<text style=color:red>This notebook should be run using the \"rtc_analysis\" conda environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>It is currently using the \"{env[0].split(\"/\")[-1]}\" environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Select the \"rtc_analysis\" from the \"Change Kernel\" submenu of the \"Kernel\" menu.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>If the \"rtc_analysis\" environment is not present, use Create_OSL_Conda_Environments.ipynb to create it.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Note that you must restart your server after creating a new environment before it is usable by notebooks.</text>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\">\n",
    "\n",
    "<font size=\"5\"> <b> 0. Importing Relevant Python Packages </b> </font>\n",
    "\n",
    "<font size=\"3\">In this notebook we will use the following scientific libraries:\n",
    "\n",
    "<ol type=\"1\">\n",
    "    <li> <b><a href=\"https://pandas.pydata.org/\" target=\"_blank\">Pandas</a></b> is a Python library that provides high-level data structures and a vast variety of tools for analysis. The great feature of this package is the ability to translate rather complex operations with data into one or two commands. Pandas contains many built-in methods for filtering and combining data, as well as the time-series functionality. </li>\n",
    "    <li> <b><a href=\"https://www.gdal.org/\" target=\"_blank\">GDAL</a></b> is a software library for reading and writing raster and vector geospatial data formats. It includes a collection of programs tailored for geospatial data processing. Most modern GIS systems (such as ArcGIS or QGIS) use GDAL in the background.</li>\n",
    "    <li> <b><a href=\"http://www.numpy.org/\" target=\"_blank\">NumPy</a></b> is one of the principal packages for scientific applications of Python. It is intended for processing large multidimensional arrays and matrices, and an extensive collection of high-level mathematical functions and implemented methods makes it possible to perform various operations with these objects. </li>\n",
    "    <li> <b><a href=\"https://matplotlib.org/index.html\" target=\"_blank\">Matplotlib</a></b> is a low-level library for creating two-dimensional diagrams and graphs. With its help, you can build diverse charts, from histograms and scatterplots to non-Cartesian coordinates graphs. Moreover, many popular plotting libraries are designed to work in conjunction with matplotlib. </li>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Python version:\n",
    "import sys\n",
    "pn = sys.version_info[0]\n",
    "\n",
    "import os # for chdir, getcwd, path.basename, path.exists\n",
    "from glob import glob\n",
    "from math import ceil\n",
    "\n",
    "import pandas as pd # for DatetimeIndex\n",
    "from osgeo import gdal # for GetRasterBand, Open, ReadAsArray\n",
    "import numpy as np #for log10, mean, percentile, power\n",
    "import pyproj\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt # for add_subplot, axis, figure, imshow, legend, plot, set_axis_off, set_data,\n",
    "                                # set_title, set_xlabel, set_ylabel, set_ylim, subplots, title, twinx\n",
    "import matplotlib.patches as patches  # for Rectangle\n",
    "import matplotlib.animation as an # for FuncAnimation\n",
    "from matplotlib import rc\n",
    "\n",
    "from IPython.display import HTML\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "if pn == 2:\n",
    "    import cStringIO #needed for the image checkboxes\n",
    "elif pn == 3:\n",
    "    import io\n",
    "    import base64\n",
    "    \n",
    "import asf_notebook as asfn\n",
    "\n",
    "# For exporting:\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\">\n",
    "\n",
    "<font size=\"5\"> <b> 1. Load Data Stack</b> </font> <img src=\"https://www.elcomercio.com/files/article_main/uploads/2017/03/29/58dc6b8cd9665.jpeg\" width=\"350\" style=\"padding:5px;\" align=\"right\" /> \n",
    "\n",
    "<font size=\"3\"> This notebook will be using a Sentinel-1 data stack (VV only) north of Guayaquil. \n",
    "\n",
    "Ecuador and other countries in western South America experienced widespread <b>flooding</b> during the 2016-2017 winter (see picture by Bolívar Velasco/EL COMERCIO). <a href='https://www.eluniverso.com/noticias/2017/03/01/nota/6068059/arboles-se-caen-medio-torrencial-lluvia-ayer'>Guayaquil in Guayas</a> was among the affected regions, as precipitation in March 2017 was well above average. The increased precipitation was associated with a Coastal Niño event.\n",
    "<br><br>\n",
    "We will study the extent and progression of the flooding in the year 2016-2017 just north of Guayaquil.\n",
    "<br><br>\n",
    "<b>Begin by writing a function to retrieve the absolute paths to each of our tiffs:</b>\n",
    "</font></font>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tiff_paths(paths):\n",
    "    tiff_paths = !ls $paths | sort -t_ -k5,5\n",
    "    return tiff_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Enter the path to the directory holding your tiffs:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    print(\"Enter the absolute path to the directory holding your tiffs.\")\n",
    "    print(\"NOTE: the tiffs should all be in the same polarization.\")\n",
    "    tiff_dir = input()\n",
    "    paths = f\"{tiff_dir}/*.tif\"\n",
    "    if os.path.exists(tiff_dir):\n",
    "        tiff_paths = get_tiff_paths(paths)\n",
    "        if len(tiff_paths) < 1:\n",
    "            print(f\"{tiff_dir} exists but contains no tifs.\")\n",
    "            print(\"You will not be able to proceed until tifs are prepared.\")\n",
    "        break\n",
    "    else:\n",
    "        print(f\"\\n{tiff_dir} does not exist.\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Determine the path to the analysis directory containing the tiff directory:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_dir = os.path.dirname(tiff_dir)\n",
    "print(analysis_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create a wildcard path to the tiffs (in VV polarity):</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_options = [f\"{tiff_dir}/*VV.tif*\", f\"{tiff_dir}/*vv.tif*\",\n",
    "               f\"{tiff_dir}/*VH.tif*\", f\"{tiff_dir}/*vh.tif*\"]\n",
    "for p in path_options:\n",
    "    pths = glob(p)\n",
    "    if pths:\n",
    "        wildcard_path = p\n",
    "        break\n",
    "print(wildcard_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Write a function to extract the tiff dates from a wildcard path.</b> Note that product naming conventions are not always consistent so it may be necessary to alter \"date = p.split('/')[-1].split(\"_\")[3].split('T')[0]\" to parse the date from the filenames correctly.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(pths):\n",
    "    dates = []\n",
    "    for p in pths:\n",
    "        for name_chunk in p.split('/')[-1].split('_'):\n",
    "            nums = list(range(48, 58))\n",
    "            if len(name_chunk) == 15 and ord(name_chunk[0]) in nums: \n",
    "                date = name_chunk.split('T')[0]\n",
    "                dates.append(date)\n",
    "                break\n",
    "    dates.sort()\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Call get_dates() to collect the product acquisition dates:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [ os.path.basename(d).split('_')[0] for d in pths ]\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"5\"> <b> 2. Create the VRT </b> </font> \n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>Parse the polarization from a tiff name and define a path to the vrt:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarization = get_tiff_paths(wildcard_path)[0].split('.')[-2][-2:]\n",
    "print(polarization)\n",
    "raster_path = f\"{analysis_dir}/raster_stack_{polarization}.vrt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create the virtual raster table for the GeoTiffs:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdalbuildvrt -separate $raster_path $wildcard_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create Pandas time index:</b> and print the dates</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_index = pd.DatetimeIndex(dates)\n",
    "\n",
    "for jacqdate, acqdate in enumerate(time_index):\n",
    "    print('{:4d} {}'.format(jacqdate, acqdate.date()),end=' ')\n",
    "    if (jacqdate % 5 == 4): print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<font face=\"Calibri\" size=\"5\"> <b> 3. Data exploration with an animation </b> </font> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Read the data</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = gdal.Open(raster_path)\n",
    "band = img.GetRasterBand(1)\n",
    "raster0 = band.ReadAsArray()\n",
    "band_number = 0 # Needed for updates\n",
    "rasterstack = img.ReadAsArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">Before analyzing the data, decide whether to use <b>linear or logarithmic scaling</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_dB = False\n",
    "\n",
    "def convert(raster, use_dB=use_dB):\n",
    "    # some Python trickery: \n",
    "    # if you call the convert function later, you can set the keyword \n",
    "    # argument use_dB to True or False\n",
    "    # if you do not provide a keyword argument, the value that you set\n",
    "    # above (when defining the function) is used\n",
    "    if use_dB:\n",
    "        return 10 * np.log10(raster)\n",
    "    else:\n",
    "        return raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Let's create an <b>animation</b> to get an idea of where and when flooding might have occurred.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "figani = plt.figure(figsize=(10, 5))\n",
    "axani = figani.subplots()\n",
    "axani.axis('off')\n",
    "\n",
    "rasterstack_ = convert(rasterstack)\n",
    "\n",
    "imani = axani.imshow(rasterstack_[0,...], cmap='gray', vmin=np.nanpercentile(rasterstack_, 1), \n",
    "               vmax=np.nanpercentile(rasterstack_, 99))\n",
    "axani.set_title(\"{}\".format(time_index[0].date()))\n",
    "\n",
    "def animate(i):\n",
    "    axani.set_title(\"{}\".format(time_index[i].date()))\n",
    "    imani.set_data(rasterstack_[i,...])\n",
    "\n",
    "# Interval is given in milliseconds\n",
    "ani = an.FuncAnimation(figani, animate, frames=rasterstack_.shape[0], interval=300)\n",
    "rc('animation', embed_limit=40971520.0)  # We need to increase the limit maybe to show the entire animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Render</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>EXERCISE</u>:  </font> Backscatter dynamics</b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> What is the most striking change in February 2017? Can you explain why the backscatter changes the way it does during that period?\n",
    "</font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>\n",
    "<font face=\"Calibri\" size=\"5\"> <b> 4. Create Minimum Image to Identify Inundated Areas </b> </font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"> As flooding is often associated with very low backscater, we first compute the minimum backscatter for each pixel to get a first impression of areas that could have been flooded during the entire period. </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"> The following line <b>calculates the minimum backscatter per pixel</b> across the time series: </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_min = np.nanmin(convert(rasterstack), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 4.2 Visualize the Minimum Image with Curser Information Included </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> We will now visualize the minimum image in a way that we can move our mouse over the image and visualize the line/sample image coordinates. This will help us create time-series information for the most interesting image locations. \n",
    "    \n",
    "To do so, we <b>first create some helper functions:</b>\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pixelPicker:\n",
    "    def __init__(self, image, width, height):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.fig = plt.figure(figsize=(width, height))\n",
    "        self.ax = self.fig.add_subplot(111, visible=False)\n",
    "        self.rect = patches.Rectangle(\n",
    "            (0.0, 0.0), width, height, \n",
    "            fill=False, clip_on=False, visible=False\n",
    "        )\n",
    "       \n",
    "        self.rect_patch = self.ax.add_patch(self.rect)\n",
    "        self.cid = self.rect_patch.figure.canvas.mpl_connect('button_press_event', \n",
    "                                                             self)\n",
    "        self.image = image\n",
    "        self.plot = self.gray_plot(self.image, fig=self.fig, return_ax=True)\n",
    "        self.plot.set_title('Select a Point of Interest')\n",
    "        \n",
    "        \n",
    "    def gray_plot(self, image, vmin=None, vmax=None, fig=None, return_ax=False):\n",
    "        '''\n",
    "        Plots an image in grayscale.\n",
    "        Parameters:\n",
    "        - image: 2D array of raster values\n",
    "        - vmin: Minimum value for colormap\n",
    "        - vmax: Maximum value for colormap\n",
    "        - return_ax: Option to return plot axis\n",
    "        '''\n",
    "        if vmin is None:\n",
    "            vmin = np.nanpercentile(self.image, 1)\n",
    "        if vmax is None:\n",
    "            vmax = np.nanpercentile(self.image, 99)\n",
    "        if fig is None:\n",
    "           my_fig = plt.figure() \n",
    "        ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "        ax.imshow(image, cmap=plt.cm.gist_gray, vmin=vmin, vmax=vmax)\n",
    "        if return_ax:\n",
    "            return(ax)\n",
    "        \n",
    "    \n",
    "    def __call__(self, event):\n",
    "        print('click', event)\n",
    "        self.x = event.xdata\n",
    "        self.y = event.ydata\n",
    "        for pnt in self.plot.get_lines():\n",
    "            pnt.remove()\n",
    "        plt.plot(self.x, self.y, 'ro')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"> Now we are ready to plot the minimum image. <b>Click a point interest for which you want to analyze radar brightness over time</b>: </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig_xsize = 7.5\n",
    "fig_ysize = 7.5\n",
    "my_plot = pixelPicker(temporal_min, fig_xsize, fig_ysize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Save the selected coordinates</b>: </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarloc = (ceil(my_plot.x), ceil(my_plot.y))\n",
    "print(sarloc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"5\"> <b> 5. Plot SAR Brightness Time Series at Point Locations </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 5.1 SAR Brightness Time Series at Point Locations </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> We will pick a pixel location identified in the SAR image above and plot the time series for this identified point. By focusing on image locations undergoing deforestation, we should see the changes in the radar cross section related to the deforestation event.\n",
    "    \n",
    "First, for processing of the imagery in this notebook we generate a list of image handles and retrieve projection and georeferencing information. We also define a function for mapping image pixels to a geographic projection</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geotrans = img.GetGeoTransform()\n",
    "proj = img.GetProjection()\n",
    "xsize = img.RasterXSize\n",
    "ysize = img.RasterYSize\n",
    "bands = img.RasterCount\n",
    "projlatlon = pyproj.Proj('EPSG:4326') # WGS84\n",
    "projstring = proj.split('[')[-1][:-2].split(',')[-1][1:-1]\n",
    "projimg = pyproj.Proj(f'EPSG:{projstring}')\n",
    "\n",
    "def geolocation(x, y=None, latlon=True):\n",
    "    if len(x) == 2:\n",
    "        y = x[1]\n",
    "        x = x[0]\n",
    "    ref_x=geotrans[0]+sarloc[0]*geotrans[1]\n",
    "    ref_y=geotrans[3]+sarloc[1]*geotrans[5]\n",
    "    if latlon:\n",
    "        ref_y, ref_x = pyproj.transform(projimg, projlatlon, ref_x, ref_y)\n",
    "    return (ref_x, ref_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"> Now, let's <b>pick a rectangle around a center pixel which we selected and defined in variable <i>sarloc</i></b>...</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extent = (5, 5) # choose a 5 by 5 rectangle\n",
    "latlon = True # if False: return utm coordinates\n",
    "\n",
    "refsarloc = geolocation(sarloc, latlon=latlon)\n",
    "projsymbol = '°' if latlon else 'm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">... and <b>extract the time series</b> for this small area around the selected center pixel in a memory-efficient way (needed for larger stacks):</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 9})\n",
    "bs_aggregated = []\n",
    "for band in range(bands):\n",
    "    rs = img.GetRasterBand(band+1).ReadAsArray(sarloc[0], sarloc[1], \n",
    "                                               extent[0], extent[1])\n",
    "    rs_mean = convert(np.nanmean(rs))\n",
    "    bs_aggregated.append(rs_mean)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "labeldB = 'dB' if use_dB else 'linear'\n",
    "ax.plot(time_index, bs_aggregated, color='k', marker='o', markersize=3)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel(f'Sentinel-1 $\\gamma^0$ [{labeldB}]')\n",
    "\n",
    "plt.grid()\n",
    "_ = fig.suptitle(f'Location: {refsarloc[0]:.3f}{projsymbol} '\n",
    "                 f'{refsarloc[1]:.3f}{projsymbol}')\n",
    "\n",
    "# fig.tight_layout() \n",
    "figname = (f'RCSTimeSeries-{refsarloc[0]:.3f}{projsymbol} '\n",
    "           f'{refsarloc[1]:.3f}{projsymbol}.png')\n",
    "plt.savefig(figname, dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>EXERCISE</u>:  </font> Explore Time Series at Different Point Locations </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Can you interpret and attribute the changes at various locations? Apart from the flooding, what other patterns do you observe?\n",
    "</font>\n",
    "</div>\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"2\"> <i>ExploreSARTimeSeriesFlood_From_Prepared_Data_Stack.ipynb - Version 1.2.0 - April 2021 </i>\n",
    "    <br>\n",
    "        <b>Version Changes:</b>\n",
    "    <ul>\n",
    "        <li>from osgeo import gdal</li>\n",
    "    </ul>\n",
    "    </i>\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtc_analysis",
   "language": "python",
   "name": "rtc_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
