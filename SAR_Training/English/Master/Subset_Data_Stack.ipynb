{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "tags": []
   },
   "source": [
    "![OpenSARlab notebook banner](NotebookAddons/blackboard-banner.png)\n",
    "\n",
    "# Subset Data Stack\n",
    "\n",
    "### Alex Lewandowski; University of Alaska Fairbanks\n",
    "\n",
    "<img style=\"padding: 7px\" src=\"NotebookAddons/UAFLogo_A_647.png\" width=\"170\" align=\"right\"/></font>\n",
    "\n",
    "This notebook crops a directory of tiffs to a subset area of interest.\n",
    "It notebook assumes that users have created a directory of geotiffs using the `Prepare_Data_Stack_HyP3` notebook. \n",
    "\n",
    "Subset the data with any of the following methods:\n",
    "\n",
    "1. Select a rectangular area of interest on an interactive plot\n",
    "1. Use Well-Known Text (WKT)\n",
    "1. Upload a shapefile\n",
    "\n",
    "<!-- <img style=\"padding: 7px\" src=\"NotebookAddons/UAFLogo_A_647.png\" width=\"170\" align=\"right\"/></font> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "<font face=\"Calibri\" size=\"5\" color=\"darkred\"> <b>Important Note about JupyterHub</b> </font>\n",
    "\n",
    "**Your JupyterHub server will automatically shutdown when left idle for more than 1 hour. Your notebooks will not be lost but you will have to restart their kernels and re-run them from the beginning. You will not be able to seamlessly continue running a partially run notebook.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import url_widget as url_w\n",
    "notebookUrl = url_w.URLWidget()\n",
    "display(notebookUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "\n",
    "notebookUrl = notebookUrl.value\n",
    "user = !echo $JUPYTERHUB_USER\n",
    "env = !echo $CONDA_PREFIX\n",
    "if env[0] == '':\n",
    "    env[0] = 'Python 3 (base)'\n",
    "if env[0] != '/home/jovyan/.local/envs/rtc_analysis':\n",
    "    display(Markdown(f'<text style=color:red><strong>WARNING:</strong></text>'))\n",
    "    display(Markdown(f'<text style=color:red>This notebook should be run using the \"rtc_analysis\" conda environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>It is currently using the \"{env[0].split(\"/\")[-1]}\" environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Select the \"rtc_analysis\" from the \"Change Kernel\" submenu of the \"Kernel\" menu.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>If the \"rtc_analysis\" environment is not present, use <a href=\"{notebookUrl.split(\"/user\")[0]}/user/{user[0]}/notebooks/conda_environments/Create_OSL_Conda_Environments.ipynb\"> Create_OSL_Conda_Environments.ipynb </a> to create it.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Note that you must restart your server after creating a new environment before it is usable by notebooks.</text>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "\n",
    "--- \n",
    "    \n",
    "## **0. Importing Relevant Python Packages**\n",
    "\n",
    "In this notebook we will use the following scientific library:\n",
    "\n",
    "- [GDAL](https://www.gdal.org/) is a software library for reading and writing raster and vector geospatial data formats. It includes a collection of programs tailored for geospatial data processing. Most modern GIS systems (such as ArcGIS or QGIS) use GDAL in the background.\n",
    "\n",
    "**Import the necesssary libraries and modules:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from pathlib import Path\n",
    "import json # for loads\n",
    "import shutil\n",
    "\n",
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "from osgeo import gdal\n",
    "from rasterio.warp import transform_bounds\n",
    "\n",
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "%matplotlib widget\n",
    "\n",
    "# import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "import opensarlab_lib as asfn\n",
    "asfn.jupytertheme_matplotlib_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "\n",
    "---\n",
    "**Write functions to gather and print individual tiff paths:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def get_tiff_paths(paths):\n",
    "    tiff_paths = list(paths.parent.rglob(paths.name))    \n",
    "    tiff_paths.sort()\n",
    "    return tiff_paths\n",
    "\n",
    "def print_tiff_paths(tiff_paths):\n",
    "    print(\"Tiff paths:\")\n",
    "    for p in tiff_paths:\n",
    "        print(f\"{p}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select the directory holding your tiffs**\n",
    "- Click the `Select` button\n",
    "- Navigate to your data directory\n",
    "- Click the `Select` button\n",
    "- Confirm that the desired path appears in green text\n",
    "- Click the `Change` button to alter your selection\n",
    "- *Note: If you used `Prepare_Data_Stack_Hyp3` notebook to generate directory, tiffs should be in `RTC_GAMMA_tiffs` directory.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = FileChooser(Path.cwd())\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "**Determine the path to the analysis directory containing the tiff directory:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tiff_dir = Path(fc.selected_path)\n",
    "analysis_dir = tiff_dir.parent\n",
    "print(f\"analysis_dir: {analysis_dir}\\n\")\n",
    "\n",
    "paths = tiff_dir/\"*.tif*\"\n",
    "tiff_paths = get_tiff_paths(paths)\n",
    "print_tiff_paths(tiff_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "**Determine the UTM zone for your images.** \n",
    "\n",
    "This assumes you have already reprojected multiple UTM projections to a single predominant projection using the `Prepare_Data_Stack_Hyp3` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "utm = asfn.get_projection(str(tiff_paths[0]))\n",
    "print(f\"UTM Zone: {utm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choose a `.tif` file to generate your shapefile**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    infile = tiff_paths[0]\n",
    "except:\n",
    "    raise OSError('Directory that contains your .tif files is empty.')\n",
    "try:\n",
    "    suffix = infile.suffix\n",
    "    if suffix != '.tif':\n",
    "        raise ValueError(f'File you chose is not a \".tif\" file. Pick a valid \".tif\" file.')\n",
    "except:\n",
    "    raise TypeError(f'{infile} is not a valid path.')\n",
    "\n",
    "outfile = str(infile.parent/f'subset_{infile.stem}.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "---\n",
    "## **1. Select a Subsetting Method and Create a Directory in Which to Store Subset Data**\n",
    "\n",
    "**Select a subsetting option**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Please choose one of three options:\")\n",
    "\n",
    "option_key = [\n",
    "    None,\n",
    "    'Option 1: Draw a rectangle',\n",
    "    'Option 2: Well-Known Text (WKT)',\n",
    "    'Option 3: Shapefile'\n",
    "]\n",
    "\n",
    "option = asfn.select_parameter([option_key[1], option_key[2] , option_key[3],], '')\n",
    "display(option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = option_key.index(option.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a directory in which to store the subset tiffs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Choose a directory name in which to store the subset geotiffs.\")\n",
    "print(\"Note: this will sit alongside the directory containing your pre-subset geotiffs.\")\n",
    "while True:\n",
    "    sub_name = input()\n",
    "    if sub_name == \"\":\n",
    "        print(\"Please enter a valid directory name\")\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "subset_dir = analysis_dir/f'{sub_name}'\n",
    "\n",
    "if not subset_dir.exists():\n",
    "    subset_dir.mkdir()\n",
    "elif any(subset_dir.rglob('*.tif*')):\n",
    "    raise Exception(f\"{subset_dir} already exists and contains tiffs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## **2. Prepare for Subsetting**\n",
    "\n",
    "**Determine the maximum and common bounds of the data stack**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_extents = asfn.get_max_extents(tiff_paths)\n",
    "xmin, ymin, xmax, ymax = transform_bounds(int(asfn.get_projection(str(tiff_paths[0]))), 3857, *max_extents)\n",
    "max_extents = [xmin, ymin, xmax, ymax]\n",
    "\n",
    "common_extents = asfn.get_common_coverage_extents(tiff_paths)\n",
    "xmin, ymin, xmax, ymax = transform_bounds(int(asfn.get_projection(str(tiff_paths[0]))), 3857, *common_extents)\n",
    "common_extents = [xmin, ymin, xmax, ymax]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Option 1: Select an AOI from an interactive plot**\n",
    "\n",
    "**Determine the maximum and common extents of the stack and plot an Area-of_Interest Selector:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if choice == 1:\n",
    "    aoi = asfn.AOI_Selector(max_extents, common_extents, figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert the subset corner coordinates from Web-Mercator back to the input data's EPSG:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if choice == 1:\n",
    "    try:\n",
    "        xmin, ymin, xmax, ymax = transform_bounds(3857, \n",
    "                                              int(asfn.get_projection(str(tiff_paths[0]))), \n",
    "                                              *[aoi.x1, aoi.y1, aoi.x2, aoi.y2])\n",
    "        ul = [xmin, ymax]\n",
    "        lr = [xmax, ymin]\n",
    "        print(f\"AOI Corner Coordinates:\")\n",
    "        print(f\"upper left corner: {ul}\")\n",
    "        print(f\"lower right corner: {lr}\")\n",
    "    except TypeError:\n",
    "        print('TypeError')\n",
    "        display(Markdown(f'<text style=color:red>This error may occur if an AOI was not selected.</text>'))\n",
    "        display(Markdown(f'<text style=color:red>Note that the square tool icon in the AOI selector menu is <b>NOT</b> the selection tool. It is the zoom tool.</text>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Option 2: Create a shapefile from WKT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Delete existing shape files (`.shp`, `.prj`, `.dbf`, `.shx`)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if choice == 2:\n",
    "    print(\"We will generate a shapefile from your WKT.\")\n",
    "    print(\"Would you like to delete any existing shape files in your tiff directory?\")\n",
    "    shp_option = asfn.select_parameter(['Yes', 'No',], '')\n",
    "    display(shp_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if choice == 2 and shp_option.value == 'Yes':\n",
    "    keywords = ['.shp','.dbf','.prj','.shx']\n",
    "    \n",
    "    for path in infile.parent.iterdir():\n",
    "        for k in keywords:\n",
    "            if path.suffix == k:\n",
    "                print(f'Removed {path}')\n",
    "                path.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choose a name for your `.shp` file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if choice == 2:\n",
    "    shp_name = input('Choose a name for the shapefile you will create: ')\n",
    "    \n",
    "    # default name if user does not input anything\n",
    "    if not shp_name:\n",
    "        shp_name = 'shape'\n",
    "    \n",
    "    shp = str(infile.parent/f'{shp_name}.shp')\n",
    "    \n",
    "    print(shp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate shapefile.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Let user input WKT (option 2)\n",
    "if choice == 2:\n",
    "    from osgeo import ogr\n",
    "    import shapely.wkt as sWkt\n",
    "    import geopandas\n",
    "    \n",
    "    print(\"When inputting your WKT:\\n\"\\\n",
    "         \"\\t1) You must use a single polygon (e.g. POLYGON((x y, x y, ...)) \\n\"\\\n",
    "         \"\\t2) The bounds of the WKT should be within the extents of the data \\n\"\\\n",
    "         \"\\t3) The projection of the WKT should match that of the dataset\")\n",
    "    \n",
    "\n",
    "    correctWktInput = False\n",
    "    while not correctWktInput:\n",
    "        wkt = input(\"Please enter your WKT: \")\n",
    "        \n",
    "        try:\n",
    "            geoShape = sWkt.loads(wkt)\n",
    "            series = geopandas.GeoSeries([geoShape])\n",
    "            isNotConnected = series.is_valid[0]\n",
    "                        \n",
    "            if not isNotConnected:\n",
    "                raise('Obsecure shape detected.')\n",
    "                continue\n",
    "                \n",
    "        except:\n",
    "            print('Error due to an unclosed shape, obsecure shape, or bad input. Try again...')\n",
    "            continue\n",
    "            \n",
    "        correctWktInput = True\n",
    "                \n",
    "    outfile = str(infile.parent/f'subset_{infile.stem}.tif')\n",
    "    epsg = getEPSG(str(infile))\n",
    "\n",
    "    driver = ogr.GetDriverByName('Esri Shapefile')\n",
    "    ds = driver.CreateDataSource(shp)\n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromEPSG(epsg)\n",
    "    layer = ds.CreateLayer('', srs, ogr.wkbPolygon)\n",
    "    defn = layer.GetLayerDefn()\n",
    "\n",
    "    # Create a new feature (attribute and geometry)\n",
    "    feat = ogr.Feature(defn)\n",
    "    \n",
    "    # Make a geometry from Shapely object\n",
    "    geom = ogr.CreateGeometryFromWkt(wkt) \n",
    "    feat.SetGeometry(geom)\n",
    "    \n",
    "    layer.CreateFeature(feat)\n",
    "    feat = geom = None  # destroy these\n",
    "\n",
    "    # Save and close everything\n",
    "    ds = layer = feat = geom = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Option 3: Upload `.shp`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "If you chose option 3, upload your shapefile (`.shp`, `.prj`, `.shx` and `.dbf` files). Once you uploaded them, select the .shp file using file selector.\n",
    "\n",
    "**Note**: `.shp`, `.shx`, `.dbf`, and `.prj` files must be in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "if choice == 3:\n",
    "    display(Markdown(f'<text style=color:red>WARNING: The uploaded shapefile must have the same projection as the dataset.</text>'))\n",
    "    print(\"Select a shapefile (.shp):\")\n",
    "    shpfc = FileChooser(Path.cwd())\n",
    "    display(shpfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "if choice == 3:\n",
    "    try:\n",
    "        shp = Path(shpfc.selected)\n",
    "    except:\n",
    "        raise TypeError('Please choose the file path before proceeding.')\n",
    "        \n",
    "    print(shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Extract wkt from shapefile:\n",
    "if choice == 3:\n",
    "    if shp.suffix == '.shp':\n",
    "        gInfo = gdal.OpenEx(str(shp))\n",
    "        layer = gInfo.GetLayer()\n",
    "        feature = layer.GetFeature(0)\n",
    "        wkt = feature.GetGeometryRef().ExportToWkt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Option 2 & 3: Display shapefile (uploaded or created from WKT) in relation to the stack extents**\n",
    "\n",
    "**Visually confirm that your AOI is located where you expect it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if choice != 1:\n",
    "    asfn.plot_shape_in_stack(shp, utm, max_extents, common_extents, figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Subset the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tiff_path in enumerate(tiff_paths):\n",
    "\n",
    "    outfile = subset_dir/f\"{tiff_path.stem}_subset{tiff_path.suffix}\"  \n",
    "\n",
    "    if choice == 1:\n",
    "        gdal.Translate(destName=str(outfile), srcDS=str(tiff_path), projWin=[ul[0], ul[1], lr[0], lr[1]])\n",
    "    else: # choice 2 & 3\n",
    "        gdal.Warp(str(outfile), str(tiff_path), cutlineDSName=str(shp) , cropToCutline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Clean Up**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "**Delete any subset `tifs` that are filled with `NaNs` and contain no data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "subset_paths = subset_dir/f\"*.tif*\"\n",
    "tiff_paths = get_tiff_paths(subset_paths)\n",
    "asfn.remove_nan_filled_tifs(tiff_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "**Sometimes, when using gdal translate to subset a stack of images, there will be slight differences in sizes of the resulting images, off by a single pixel in either direction. The following code checks the newly subset stack for this problem, and if found, it re-subsets all the images to the size of the smallest image in the stack.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Align geotiffs to an integer resolution value\n",
    "\n",
    "fnames = list(subset_dir.rglob('*.tif*'))\n",
    "fnames.sort()\n",
    "\n",
    "resolution = int(gdal.Info(str(fnames[0]), format='json')['geoTransform'][1])\n",
    "for fname in fnames:\n",
    "    gdal.Warp(str(fname), str(fname), \n",
    "              dstSRS=f'EPSG:{utm}', srcSRS=f'EPSG:{utm}', \n",
    "              xRes=resolution, yRes=resolution, targetAlignedPixels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "**Decide whether or not to cleanup the original tiffs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "cleanup = asfn.select_parameter([\"Save original tiffs\", \"Delete original tiffs\"], '')\n",
    "cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "if cleanup.value == 'Delete original tiffs':\n",
    "    shutil.rmtree(tiff_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "**Print the path to your subset directory:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "print(subset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Relavent notebooks:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to display links\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "current = Path.cwd()\n",
    "abs_path = [\n",
    "    Path('/home/jovyan/notebooks/SAR_Training/English/Master/Change_Detection_From_Prepared_Data_Stack.ipynb'),\n",
    "    Path('/home/jovyan/notebooks/SAR_Training/English/Master/Explore_SAR_Time_Series_From_Prepared_Data_Stack.ipynb'),\n",
    "    Path('/home/jovyan/notebooks/SAR_Training/English/Master/SARChangeDetectionMethods_From_Prepared_Data_Stack.ipynb'),\n",
    "    Path('/home/jovyan/notebooks/SAR_Training/English/Master/Time_Series_From_Prepared_Stack.ipynb')\n",
    "]\n",
    "\n",
    "details = [\n",
    "    'Introduce you to the analysis of deep multi-temporal SAR image data stacks.',\n",
    "    'Introduces you to a some popular change detection methods that can be applied on SAR time series data.',\n",
    "    'Introduces you to the time series signatures associated with flooding.',\n",
    "    'Applies Change Point Detection on a deep multi-temporal SAR image data stack acquired by Sentinel-1.'\n",
    "]\n",
    "\n",
    "\n",
    "for a in abs_path:\n",
    "    name = a.stem\n",
    "    relative_path = a.relative_to(current)\n",
    "    detail = details.pop()\n",
    "    link_t = f\"<li><a href='{relative_path}'> {name} </a>: {detail} </li>\"\n",
    "    html = HTML(link_t)\n",
    "    display(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*GEOS 657 Microwave Remote Sensing - Version 2.1.0 - June 2023*\n",
    "\n",
    "*Version Changes:*\n",
    "- *Use updated AOI_Selector*\n",
    "- *Display shapefile and WKT polygons on a basemap showing maximum and common coverage extents*\n",
    "- *general refactoring for clarity*"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "insar_analysis [conda env:.local-insar_analysis]",
   "language": "python",
   "name": "conda-env-.local-insar_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
