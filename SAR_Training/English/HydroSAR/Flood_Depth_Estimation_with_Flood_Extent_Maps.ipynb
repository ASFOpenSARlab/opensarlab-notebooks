{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "![HydroSAR Banner](./NotebookAddOns/HydroSARbanner.jpg)\n",
    "\n",
    "# Flood Depth Estimation with Flood Extent Maps\n",
    "\n",
    "## Part of NASA A.37 Project: Integrating SAR Data for Improved Resilience and Response to Weather-Related Disasters\n",
    "\n",
    "### PI:Franz J. Meyer\n",
    "**Version 0.1.8 - 2021/01/24**\n",
    "\n",
    "Change Log: See bottom of the notebook.\n",
    "    \n",
    "**Batuhan Osmanoglu, MinJeong Jo; NASA Goddard Space Fligth Center**\n",
    "\n",
    "This notebook provides the processor to generate Flood Depth map using the product generated by **Hyp3 Change Detection-Threshold** processor. This notebook can be used to generate **Multiple** FD Products\n",
    "\n",
    "*Note: Before you start to use the notebook, Hyp3-generated change detection maps in Geotiff format need to be placed in your own data folder. For the HydroSAR Training, these SAR data are already available to you after completion of Lab 2.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import url_widget as url_w\n",
    "notebookUrl = url_w.URLWidget()\n",
    "display(notebookUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "\n",
    "notebookUrl = notebookUrl.value\n",
    "user = !echo $JUPYTERHUB_USER\n",
    "env = !echo $CONDA_PREFIX\n",
    "if env[0] == '':\n",
    "    env[0] = 'Python 3 (base)'\n",
    "if env[0] != '/home/jovyan/.local/envs/hydrosar':\n",
    "    display(Markdown(f'<text style=color:red><strong>WARNING:</strong></text>'))\n",
    "    display(Markdown(f'<text style=color:red>This notebook should be run using the \"hydrosar\" conda environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>It is currently using the \"{env[0].split(\"/\")[-1]}\" environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Select \"hydrosar\" from the \"Change Kernel\" submenu of the \"Kernel\" menu.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>If the \"hydrosar\" environment is not present, use <a href=\"{notebookUrl.split(\"/user\")[0]}/user/{user[0]}/notebooks/conda_environments/Create_OSL_Conda_Environments.ipynb\"> Create_OSL_Conda_Environments.ipynb </a> to create it.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Note that you must restart your server after creating a new environment before it is usable by notebooks.</text>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Importing Relevant Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "#Setup Environment\n",
    "from pathlib import Path\n",
    "import urllib\n",
    "import pprint\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "gdal.UseExceptions()\n",
    "from osgeo import osr\n",
    "import pylab as pl\n",
    "from scipy import ndimage\n",
    "from scipy import optimize\n",
    "from scipy import stats\n",
    "import astropy\n",
    "import astropy.convolution\n",
    "import pykrige\n",
    "import pysheds\n",
    "from pysheds.grid import Grid\n",
    "from affine import Affine\n",
    "import rasterio\n",
    "import pyproj\n",
    "\n",
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "# #Download packages\n",
    "codes_folder = Path('/home/jovyan/adore_doris')\n",
    "if not codes_folder.exists():\n",
    "    !git clone https://github.com/bosmanoglu/adore-doris.git {codes_folder}\n",
    "else:\n",
    "    print(\"here\")\n",
    "    !git --git-dir={codes_folder/\".git\"} pull origin master\n",
    "\n",
    "import sys\n",
    "\n",
    "if str(codes_folder) not in sys.path:\n",
    "    sys.path.append(f'{codes_folder}/lib/python')\n",
    "    sys.path.append(codes_folder)\n",
    "    \n",
    "# #import modules after downloads\n",
    "import gis\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Define Convenience Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     1,
     17,
     21,
     29,
     33,
     37,
     62,
     70,
     73,
     89,
     98,
     113,
     119,
     125,
     141,
     158,
     194,
     293,
     310,
     323,
     336
    ],
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from os import system\n",
    "\n",
    "# Define convenience functions\n",
    "def bounding_box_inside_bounding_box(small, big):\n",
    "    s0 = np.array([p[0] for p in small])\n",
    "    s1 = np.array([p[1] for p in small])\n",
    "    b0 = np.array([p[0] for p in big])\n",
    "    b1 = np.array([p[1] for p in big])\n",
    "    inside = True\n",
    "    if s0.min() < b0.min():\n",
    "        inside = False\n",
    "    if s0.max() > b0.max():\n",
    "        inside = False\n",
    "    if s1.min() < b1.min():\n",
    "        inside = False\n",
    "    if s1.max() > b1.max():\n",
    "        inside = False\n",
    "    return inside\n",
    "\n",
    "\n",
    "def getGeoTransform(filename):\n",
    "    warnings.warn(\"getGeoTransform will be deprecated in the future. Please use read_data instead.\", PendingDeprecationWarning)\n",
    "    return get_geotransform(filename)\n",
    "\n",
    "\n",
    "def get_geotransform(filename):\n",
    "    '''\n",
    "    [top left x, w-e pixel resolution, rotation, top left y, rotation, n-s pixel resolution]=getGeoTransform('/path/to/file')\n",
    "    '''\n",
    "    #http://stackoverflow.com/questions/2922532/obtain-latitude-and-longitude-from-a-geotiff-file\n",
    "    ds = gdal.Open(filename)\n",
    "    return ds.GetGeoTransform()\n",
    "    \n",
    "    \n",
    "def build_vrt(filename, input_file_list):\n",
    "    resolution = gdal.Info(input_file_list[0], format='json')['geoTransform'][1]\n",
    "    vrt_options = gdal.BuildVRTOptions(resampleAlg='near', \n",
    "                                       separate=False,\n",
    "                                       xRes=resolution,\n",
    "                                       yRes=resolution,\n",
    "                                       targetAlignedPixels=True)\n",
    "    gdal.BuildVRT(filename, input_file_list, options=vrt_options)\n",
    "\n",
    "    \n",
    "def get_tiff_paths(paths):\n",
    "    tiff_paths = !ls $paths | sort -t_ -k5,5\n",
    "    return tiff_paths\n",
    "\n",
    "\n",
    "def gdal_get_projection(filename, out_format='proj4'):\n",
    "    \"\"\"\n",
    "    epsg_string=get_epsg(filename, out_format='proj4')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ds = gdal.Open(filename, gdal.GA_ReadOnly)\n",
    "        srs = gdal.osr.SpatialReference()\n",
    "        srs.ImportFromWkt(ds.GetProjectionRef())\n",
    "    except: #I am not sure if this is working for datasets without a layer. The first try block should work mostly.\n",
    "        ds = gdal.Open(filename, gdal.GA_ReadOnly)\n",
    "        ly = ds.GetLayer()\n",
    "        if ly is None:\n",
    "            print(f\"Can not read projection from file:{filename}\")\n",
    "            return None\n",
    "        else:\n",
    "            srs = ly.GetSpatialRef()\n",
    "    if out_format.lower() == 'proj4':\n",
    "        return srs.ExportToProj4()\n",
    "    elif out_format.lower() == 'wkt':\n",
    "        return srs.ExportToWkt()\n",
    "    elif out_format.lower() == 'epsg':\n",
    "        crs = pyproj.crs.CRS.from_proj4(srs.ExportToProj4())\n",
    "        return crs.to_epsg()\n",
    "\n",
    "\n",
    "def get_size(filename):\n",
    "    \"\"\"(width, height) = get_size(filename)\n",
    "    \"\"\"\n",
    "    ds = gdal.Open(filename)\n",
    "    width = ds.RasterXSize\n",
    "    height = ds.RasterYSize\n",
    "    ds = None\n",
    "    return (width, height)\n",
    "\n",
    "\n",
    "def get_proj4(filename):\n",
    "    f = rasterio.open(filename)\n",
    "    return pyproj.Proj(f.crs, preserve_units=True)  #used in pysheds\n",
    "\n",
    "\n",
    "def clip_gT(gT, xmin, xmax, ymin, ymax, method='image'):\n",
    "    '''calculate new geotransform for a clipped raster either using pixels or projected coordinates.\n",
    "    clipped_gT=clip_gT(gT, xmin, xmax, ymin, ymax, method='image')\n",
    "    method: 'image' | 'coord'\n",
    "    '''\n",
    "    if method == 'image':\n",
    "        y, x = xy2coord(ymin, xmin, gT); #top left, reference, coordinate\n",
    "    if method == 'coord':\n",
    "      #find nearest pixel\n",
    "      yi, xi = coord2xy(ymin, xmin, gT)\n",
    "      #get pixel coordinate\n",
    "      y, x = xy2coord(yi, xi, gT)\n",
    "    gTc = list(gT)\n",
    "    gTc[0] = y\n",
    "    gTc[3] = x\n",
    "    return tuple(gTc)\n",
    "\n",
    "\n",
    "def xy2coord(x, y, gT):\n",
    "    '''\n",
    "    lon,lat=xy2coord(x,y,geoTransform)\n",
    "    projects pixel index to position based on geotransform.\n",
    "    '''\n",
    "    coord_x = gT[0] + x*gT[1] + y*gT[2]\n",
    "    coord_y = gT[3] + x*gT[4] + y*gT[5]\n",
    "    return coord_x, coord_y\n",
    "\n",
    "\n",
    "def coord2xy(x, y, gT):\n",
    "    '''\n",
    "    x,y = coord2xy(lon, lat, geoTransform)\n",
    "    calculates pixel index closest to the lon, lat.\n",
    "    '''\n",
    "    #ref: https://gis.stackexchange.com/questions/221292/retrieve-pixel-value-with-geographic-coordinate-as-input-with-gdal/221430\n",
    "    xOrigin = gT[0]\n",
    "    yOrigin = gT[3]\n",
    "    pixelWidth = gT[1]\n",
    "    pixelHeight = -gT[5]\n",
    "\n",
    "    col = np.array((x - xOrigin) / pixelWidth).astype(int)\n",
    "    row = np.array((yOrigin - y) / pixelHeight).astype(int)\n",
    "\n",
    "    return row, col\n",
    "\n",
    "\n",
    "def fitSurface(x, y, z, X, Y):\n",
    "    p0 = [0, 0.1, 0.1]\n",
    "    fitfunc = lambda p, x, y: p[0] + p[1] * x + p[2] * y\n",
    "    errfunc = lambda p, x, y, z: abs(fitfunc(p,x,y) - z)\n",
    "    planefit, success = optimize.leastsq(errfunc, p0, args=(x,y,z))\n",
    "    return fitfunc(planefit, X, Y)    \n",
    "\n",
    "\n",
    "def nonan(a, rows=False):\n",
    "    if rows:\n",
    "        return a[np.isnan(a).sum(1)==0]\n",
    "    else:\n",
    "        return a[~np.isnan(a)]\n",
    "\n",
    "    \n",
    "def get_wesn(filename, t_srs=None):\n",
    "    bb = bounding_box(filename, t_srs=t_srs)\n",
    "    w = np.inf\n",
    "    e = -np.inf\n",
    "    n = -np.inf\n",
    "    s = np.inf\n",
    "    for p in bb:\n",
    "        if p[0] < w:\n",
    "            w = p[0]\n",
    "        if p[0] > e:\n",
    "            e = p[0]\n",
    "        if p[1] < s:\n",
    "            s = p[1]\n",
    "        if p[1] > n:\n",
    "            n = p[1]\n",
    "    return [w, e, s, n]\n",
    "\n",
    "\n",
    "def bounding_box(filename, t_srs=None):\n",
    "    \"\"\"\n",
    "    ((lon1,lat1), (lon2,lat2), (lon3,lat3), (lon4,lat4))=bounding_box('/path/to/file', t_srs=None) #returns x,y in native coordinate system\n",
    "    ((lon1,lat1), (lon2,lat2), (lon3,lat3), (lon4,lat4))=bounding_box('/path/to/file', t_srs='+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs')\n",
    "    \"\"\"\n",
    "    gT = getGeoTransform(filename)\n",
    "    width, height = get_size(filename)\n",
    "    pts = (xy2coord(0, 0, gT), xy2coord(width, 0, gT), xy2coord(width, height, gT), xy2coord(0, height, gT))\n",
    "    if t_srs is None:\n",
    "        return pts\n",
    "    else:\n",
    "        pts_tsrs = []\n",
    "        s_srs = gdal_get_projection(filename, out_format='proj4')\n",
    "        for p in pts:\n",
    "            pts_tsrs.append(transform_point(p[0], p[1], 0, s_srs=s_srs, t_srs=t_srs))\n",
    "    return tuple(pts_tsrs)   \n",
    "\n",
    "\n",
    "def transform_point(x, y, z, \n",
    "                    s_srs='+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs', \n",
    "                    t_srs='+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs'):\n",
    "    '''\n",
    "    transform_point(x,y,z,s_srs='+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs', t_srs='+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs')\n",
    "    \n",
    "    Known Bugs: gdal transform may fail if a proj4 string can not be found for the EPSG or WKT formats. \n",
    "    '''    \n",
    "    srs_cs = osr.SpatialReference()    \n",
    "    if \"EPSG\" == s_srs[0: 4]:    \n",
    "        srs_cs.ImportFromEPSG(int(s_srs.split(':')[1]));\n",
    "    elif \"GEOCCS\" == s_srs[0:6]:\n",
    "        srs_cs.ImportFromWkt(s_srs);\n",
    "    else:\n",
    "        srs_cs.ImportFromProj4(s_srs);\n",
    "\n",
    "    trs_cs = osr.SpatialReference()    \n",
    "    if \"EPSG\" == t_srs[0:4]:    \n",
    "        trs_cs.ImportFromEPSG(int(t_srs.split(':')[1]));\n",
    "    elif \"GEOCCS\" == t_srs[0:6]:\n",
    "        trs_cs.ImportFromWkt(t_srs);\n",
    "    else:\n",
    "        trs_cs.ImportFromProj4(t_srs);\n",
    "    if int(gdal.VersionInfo()) > 2999999: #3010300\n",
    "        #https://gdal.org/tutorials/osr_api_tut.html#crs-and-axis-order\n",
    "        # https://github.com/OSGeo/gdal/blob/master/gdal/MIGRATION_GUIDE.TXT\n",
    "        srs_cs.SetAxisMappingStrategy(osr.OAMS_TRADITIONAL_GIS_ORDER)\n",
    "        trs_cs.SetAxisMappingStrategy(osr.OAMS_TRADITIONAL_GIS_ORDER)\n",
    "    transform = osr.CoordinateTransformation(srs_cs, trs_cs) \n",
    "\n",
    "    if numel(x) > 1:\n",
    "        return [transformPoint(x[k], y[k], z[k]) for k in range(numel(x))]\n",
    "    else:\n",
    "        try:\n",
    "            return transform.TransformPoint((x, y, z));\n",
    "        except: \n",
    "            return transform.TransformPoint(x, y, z)\n",
    "\n",
    "def get_waterbody(filename, ths):\n",
    "    corners = bounding_box(filename)\n",
    "\n",
    "    epsg = gdal_get_projection(filename, out_format='epsg')\n",
    "    if epsg == \"4326\":         \n",
    "        corners = bounding_box(filename)\n",
    "    else:\n",
    "        srs = gdal_get_projection(filename, out_format='proj4')\n",
    "        corners = bounding_box(filename, t_srs=\"EPSG:4326\")\n",
    "    west = corners[0][0]\n",
    "    east = corners[1][0]\n",
    "    south = corners[2][1]\n",
    "    north = corners[0][1]    \n",
    "        \n",
    "# S_WATER directory is being created above working directory (i.e. Bangladesh, El_Salvador, etc.) to avoid clutter.\n",
    "# Modify here with \"work_path\" if you want S_WATER directory generated within your working directory.\n",
    "    cwd = Path.cwd()\n",
    "    sw_path = cwd/f\"S_WATER\"\n",
    "\n",
    "    if not sw_path.exists():\n",
    "        sw_path.mkdir()\n",
    "\n",
    "    lon = np.floor(west/10)\n",
    "    lon = int(abs(lon*10))\n",
    "    lat = np.ceil(north/10)\n",
    "    lat = int(abs(lat*10))\n",
    "\n",
    "    if (west < 0 and north < 0):\n",
    "        urllib.request.urlretrieve(f\"https://storage.googleapis.com/global-surface-water/downloads2019v2/occurrence/occurrence_{lon}W_{lat}Sv1_1_2019.tif\", f\"{cwd}/S_WATER/surface_water_{lon}W_{lat}S.tif\")\n",
    "        if (np.floor(west/10) != np.floor(east/10)):\n",
    "            urllib.request.urlretrieve(f\"https://storage.googleapis.com/global-surface-water/downloads2019v2/occurrence/occurrence_{lon-10}W_{lat}Sv1_1_2019.tif\", f\"{cwd}/S_WATER/surface_water_{lon-10}W_{lat}S.tif\")\n",
    "        if (np.floor(north/10) != np.floor(south/10)):\n",
    "            urllib.request.urlretrieve(f\"https://storage.googleapis.com/global-surface-water/downloads2019v2/occurrence/occurrence_{lon}W_{lat+10}Sv1_1_2019.tif\", f\"{cwd}/S_WATER/surface_water_{lon}W_{lat+10}S.tif\")\n",
    "        if (np.floor(north/10) != np.floor(south/10)) and (np.floor(west/10) != np.floor(east/10)):\n",
    "            urllib.request.urlretrieve(f\"https://storage.googleapis.com/global-surface-water/downloads2019v2/occurrence/occurrence_{lon-10}W_{lat+10}Sv1_1_2019.tif\", f\"{cwd}/S_WATER/surface_water_{lon-10}W_{lat+10}S.tif\")\n",
    "        print(f\"lon: {lon}-{lon-10}W, lat: {lat}-{lat+10}S \")\n",
    "\n",
    "    elif (west < 0 and north >= 0):\n",
    "        urllib.request.urlretrieve(f\"https://storage.googleapis.com/global-surface-water/downloads2019v2/occurrence/occurrence_{lon}W_{lat}Nv1_1_2019.tif\", f\"{cwd}/S_WATER/surface_water_{lon}W_{lat}N.tif\")\n",
    "        if (np.floor(west/10) != np.floor(east/10)):\n",
    "            urllib.request.urlretrieve(f\"https://storage.googleapis.com/global-surface-water/downloads2019v2/occurrence/occurrence_{lon-10}W_{lat}Nv1_1_2019.tif\", f\"{cwd}/S_WATER/surface_water_{lon-10}W_{lat}N.tif\")\n",
    "        if (np.floor(north/10) != np.floor(south/10)):\n",
    "            urllib.request.urlretrieve(f\"https://storage.googleapis.com/global-surface-water/downloads2019v2/occurrence/occurrence_{lon}W_{lat-10}Nv1_1_2019.tif\", f\"{cwd}/S_WATER/surface_water_{lon}W_{lat-10}N.tif\")\n",
    "        if (np.floor(north/10) != np.floor(south/10)) and (np.floor(west/10) != np.floor(east/10)):\n",
    "            urllib.request.urlretrieve(f\"https://storage.googleapis.com/global-surface-water/downloads2019v2/occurrence/occurrence_{lon-10}W_{lat-10}Nv1_1_2019.tif\", f\"{cwd}/S_WATER/surface_water_{lon-10}W_{lat-10}N.tif\")\n",
    "        print(f\"lon: {lon}-{lon-10}W, lat: {lat}-{lat-10}N \")\n",
    "\n",
    "\n",
    "    elif (west >= 0 and north < 0):\n",
    "        urllib.request.urlretrieve(f\"https://storage.googleapis.com/global-surface-water/downloads2019v2/occurrence/occurrence_{lon}E_{lat}Sv1_1_2019.tif\", f\"{cwd}/S_WATER/surface_water_{lon}E_{lat}S.tif\")\n",
    "        if (np.floor(west/10) != np.floor(east/10)):\n",
    "            urllib.request.urlretrieve(f\"https://storage.googleapis.com/global-surface-water/downloads2019v2/occurrence/occurrence_{lon+10}E_{lat}Sv1_1_2019.tif\", f\"{cwd}/S_WATER/surface_water_{lon+10}E_{lat}S.tif\")\n",
    "        if (np.floor(north/10) != np.floor(south/10)):\n",
    "            urllib.request.urlretrieve(f\"https://storage.googleapis.com/global-surface-water/downloads2019v2/occurrence/occurrence_{lon}E_{lat+10}Sv1_1_2019.tif\", f\"{cwd}/S_WATER/surface_water_{lon}E_{lat+10}S.tif\")\n",
    "        if (np.floor(north/10) != np.floor(south/10)) and (np.floor(west/10) != np.floor(east/10)):\n",
    "            urllib.request.urlretrieve(f\"https://storage.googleapis.com/global-surface-water/downloads2019v2/occurrence/occurrence_{lon+10}E_{lat+10}Sv1_1_2019.tif\", f\"{cwd}/S_WATER/surface_water_{lon+10}E_{lat+10}S.tif\")\n",
    "        print(f\"lon: {lon}-{lon+10}E, lat: {lat}-{lat+10}S \")\n",
    "\n",
    "    else:\n",
    "        urllib.request.urlretrieve(f\"https://storage.googleapis.com/global-surface-water/downloads2019v2/occurrence/occurrence_{lon}E_{lat}Nv1_1_2019.tif\", f\"{cwd}/S_WATER/surface_water_{lon}E_{lat}N.tif\")\n",
    "        if (np.floor(west/10) != np.floor(east/10)):\n",
    "            urllib.request.urlretrieve(f\"https://storage.googleapis.com/global-surface-water/downloads2019v2/occurrence/occurrence_{lon+10}E_{lat}Nv1_1_2019.tif\", f\"{cwd}/S_WATER/surface_water_{lon+10}E_{lat}N.tif\")\n",
    "        if (np.floor(north/10) != np.floor(south/10)):\n",
    "            urllib.request.urlretrieve(f\"https://storage.googleapis.com/global-surface-water/downloads2019v2/occurrence/occurrence_{lon}E_{lat-10}Nv1_1_2019.tif\", f\"{cwd}/S_WATER/surface_water_{lon}E_{lat-10}N.tif\")\n",
    "        if (np.floor(north/10) != np.floor(south/10)) and (np.floor(west/10) != np.floor(east/10)):\n",
    "            urllib.request.urlretrieve(f\"https://storage.googleapis.com/global-surface-water/downloads2019v2/occurrence/occurrence_{lon+10}E_{lat-10}Nv1_1_2019.tif\", f\"{cwd}/S_WATER/surface_water_{lon+10}E_{lat-10}N.tif\")\n",
    "        print(f\"lon: {lon}-{lon+10}E, lat: {lat}-{lat-10}N \")\n",
    "\n",
    "    # Building the virtual raster for Change Detection product(tiff)\n",
    "    product_wpath = cwd/f\"S_WATER/surface_water*.tif\"\n",
    "\n",
    "    #wildcard_path is not being used for now\n",
    "    #wildcard_path = f\"{cwd}/change_VV_20170818T122205_20170830T122203.tif\"\n",
    "    print(product_wpath)\n",
    "\n",
    "    get_ipython().system(f'gdalbuildvrt {product_wpath.parent}/surface_water_map.vrt $product_wpath')\n",
    "\n",
    "\n",
    "    #Clipping/Resampling Surface Water Map for AOI\n",
    "    dim = get_size(filename)\n",
    "    if epsg == \"4326\":\n",
    "        cmd_resamp = f\"gdalwarp -overwrite -te {west} {south} {east} {north} -ts {dim[0]} {dim[1]} -r lanczos {product_wpath.parent}/surface_water_map.vrt {product_wpath.parent}/surface_water_map_clip.tif\"\n",
    "    else:   \n",
    "        corners=bounding_box(filename) # we now need corners in the non EPSG:4326 format.  \n",
    "        west = corners[0][0]\n",
    "        east = corners[1][0]\n",
    "        south = corners[2][1]\n",
    "        north = corners[0][1]            \n",
    "        cmd_resamp = f\"gdalwarp -overwrite -t_srs '{srs}' -te {west} {south} {east} {north} -ts {dim[0]} {dim[1]} -r nearest {product_wpath.parent}/surface_water_map.vrt {product_wpath.parent}/surface_water_map_clip.tif\"        \n",
    "    print(cmd_resamp)\n",
    "    system(cmd_resamp)\n",
    "\n",
    "    #load resampled water map\n",
    "    wimage_file = f\"{product_wpath.parent}/surface_water_map_clip.tif\"\n",
    "    water_map = gdal.Open(wimage_file)\n",
    "    \n",
    "    swater_map = gis.readData(wimage_file)\n",
    "    wmask= swater_map > ths   #higher than 30% possibility (present water)\n",
    "        \n",
    "    return wmask\n",
    "\n",
    "\n",
    "def numel(x):\n",
    "    if isinstance(x, int):\n",
    "      return 1\n",
    "    elif isinstance(x, np.double):\n",
    "      return 1\n",
    "    elif isinstance(x, float):\n",
    "      return 1\n",
    "    elif isinstance(x, str):\n",
    "      return 1\n",
    "    elif isinstance(x, list) or isinstance(x, tuple):\n",
    "      return len(x)\n",
    "    elif isinstance(x, np.ndarray):\n",
    "      return x.size\n",
    "    else: \n",
    "      print('Unknown type {}.'.format(type(x)))\n",
    "      return None\n",
    "\n",
    "    \n",
    "def yesno(yes_no_question = \"[y/n]\"):\n",
    "    while True:\n",
    "        # raw_input returns the empty string for \"enter\"\n",
    "        yes = {'yes','y', 'ye'}\n",
    "        no = {'no','n'}\n",
    "\n",
    "        choice = input(yes_no_question+\"[y/n]\").lower()\n",
    "        if choice in yes:\n",
    "            return True\n",
    "        elif choice in no:\n",
    "            return False\n",
    "        else:\n",
    "            print(\"Please respond with 'yes' or 'no'\")\n",
    "            \n",
    "            \n",
    "def fill_nan(arr):\n",
    "    \"\"\"\n",
    "    filled_arr=fill_nan(arr)\n",
    "    Fills Not-a-number values in arr using astropy. \n",
    "    \"\"\"    \n",
    "    kernel = astropy.convolution.Gaussian2DKernel(x_stddev=3) #kernel x_size=8*stddev\n",
    "    arr_type = arr.dtype          \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        while np.any(np.isnan(arr)):\n",
    "            arr = astropy.convolution.interpolate_replace_nans(arr.astype(float), kernel, convolve=astropy.convolution.convolve)\n",
    "    return arr.astype(arr_type) \n",
    "\n",
    "\n",
    "def logstat(data, func=np.nanstd):\n",
    "    \"\"\" stat=logstat(data, func=np.nanstd)\n",
    "       calculates the statistic after taking the log and returns the statistic in linear scale.\n",
    "       INF values inside the data array are set to nan. \n",
    "       The func has to be able to handle nan values. \n",
    "    \"\"\"\n",
    "    ld = np.log(data)\n",
    "    ld[np.isinf(ld)] = np.nan #requires func to handle nan-data.\n",
    "    st = func(ld)\n",
    "    return np.exp(st)\n",
    "\n",
    "def iterative(hand, extent, water_levels=range(15)):\n",
    "    #accuracy=np.zeros(len(water_levels))    \n",
    "    #for k,w in enumerate(water_levels):\n",
    "    #    iterative_flood_extent=hand<w\n",
    "    #    TP=np.nansum(np.logical_and(iterative_flood_extent==1, extent==1)) #true positive\n",
    "    #    TN=np.nansum(np.logical_and(iterative_flood_extent==0, extent==0)) # True negative\n",
    "    #    FP=np.nansum(np.logical_and(iterative_flood_extent==1, extent==0)) # False positive\n",
    "    #    FN=np.nansum(np.logical_and(iterative_flood_extent==0, extent==1)) # False negative\n",
    "    #    #accuracy[k]=(TP+TN)/(TP+TN+FP+FN) #accuracy \n",
    "    #    accuracy[k]=TP/(TP+FP+FN) #threat score\n",
    "    #best_water_level=water_levels[np.argmax(accuracy)]\n",
    "    \n",
    "    def _goal_ts(w):\n",
    "        iterative_flood_extent=hand<w # w=water level\n",
    "        TP = np.nansum(np.logical_and(iterative_flood_extent==1, extent==1)) #true positive\n",
    "        TN = np.nansum(np.logical_and(iterative_flood_extent==0, extent==0)) # True negative\n",
    "        FP = np.nansum(np.logical_and(iterative_flood_extent==1, extent==0)) # False positive\n",
    "        FN = np.nansum(np.logical_and(iterative_flood_extent==0, extent==1)) # False negative\n",
    "        return 1 - TP / (TP + FP + FN) #threat score #we will minimize goal func, hence 1-threat_score.\n",
    "    #bounds=(min(water_levels), max(water_levels))\n",
    "    #opt_res=optimize.minimize(_goal_ts, max(bounds),method='TNC',bounds=[bounds],options={'xtol':0.1, 'scale':1})\n",
    "\n",
    "    class MyBounds(object):\n",
    "        def __init__(self, xmax=[max(water_levels)], xmin=[min(water_levels)]):\n",
    "            self.xmax = np.array(xmax)\n",
    "            self.xmin = np.array(xmin)\n",
    "        def __call__(self, **kwargs):\n",
    "            x = kwargs[\"x_new\"]\n",
    "            tmax = bool(np.all(x <= self.xmax))\n",
    "            tmin = bool(np.all(x >= self.xmin))\n",
    "            return tmax and tmin\n",
    "    mybounds = MyBounds()\n",
    "    x0 = [np.mean(water_levels)]\n",
    "    opt_res = optimize.basinhopping(_goal_ts, x0, niter=10000, niter_success=100, accept_test=mybounds)\n",
    "    if opt_res.message[0] == 'success condition satisfied' or opt_res.message[0] == 'requested number of basinhopping iterations completed successfully':\n",
    "        best_water_level = opt_res.x[0]\n",
    "    else:        \n",
    "        best_water_level = np.inf # set to inf to mark unstable solution.    \n",
    "    return best_water_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "# Define Some Common Parameters\n",
    "\n",
    "This section allows you to customize how flood depth estimation is performed. **The main paramters that users might want to change are:**\n",
    "    \n",
    "- **Input File Naming Scheme:** This is only relevant if you are interested in mosaicking large areas. This gives you the option of either picking initial flood mapping information created in Lab 2 (naming scheme */*_water_mask_combined.tiff*) or final post-processed flood mapping information (naming scheme */*_fcWM.tiff*) for flood depth calculation [**for the HydroSAR training, please do not change this variable from its default**]\n",
    "- **Estimator:** Three different estimation approaches were implemented and are currently being tested by the HydroSAR team: \n",
    "- **Iterative:** Basin hopping optimization method to match flooded areas to flood depth estimates given the HAND layer. From our current experience, this is the most accurate, but also the most time consuming approach.\n",
    "- **Normalized Median Absolute Deviation (nmad):** Uses a median operator to estimate the variation to increase robustness in the presence of outliers. [**We will use this approach for the HydroSAR training**].\n",
    "- **Logstat:** This approach calculates mean and standard deviation of HAND heights in the logarithmic domain to improve robustness for very non-Gaussian data distributions.\n",
    "- **Numpy:** Calculates statistics needed in the approach in linear scale. This approach is least robust to outliers and non-Gaussian distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "#parameters setup\n",
    "version = \"0.1.8\"\n",
    "water_classes = [1, 2, 3, 4, 5] # 1 has to be a water class, 0 is no water Others are optional.\n",
    "pattern = \"*_water_mask_combined.tiff\" #\"filter_*_amp_Classified.tif\"\n",
    "show_plots = True #turn this off for debugging with IPDB\n",
    "water_level_sigma = 3 #use 3*std to estimate max. water height (water level) for each object. Used for numpy, nmad,logstat\n",
    "estimator = \"nmad\" # iterative, numpy, nmad or logstat\n",
    "iterative_bounds = [0, 15] #only used for iterative\n",
    "output_prefix = '' # Output file is created in the same folder as flood extent. A prefix can be added to the filename.\n",
    "known_water_threshold = 30 #Threshold for extracting the known water area in percent. \n",
    "if show_plots:\n",
    "    %matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Prepare Data Set for HAND Calculation\n",
    "\n",
    "**Enter the path to the directory holding your tiffs:** Here we ask you if you want to calculate flood depth across a mosaic or for a single file. [**Please select \"single file\" for the HydroSAR Training Exercise**]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     1
    ],
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "#Here we ask if we are processing a spatial mosaic or a single file. \n",
    "if yesno(\"Would you like to mosaic multiple files (e.g. large area coverage from multiple scenes)?\"):\n",
    "    print(f\"Choose one of the water extent files inside the folder. All files with matching the following will be processed: {pattern}\")\n",
    "    file_folder_func = lambda x: Path(x).parent\n",
    "    single_file = False\n",
    "else:    \n",
    "    print(\"Choose your GDAL compatible Classified water extent file using the file browser below:\")\n",
    "    file_folder_func = lambda x: x\n",
    "    single_file = True\n",
    "f = FileChooser(Path.cwd())\n",
    "display(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from os import WEXITSTATUS\n",
    "\n",
    "work_path = Path(file_folder_func(f.selected)).parent\n",
    "\n",
    "#Check if folder or file\n",
    "tiff_path = Path(file_folder_func(f.selected))\n",
    "\n",
    "if not single_file:\n",
    "    #merge all tifs\n",
    "    tiffs = list(map(str,list(tiff_path.rglob(f\"{pattern}\"))))\n",
    "    print(\"Processing the following files:\")\n",
    "    pprint.pprint(tiffs)\n",
    "    \n",
    "# May need to change location of where Water_Masks.vrt is being created\n",
    "    combined_vrt = tiff_path/f'{tiff_path.name}.vrt'\n",
    "    combined_tif = tiff_path/f'{tiff_path.name}.tif'\n",
    "    \n",
    "    print(combined_vrt)\n",
    "    print(combined_tif)\n",
    "    \n",
    "    build_vrt(str(combined_vrt), tiffs)\n",
    "    #translate vrt to tif. There is a problem warping with the vrt.\n",
    "    cmd_translate = f\"gdal_translate -of GTiff {combined_vrt} {combined_tif}\"\n",
    "    print(cmd_translate)\n",
    "    exitcode = WEXITSTATUS(system(cmd_translate))\n",
    "    if exitcode != 0:\n",
    "        print(\"Error in creating a mosaic from selected files\\n\")\n",
    "        print(f\"\\nCommand failed:\\n {cmd_translate}\")\n",
    "        assert exitcode == 0\n",
    "    tiff_path = combined_tif\n",
    "else:\n",
    "    pass # do nothing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "**Reproject tiffs from UTM to EPSG 4326:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Choose your GDAL compatible precalculated HAND file using the file browser below:\")\n",
    "\n",
    "# prehaps search path where 'hand' is stored and replace Path.cwd()\n",
    "f = FileChooser(Path.cwd())\n",
    "display(f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#checking current coordinate reference system\n",
    "\n",
    "tiff_dir = tiff_path.parent\n",
    "\n",
    "info = (gdal.Info(str(tiff_path), options = ['-json']))\n",
    "info = info['coordinateSystem']['wkt']\n",
    "epsg = info.split('ID')[-1].split(',')[1].replace(']', '')\n",
    "print(f\"EPSG code for Water Extent: {epsg}\")\n",
    "\n",
    "hand_dem = Path(f.selected)\n",
    "info_hand = (gdal.Info(str(hand_dem), options = ['-json']))\n",
    "info_hand = info_hand['coordinateSystem']['wkt']\n",
    "epsg_hand = info_hand.split('ID')[-1].split(',')[1].replace(']', '')\n",
    "print(f'EPSG for HAND: {epsg_hand}')\n",
    "\n",
    "# #Reprojecting coordinate system\n",
    "filename = tiff_path.name\n",
    "filenoext = Path(filename).stem #given vrt we want to force geotif output with tif extension\n",
    "from os import symlink\n",
    "if epsg != epsg_hand:\n",
    "    cmd_reproj=f\"gdalwarp -overwrite -t_srs EPSG:{epsg_hand} -r cubicspline -of GTiff {tiff_dir}/{filename} {tiff_dir}/reproj_{filenoext}.tif\"\n",
    "    print(cmd_reproj)\n",
    "    system(cmd_reproj)\n",
    "else:\n",
    "    if (tiff_dir/f'reproj_{filenoext}.tif').exists():\n",
    "        (tiff_dir/f'reproj_{filenoext}.tif').unlink()\n",
    "    symlink(tiff_dir/filename, tiff_dir/f'reproj_{filenoext}.tif')\n",
    "    \n",
    "    \n",
    "# Building the virtual raster for Change Detection product(tiff)\n",
    "reprojected_flood_mask = tiff_dir/f\"reproj_{filenoext}.tif\"\n",
    "print(f\"Reprojected Flood Mask File: {reprojected_flood_mask}\")\n",
    "\n",
    "pixels, lines = get_size(str(reprojected_flood_mask))\n",
    "print(f\"X-dimension: {pixels} Y-dimension: {lines}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "#checking extent of the map\n",
    "info = (gdal.Info(str(reprojected_flood_mask), options = ['-json']))\n",
    "west, east, south, north = get_wesn(str(reprojected_flood_mask))\n",
    "print(f\"Retrieved Extent of Flood Extent (w/e/s/n):{west}, {east}, {south}, {north}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check if HAND is valid. \n",
    "hand_dem_bb = bounding_box(str(hand_dem))\n",
    "if not bounding_box_inside_bounding_box(bounding_box(str(reprojected_flood_mask)), hand_dem_bb):\n",
    "    print('Flood Extent Bounding Box:')\n",
    "    print(bounding_box(str(reprojected_flood_mask)))\n",
    "    print('HAND boundbing box:')\n",
    "    print(hand_dem_bb)\n",
    "    print('You can use BIG HAND Notebook to calculate HAND from a DEM.')\n",
    "    print('Image is not completely covered inside given HAND.')\n",
    "    print('If you continue your result may not be valid...')\n",
    "    if yesno(\"Do you want to continue?\"):\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError('Image is not completely covered inside given HAND.')\n",
    "\n",
    "#Clip HAND to the same size as the reprojected_flood_mask\n",
    "filename = hand_dem.name\n",
    "cmd_clip = f\"gdalwarp -overwrite -te {west} {south} {east} {north} -ts {pixels} {lines} -r lanczos  -of GTiff {hand_dem} {tiff_dir}/clip_{filename}\"\n",
    "print(cmd_clip)\n",
    "system(cmd_clip)\n",
    "\n",
    "# NO ATTRIBUTE NAMED 'readData'\n",
    "hand_array = gis.readData(f\"{tiff_dir}/clip_{filename}\")\n",
    "if np.all(hand_array==0):\n",
    "    print('HAND is all zeros. HAND DEM does not cover the imaged area.')\n",
    "    raise ValueError # THIS SHOULD NEVER HAPPEN now that we are checking the bounding box. Unless HAND is bad.     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Generating Flood Mask\n",
    "\n",
    "## Pull Known Perennial Water Information from Public Repository\n",
    "\n",
    "All perennial Global Surface Water data is produced under the Copernicus Programme: Jean-Francois Pekel, Andrew Cottam, Noel Gorelick, Alan S. Belward, High-resolution mapping of global surface water and its long-term changes. Nature 540, 418-422 (2016). (doi:10.1038/nature20584). **We pull this layer to make sure all perennial water is accounted for in the surface water information that is used for Flood Depth Map calculation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "#Get known Water Mask\n",
    "ths = known_water_threshold #30 #higher than 30% possibility \n",
    "known_water_mask = get_waterbody(str(reprojected_flood_mask), ths)\n",
    "if show_plots:\n",
    "    pl.matshow(known_water_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Grabbing Surface Water Extent Map Created in Lab 2\n",
    "\n",
    "Now we grab the Surface Water Extent Map that we created in Lab 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "#load and display change detection product from Hyp3\n",
    "hyp_map = gdal.Open(str(reprojected_flood_mask))\n",
    "change_map = hyp_map.ReadAsArray()\n",
    "\n",
    "#Initial mask layer generation\n",
    "for c in water_classes: # This allows more than a single water_class to be included in flood mask\n",
    "    change_map[change_map==c] = 1\n",
    "\n",
    "mask = change_map == 1\n",
    "flood_mask = np.bitwise_or(mask,known_water_mask) #add known water mask... #Added 20200921\n",
    "\n",
    "if show_plots:\n",
    "    pl.matshow(flood_mask)\n",
    "    pl.title('Final Flood Mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Flood Depth Map Calculation\n",
    "\n",
    "Now we **add known water information to the SAR-derived surface water detection maps** and then we **generate our desired Flood Depth Product:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Calculate Flood Depth - Show Progress Bar\n",
    "flood_mask_labels, num_labels = ndimage.label(flood_mask)\n",
    "print(f'Detected {num_labels} water bodies...')\n",
    "object_slices = ndimage.find_objects(flood_mask_labels)\n",
    "if show_plots:\n",
    "    pl.matshow(flood_mask_labels)\n",
    "    pl.colorbar()\n",
    "\n",
    "flood_depth=np.zeros(flood_mask.shape)\n",
    "print(f'Using estimator: {estimator}')\n",
    "for l in tqdm(range(1, num_labels)):#Skip first, largest label.\n",
    "    slices = object_slices[l-1] #osl label=1 is in object_slices[0]\n",
    "    min0 = slices[0].start\n",
    "    max0 = slices[0].stop\n",
    "    min1 = slices[1].start\n",
    "    max1 = slices[1].stop\n",
    "    flood_mask_labels_clip = flood_mask_labels[min0: max0, min1: max1] \n",
    "\n",
    "    flood_mask_clip = flood_mask[min0: max0, min1: max1].copy()\n",
    "    flood_mask_clip[flood_mask_labels_clip != l] = 0 #Maskout other flooded areas (labels)\n",
    "    hand_clip = hand_array[min0: max0, min1: max1] \n",
    "\n",
    "# Supressed warning in regards to /tmp/ipykernel_296/3146410417.py:26: RuntimeWarning: Mean of empty slicem=np.nanmean(hand_clip[flood_mask_labels_clip==l])\n",
    "# If this part crashes, try removing 'warning' \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore', r'Mean of empty slice')\n",
    "        if estimator.lower() == \"numpy\":\n",
    "            m = np.nanmean(hand_clip[flood_mask_labels_clip == l])\n",
    "            s = np.nanstd( hand_clip[flood_mask_labels_clip == l])\n",
    "            water_height = m + water_level_sigma * s\n",
    "        elif estimator.lower() == \"nmad\":\n",
    "            m = np.nanmean(hand_clip[flood_mask_labels_clip==l])\n",
    "            s = stats.median_abs_deviation(hand_clip[flood_mask_labels_clip==l], scale='normal', nan_policy='omit')\n",
    "            water_height = m + water_level_sigma * s\n",
    "        elif estimator.lower() == \"logstat\":\n",
    "            m = logstat(hand_clip[flood_mask_labels_clip==l], func=np.nanmean)\n",
    "            s = logstat(hand_clip[flood_mask_labels_clip==l])  \n",
    "            water_height = m + water_level_sigma * s\n",
    "        elif estimator.lower() == \"iterative\":\n",
    "            water_height = iterative(hand_clip, flood_mask_labels_clip==l, water_levels=iterative_bounds)            \n",
    "        else:\n",
    "            print(\"Unknown estimator selected for water height calculation.\")\n",
    "            raise ValueError\n",
    "\n",
    "        \n",
    "    #if np.isnan(m) or np.isnan(s):\n",
    "    #    set_trace()\n",
    "    flood_depth_clip = flood_depth[min0:max0, min1:max1]\n",
    "    flood_depth_clip[flood_mask_labels_clip==l] = water_height - hand_clip[flood_mask_labels_clip==l]    \n",
    "\n",
    "#remove negative depths:\n",
    "flood_depth[flood_depth<0] = 0\n",
    "if show_plots:\n",
    "    m = np.nanmean(flood_depth)\n",
    "    s = np.nanstd(flood_depth)\n",
    "    clim_min = max([m-2*s, 0])\n",
    "    clim_max = min([m+2*s, 5])\n",
    "    pl.matshow(flood_depth)\n",
    "    pl.colorbar()\n",
    "    pl.clim([clim_min, clim_max])\n",
    "    pl.title('Estimated Flood Depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Export Your Flood Depth Map as GeoTIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "#Saving Estimated FD to geotiff\n",
    "geotiff_path = work_path/'geotiff'\n",
    "\n",
    "if not geotiff_path.exists():\n",
    "    geotiff_path.mkdir()\n",
    "\n",
    "gT = gis.getGeoTransform(f\"{tiff_dir}/clip_{filename}\")\n",
    "\n",
    "outfilename = str(tiff_path).split(str(tiff_dir))[1].split(\"/\")[1]\n",
    "srs_proj4 = gdal_get_projection(f\"{tiff_dir}/clip_{filename}\")\n",
    "gis.writeTiff(flood_depth, gT, filename = \"_\".join(filter(None, [output_prefix, f\"{geotiff_path}/HAND_WaterDepth\", estimator, version, outfilename])), srs_proj4=srs_proj4, nodata=0, options = [\"TILED=YES\",\"COMPRESS=LZW\",\"INTERLEAVE=BAND\",\"BIGTIFF=YES\"])\n",
    "gis.writeTiff(flood_mask, gT, filename = \"_\".join(filter(None, [output_prefix, f\"{geotiff_path}/Flood_mask\", estimator, version, outfilename])), srs_proj4=srs_proj4, options = [\"TILED=YES\",\"COMPRESS=LZW\",\"INTERLEAVE=BAND\",\"BIGTIFF=YES\"])\n",
    "\n",
    "flood_mask[known_water_mask] = 0\n",
    "flood_depth[np.bitwise_not(flood_mask)] = 0\n",
    "gis.writeTiff(flood_depth, gT, filename = \"_\".join(filter(None, [output_prefix, f\"{geotiff_path}/HAND_FloodDepth\", estimator, version, outfilename])), nodata=0, srs_proj4=srs_proj4, options = [\"TILED=YES\",\"COMPRESS=LZW\",\"INTERLEAVE=BAND\",\"BIGTIFF=YES\"])\n",
    "print('Export complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Clean Up Temporary and Intermediate Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "#clear some intermediate files\n",
    "try:\n",
    "    reprojected_flood_mask.unlink()\n",
    "except:\n",
    "    pass\n",
    "try:    \n",
    "    (tiff_dir/f'clip_{filename}').unlink()\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    (tiff_dir/f'reproj_{filenoext}.tif').unlink()\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    (tiff_dir/f'surface_water_map_clip.tif').unlink()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "---\n",
    "- *Version 0.1.9 - Batu Osmanoglu, MinJeong Jo*\n",
    "- *Version 0.1.10 - Rui Kawahara*\n",
    "- *Version 0.1.11 - Alex Lewandowski*\n",
    "\n",
    "---\n",
    "\n",
    "***Change Log***\n",
    "- *2021/11/23: v0.1.11 - Alex Lewandowski*\n",
    "    - *Feat: Use url-widget to access url via js, needed for jupyterLab \n",
    "    - *Feat: Use ipyfilechooser to shorten notebook*\n",
    "    - *Feat: Change html to Markdown for better rendering on GitHub*\n",
    "- *2021/11/8: v0.1.10 - Rui Kawahara* \n",
    "    - *Configured in such way that the new Geotiff and S_WATER directory gets generated in source directory (e.g. `BangladeshFloodMapping`).*\n",
    "    - *Most of `os` modules are updated to `pathlib` counterparts.*\n",
    "    - *Works with multiple images as well as single image processing.*\n",
    "- *2021/01/24: v0.1.9 - Batu Osmanoglu, MinJeong Jo*\n",
    "    - *Added `iterative` estimator. This method is based on `scipy.optimize.basinhopping` with bounds, which can be specified with the `iterative_bounds` parameter. It takes considerably longer to use iterative method as it tried to match the observed flood-extent pattern at different water levels.*\n",
    "- *2021/01/19:*\n",
    "    - Minor cleanup and threshold implementation to `get_waterbody`. Also changed the dataset to 2019 (`downloads2019v2`).\n",
    "- *2020/12/01:*\n",
    "    - *Added new statistical estimators for maximum water height: numpy, nmad or logstat. Numpy uses standard mean, and std.dev. functions. NMAD uses normalized mean absolute difference for sigma. See `scipy.stats.median_abs_deviation()` for details. logstat uses standard mean and std.dev functions after taking the logarithm of the data. See `logstat()` for details.*\n",
    "- *2020/11/09:*\n",
    "    - *Changed known water source, Occurrence 2019 vertion. Added a threshold variable.*\n",
    "- *2020/10/22:*\n",
    "    - *BugFix: During reproj EPSG code was wrongly identified. Also if EPSG code is read-wrong the -s_srs flag in gdal_warp causing the reprojection to fail. Fixed both.*\n",
    "    - *Testing: Replaced standard deviation with normalized mean absolute deviation. For large riverine floods, large water objects result in overestimation of sigma resulting in deeper than expected water depths.*\n",
    "    - *Feat: Removing negative water depths in the final map.*\n",
    "- *2020/10/10:*\n",
    "    - *BugFix: Looks like with the recent updates `gdal.Info(tiff_path, options = ['-json'])` returns a dict instead of a string. Fixed the collection of projection based on this.*\n",
    "    - *Feat: Allowing to continue even if HAND is smaller than image. This is useful if SAR image covers significant amount of ocean etc.*\n",
    "    - *BugFix: gis.readData() was failing to read the VRT generated in get_waterbody. gdalwarp outputs a GeoTif now.*\n",
    "- *2020/10/01:*\n",
    "    - *Feat: Moving away from repetitive argwhere to ndimage.find_objects results in ~6000x faster calculation.*\n",
    "- *2020/09/30:*\n",
    "    - *BugFix: The known water mask and input mask was merged using a sum operator instead of a bitwise_or operator.*\n",
    "- *2020/09/20:*\n",
    "    - *BugFix: Added known water download and addition to the mask. This helps to make sure known water bodies are handled as a single object. Removed morphological filters also.*\n",
    "- *2020/09/17:*\n",
    "    - *First version.\n",
    "- *2021/04/016:*\n",
    "    - *Update: import gdal and osr from osgeo*"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "hydrosar [conda env:.local-hydrosar]",
   "language": "python",
   "name": "conda-env-.local-hydrosar-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
