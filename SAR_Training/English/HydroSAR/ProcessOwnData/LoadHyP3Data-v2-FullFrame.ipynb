{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![HydroSAR Banner](./../NotebookAddOns/HydroSARbanner.jpg)\n",
    "\n",
    "# Load HyP3 Data for Full Frame Processing\n",
    "\n",
    "<img style=\"padding: 7px\" src=\"../../Master/NotebookAddons/UAFLogo_A_647.png\" width=\"170\" align=\"right\"/>\n",
    "\n",
    "### Franz J Meyer and Alex Lewandowski; University of Alaska Fairbanks\n",
    "\n",
    "This notebook downloads data from an ASF-HyP3 subscription and prepares it for full frame processing with subsequent HydroSAR algorithms. Data are downloaded, extracted, and organized. DEM tiles are extracted and mosaicked to a consistent large-scale product for use in other HydroSAR workflows.\n",
    "    \n",
    "**Complete Full Frame Flood Mapping Sequence:**\n",
    "\n",
    "This notebook is the first step in the **Full Frame Flood Mapping Sequence**, which consists of running the following notebooks in the order given:\n",
    "\n",
    "1. **Load HyP3 Data:** Run this notebook (LoadHyP3Data-FullFrame.ipynb)\n",
    "1. **Calculate HAND layer:** Run [Big_Hand_notebook.ipynb](./Big_Hand_notebook.ipynb)\n",
    "1. **Perform Full Frame Surface Water Mapping:** Run [HYDRO30Workflow-v1.ipynb](./HYDRO30Workflow-v1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Important Note about JupyterHub**\n",
    "\n",
    "Your JupyterHub server will automatically shutdown when left idle for more than 1 hour. Your notebooks will not be lost but you will have to restart their kernels and re-run them from the beginning. You will not be able to seamlessly continue running a partially run notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import url_widget as url_w\n",
    "notebookUrl = url_w.URLWidget()\n",
    "display(notebookUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "\n",
    "notebookUrl = notebookUrl.value\n",
    "user = !echo $JUPYTERHUB_USER\n",
    "env = !echo $CONDA_PREFIX\n",
    "if env[0] == '':\n",
    "    env[0] = 'Python 3 (base)'\n",
    "if env[0] != '/home/jovyan/.local/envs/hydrosar':\n",
    "    display(Markdown(f'<text style=color:red><strong>WARNING:</strong></text>'))\n",
    "    display(Markdown(f'<text style=color:red>This notebook should be run using the \"hydrosar\" conda environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>It is currently using the \"{env[0].split(\"/\")[-1]}\" environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Select \"hydrosar\" from the \"Change Kernel\" submenu of the \"Kernel\" menu.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>If the \"hydrosar\" environment is not present, use <a href=\"{notebookUrl.split(\"/user\")[0]}/user/{user[0]}/notebooks/conda_environments/Create_OSL_Conda_Environments.ipynb\"> Create_OSL_Conda_Environments.ipynb </a> to create it.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Note that you must restart your server after creating a new environment before it is usable by notebooks.</text>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Importing Relevant Python Packages\n",
    "\n",
    "In this notebook we will use the following scientific libraries:\n",
    "\n",
    "1. **[GDAL](https://www.gdal.org/)** is a software library for reading and writing raster and vector geospatial data formats. It includes a collection of programs tailored for geospatial data processing. Most modern GIS systems (such as ArcGIS or QGIS) use GDAL in the background.\n",
    "1. **[NumPy](http://www.numpy.org/)** is one of the principal packages for scientific applications of Python. It is intended for processing large multidimensional arrays and matrices, and an extensive collection of high-level mathematical functions and implemented methods makes it possible to perform various operations with these objects.\n",
    "\n",
    "**Our first step is to import them:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import json # for loads\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pytz\n",
    "import re\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "\n",
    "from IPython.display import HTML, display, clear_output, Markdown\n",
    "    \n",
    "from hyp3_sdk import Batch, HyP3\n",
    "\n",
    "import opensarlab_lib as asfn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Load Your Own Data Stack Into the Notebook\n",
    "\n",
    "This notebook assumes that you've created your own data stack over your personal area of interest using the [Alaska Satellite Facility's](https://www.asf.alaska.edu/) value-added product system [HyP3](https://hyp3-docs.asf.alaska.edu/). HyP3 is an environment that is used by ASF to prototype value added products and provide them to users to collect feedback. \n",
    "\n",
    "This lab expects [Radiometric Terrain Corrected](https://media.asf.alaska.edu/uploads/RTC/rtc_atbd_v1.2_final.pdf) (RTC) image products as input, so be sure to select an RTC process when creating the subscription for your input data within HyP. Prefer a unique orbit geometry **(choose ascending or descending, not both)** to keep geometric differences between images low. \n",
    "\n",
    "We will retrieve HyP3 data via the HyP3 API. As both HyP3 and the Notebook environment sit in the [Amazon Web Services (AWS)](https://aws.amazon.com/) cloud, data transfer is quick and cost effective.\n",
    "\n",
    "---\n",
    "\n",
    "Before we download anything, create a working directory for this analysis and change into it. \n",
    "\n",
    "**Select or create a working directory for the analysis:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    print(f\"Current working directory: {Path.cwd()}\")\n",
    "    data_dir = Path(input(f\"\\nPlease enter the name of a directory in which to store your data for this analysis.\"))\n",
    "    if data_dir == Path('.'):\n",
    "        continue\n",
    "    if data_dir.is_dir():\n",
    "        contents = data_dir.glob('*')\n",
    "        if len(list(contents)) > 0:\n",
    "            choice = asfn.handle_old_data(data_dir)\n",
    "            if choice == 1:\n",
    "                if data_dir.exists():\n",
    "                    shutil.rmtree(data_dir)\n",
    "                data_dir.mkdir()\n",
    "                break\n",
    "            elif choice == 2:\n",
    "                break\n",
    "            else:\n",
    "                clear_output()\n",
    "                continue\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        data_dir.mkdir()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Change into the analysis directory and create a folder in which to download your RTC products:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Setting Paths\n",
    "analysis_directory = Path.cwd()/data_dir\n",
    "print(f\"analysis_directory: {analysis_directory}\")\n",
    "\n",
    "products_path = analysis_directory/\"rtc_products\"\n",
    "products_path.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a HyP3 object and authenticate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp3 = HyP3(prompt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List your Hyp3 RTC_GAMMA projects containing active products and select one:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_hyp3_info = hyp3.my_info()\n",
    "active_projects = dict()\n",
    "\n",
    "for project in my_hyp3_info['job_names']:\n",
    "    batch = Batch()\n",
    "    try:\n",
    "        batch = hyp3.find_jobs(name=project, job_type='RTC_GAMMA').filter_jobs(include_expired=False)\n",
    "    except UserWarning:\n",
    "        pass       \n",
    "    if len(batch) > 0:\n",
    "        active_projects.update({batch.jobs[0].name: batch})\n",
    "        \n",
    "if len(active_projects) > 0:\n",
    "    display(Markdown(\"<text style='color:darkred;'>Note: After selecting a project, you must select the next cell before hitting the 'Run' button or typing Shift/Enter.</text>\"))\n",
    "    display(Markdown(\"<text style='color:darkred;'>Otherwise, you will rerun this code cell.</text>\"))\n",
    "    print('\\nSelect a Project:')\n",
    "    project_select = asfn.select_parameter(active_projects)\n",
    "    display(project_select)\n",
    "else:\n",
    "    print(\"Found no active RTC_GAMMA jobs in any HyP3 projects\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select a date range of products to download:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = project_select.value\n",
    "\n",
    "display(Markdown(\"<text style='color:darkred;'>Note: After selecting a date range, you should select the next cell before hitting the 'Run' button or typing Shift/Enter.</text>\"))\n",
    "display(Markdown(\"<text style='color:darkred;'>Otherwise, you may simply rerun this code cell.</text>\"))\n",
    "print('\\nSelect a Date Range:')\n",
    "dates = asfn.get_job_dates(batch)\n",
    "date_picker = asfn.gui_date_picker(dates)\n",
    "date_picker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the selected date range and remove products falling outside of it:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = asfn.get_slider_vals(date_picker)\n",
    "date_range[0] = date_range[0].date()\n",
    "date_range[1] = date_range[1].date()\n",
    "print(f\"Date Range: {str(date_range[0])} to {str(date_range[1])}\")\n",
    "batch = asfn.filter_jobs_by_date(batch, date_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gather the available paths and orbit directions for the remaining products:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"<text style='color:darkred;'><text style='font-size:150%;'>This may take some time for projects containing many jobs...</text></text>\"))\n",
    "asfn.set_paths_orbits(batch)\n",
    "paths = set()\n",
    "orbit_directions = set()\n",
    "for p in batch:\n",
    "    paths.add(p.path)\n",
    "    orbit_directions.add(p.orbit_direction)\n",
    "paths.add('All Paths')\n",
    "display(Markdown(f\"<text style=color:blue><text style='font-size:175%;'>Done.</text></text>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Select a path or paths (use shift or ctrl to select multiple paths):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"<text style='color:darkred;'>Note: After selecting a path, you must select the next cell before hitting the 'Run' button or typing Shift/Enter.</text>\"))\n",
    "display(Markdown(\"<text style='color:darkred;'>Otherwise, you will simply rerun this code cell.</text>\"))\n",
    "print('\\nSelect a Path:')\n",
    "path_choice = asfn.select_mult_parameters(paths)\n",
    "path_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_path = path_choice.value\n",
    "if flight_path:\n",
    "    if flight_path:\n",
    "        print(f\"Flight Path: {flight_path}\")\n",
    "    else:\n",
    "        print('Flight Path: All Paths')\n",
    "else:\n",
    "    print(\"WARNING: You must select a flight path in the previous cell, then rerun this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select an orbit direction:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(orbit_directions) > 1:\n",
    "    display(Markdown(\"<text style='color:red;'>Note: After selecting a flight direction, you must select the next cell before hitting the 'Run' button or typing Shift/Enter.</text>\"))\n",
    "    display(Markdown(\"<text style='color:red;'>Otherwise, you will simply rerun this code cell.</text>\"))\n",
    "print('\\nSelect a Flight Direction:')\n",
    "direction_choice = asfn.select_parameter(orbit_directions, 'Direction:')\n",
    "direction_choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the selected orbit direction:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction = direction_choice.value\n",
    "print(f\"Orbit Direction: {direction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter jobs by path and orbit direction:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = asfn.filter_jobs_by_path(batch, flight_path)\n",
    "batch = asfn.filter_jobs_by_orbit(batch, direction)\n",
    "print(f\"There are {len(batch)} products to download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download the products, unzip them into the rtc_products directory, and delete the zip files:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nProject: {batch.jobs[0].name}\")\n",
    "project_zips = batch.download_files(products_path)\n",
    "for z in project_zips:\n",
    "    asfn.asf_unzip(str(products_path), str(z))\n",
    "    z.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Migrate VV & VH images into folder `FullFrames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Uitility Functions needed for Extracting the Relevant Information from the downloaded Zip Files\n",
    "def get_tiff_paths(regex, pths):\n",
    "    tiff_paths = list()\n",
    "    paths = (Path.cwd()).glob(pths)\n",
    "    for pth in list(paths):\n",
    "        tiff_path = re.search(regex, str(pth))\n",
    "        if tiff_path:\n",
    "            tiff_paths.append(pth)\n",
    "    return tiff_paths\n",
    "\n",
    "with asfn.work_dir(products_path):\n",
    "    regex = \"/(\\w{1,600}/){0,}\\w{5,600}(_|-)V(V|H).(tif|tiff)$\"\n",
    "    pths = f\"*/*.tif*\"\n",
    "    tiff_paths = get_tiff_paths(regex, pths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Extract Relevant Files from Zips and Organize your Data\n",
    "ff_path = Path(f\"{analysis_directory}/FullFrames/\")\n",
    "if not ff_path.is_dir():\n",
    "    ff_path.mkdir()\n",
    "print('Copying VV and VH bands into folder FullFrames ...')\n",
    "for pth in tqdm(tiff_paths):\n",
    "    pol_regex = '(vv|VV|vh|VH)(?=.tif)'\n",
    "    pol = re.search(pol_regex, str(pth))\n",
    "    if pol:\n",
    "        pol = pol.group(0)\n",
    "    dt_regex = '\\d{8}T\\d{6}'\n",
    "    dt = re.search(dt_regex, str(pth))\n",
    "    if dt:\n",
    "        dt = dt.group(0)\n",
    "    outname = (f\"{dt}_{pol}.tif\")\n",
    "    pth.rename(ff_path/outname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Mosaicking DEMs \n",
    "\n",
    "### Collect DEM files and Migrate into Folder `DEMs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Look for DEM files in your Subscription --> Needed to facilitate HAND Calculation\n",
    "dem_path = analysis_directory/'DEMS'\n",
    "if not dem_path.is_dir():\n",
    "    dem_path.mkdir()\n",
    "dems_relative = f\"*/*/*/*dem.tif\"\n",
    "print(dems_relative)\n",
    "dems = Path().glob(dems_relative)\n",
    "for d in dems:\n",
    "    print(dem_path/d.name)\n",
    "    d.rename(dem_path/d.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Performing Mosaicking\n",
    "\n",
    "**Writing Support Functions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Writing some Uitility Functions\n",
    "def get_DEM_paths(pths):\n",
    "    DEM_paths = []\n",
    "    \n",
    "    for pth in glob.glob(pths):\n",
    "        DEM_paths.append(pth)\n",
    "    return DEM_paths\n",
    "\n",
    "def get_DEM_dates(paths):\n",
    "    dates = []\n",
    "    for pth in tiff_paths:\n",
    "        date = pth.split(\"/\")[-1].split(\"_\")[3].split(\"T\")[0]\n",
    "        dates.append(date)\n",
    "    return dates\n",
    "\n",
    "def print_tiff_paths(tiff_paths):\n",
    "    print(\"Tiff paths:\")\n",
    "    for p in tiff_paths:\n",
    "        print(f\"{p}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Identifying Predominant UTM zone:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check UTM Zones and Identify Dominant UTM Zone for your data stack\n",
    "\n",
    "DEM_paths = list(dem_path.glob(\"*.tif\"))\n",
    "\n",
    "utm_zones = []\n",
    "utm_types = []\n",
    "print('Checking UTM Zones in the DEM data stack ...\\n')\n",
    "for dem in DEM_paths:\n",
    "    info = (gdal.Info(str(dem), options = ['-json']))\n",
    "    info = json.dumps(info)\n",
    "    info = (json.loads(info))['coordinateSystem']['wkt']\n",
    "    zone = info.split('ID')[-1].split(',')[1][0:-2]\n",
    "    utm_zones.append(zone)\n",
    "    typ = info.split('ID')[-1].split('\"')[1]\n",
    "    utm_types.append(typ)\n",
    "print(f\"UTM Zones:\\n {utm_zones}\\n\")\n",
    "print(f\"UTM Types:\\n {utm_types}\")\n",
    "\n",
    "# Identifying Predominant UTM Zone\n",
    "\n",
    "utm_unique, counts = np.unique(utm_zones, return_counts=True)\n",
    "a = np.where(counts == np.max(counts))\n",
    "predominant_utm = utm_unique[a][0]\n",
    "print(f\"\\nPredominant UTM Zone: {predominant_utm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Reproject and Mosaic DEMs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reproject (if needed) and Mosaic DEM Files in Preparation for Subsequent HAND Calculation\n",
    "# print(DEM_paths)\n",
    "reproject_indicies = [i for i, j in enumerate(utm_zones) if j != predominant_utm] #makes list of indicies in utm_zones that need to be reprojected\n",
    "print('--------------------------------------------')\n",
    "print('Reprojecting %4.1f files' %(len(reproject_indicies)))\n",
    "print('--------------------------------------------')\n",
    "for k in reproject_indicies:\n",
    "    temppath = f\"{str(DEM_paths[k].parent)}/r{DEM_paths[k].name}\"\n",
    "    print(temppath)  \n",
    "\n",
    "    cmd = f\"gdalwarp -overwrite {DEM_paths[k]} {temppath} -s_srs {utm_types[k]}:{utm_zones[k]} -t_srs EPSG:{predominant_utm}\"\n",
    "#     print(cmd)\n",
    "    !{cmd}\n",
    "    \n",
    "    DEM_paths[k].unlink()\n",
    "\n",
    "print(' ')\n",
    "print('--------------------------------------------')\n",
    "print('Update DEM Paths')\n",
    "print('--------------------------------------------')\n",
    "DEM_paths = list(dem_path.glob(\"*.tif\"))\n",
    "for d in DEM_paths:\n",
    "    print(d)\n",
    "\n",
    "\n",
    "print(' ')\n",
    "print('--------------------------------------------')\n",
    "print('Build String of DEMs to Merge')\n",
    "print('--------------------------------------------')\n",
    "DEM_merge_paths = \"\"\n",
    "for pth in DEM_paths:\n",
    "    DEM_merge_paths = f\"{str(pth)} {DEM_merge_paths}\"\n",
    "print(DEM_merge_paths)\n",
    "   \n",
    "print(' ')\n",
    "print('--------------------------------------------')\n",
    "print('Create DEM Mosaic')\n",
    "print('--------------------------------------------')\n",
    "output = f\"{ff_path}/DEM-Mosaic.tif\"\n",
    "gdal_command = f\"gdal_merge.py -o {output} {DEM_merge_paths}\"\n",
    "# print(f\"\\n\\nCalling the command: {gdal_command}\\n\")\n",
    "!{gdal_command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Cleanup Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Cleaning up Temporary Files\n",
    "shutil.rmtree(dem_path)\n",
    "shutil.rmtree(products_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "\n",
    "*LoadHyP3Data-v2-FullFrame.ipynb - Version 1.1.0 - November 2021*\n",
    "\n",
    "*Version Changes:*\n",
    "\n",
    "- *asf_notebook -> opensarlab_lib*\n",
    "- *url_wdiget*\n",
    "- *html -> markdown*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydrosar",
   "language": "python",
   "name": "conda-env-.local-hydrosar-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
