{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![HydroSAR Banner](./NotebookAddOns/HydroSARbanner.jpg)\n",
    "\n",
    "# Exploring SAR Time Series Data for Flood Monitoring\n",
    "\n",
    "**Franz J Meyer; University of Alaska Fairbanks**\n",
    "\n",
    "<img style=\"padding:7px;\" src=\"../Master/NotebookAddons/UAFLogo_A_647.png\" width=\"170\" align=\"right\" /></font>\n",
    "\n",
    "This notebook introduces you to the time series signatures associated with flooding. The data analysis is done in the framework of *Jupyter Notebooks*. The Jupyter Notebook environment is easy to launch in any web browser for interactive data exploration with provided or new training data. Notebooks are comprised of text written in a combination of executable python code and markdown formatting including latex style mathematical equations. Another advantage of Jupyter Notebooks is that they can easily be expanded, changed, and shared with new data sets or newly available time series steps. Therefore, they provide an excellent basis for collaborative and repeatable data analysis.\n",
    "\n",
    "**This notebook covers the following data analysis concepts:**\n",
    "\n",
    "- How to load time series stacks into Jupyter Notebooks and how to explore image content using basic functions such as mean value calculation and histogram analysis.\n",
    "- How to extract time series information for individual pixels of an image.\n",
    "- Typical time series signatures over forests and deforestation sites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Notes about JupyterHub**\n",
    "\n",
    "Your JupyterHub server will automatically shutdown when left idle for more than 1 hour. Your notebooks will not be lost but you will have to restart their kernels and re-run them from the beginning. You will not be able to seamlessly continue running a partially run notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import url_widget as url_w\n",
    "notebookUrl = url_w.URLWidget()\n",
    "display(notebookUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "\n",
    "notebookUrl = notebookUrl.value\n",
    "user = !echo $JUPYTERHUB_USER\n",
    "env = !echo $CONDA_PREFIX\n",
    "if env[0] == '':\n",
    "    env[0] = 'Python 3 (base)'\n",
    "if env[0] != '/home/jovyan/.local/envs/rtc_analysis':\n",
    "    display(Markdown(f'<text style=color:red><strong>WARNING:</strong></text>'))\n",
    "    display(Markdown(f'<text style=color:red>This notebook should be run using the \"rtc_analysis\" conda environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>It is currently using the \"{env[0].split(\"/\")[-1]}\" environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Select the \"rtc_analysis\" from the \"Change Kernel\" submenu of the \"Kernel\" menu.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>If the \"rtc_analysis\" environment is not present, use <a href=\"{notebookUrl.split(\"/user\")[0]}/user/{user[0]}/notebooks/conda_environments/Create_OSL_Conda_Environments.ipynb\"> Create_OSL_Conda_Environments.ipynb </a> to create it.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Note that you must restart your server after creating a new environment before it is usable by notebooks.</text>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Importing Relevant Python Packages\n",
    "\n",
    "In this notebook we will use the following scientific libraries:\n",
    "\n",
    "- [GDAL](https://www.gdal.org/) is a software library for reading and writing raster and vector geospatial data formats. It includes a collection of programs tailored for geospatial data processing. Most modern GIS systems (such as ArcGIS or QGIS) use GDAL in the background.\n",
    "- [NumPy](http://www.numpy.org/) is one of the principal packages for scientific applications of Python. It is intended for processing large multidimensional arrays and matrices, and an extensive collection of high-level mathematical functions and implemented methods makes it possible to perform various operations with these objects.\n",
    "- [Matplotlib](https://matplotlib.org/index.html) is a low-level library for creating two-dimensional diagrams and graphs. With its help, you can build diverse charts, from histograms and scatterplots to non-Cartesian coordinates graphs. Moreover, many popular plotting libraries are designed to work in conjunction with matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from pathlib import Path\n",
    "from math import ceil\n",
    "\n",
    "from osgeo import gdal # for GetRasterBand, Open, ReadAsArray\n",
    "import numpy as np #for log10, mean, percentile, power\n",
    "import pyproj # for Proj, transform\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt # for add_subplot, axis, figure, imshow, legend, plot, set_axis_off, set_data,\n",
    "                                # set_title, set_xlabel, set_ylabel, set_ylim, subplots, title, twinx\n",
    "import matplotlib.patches as patches  # for Rectangle\n",
    "import matplotlib.animation as an # for FuncAnimation\n",
    "\n",
    "from matplotlib import rc \n",
    "from IPython.display import HTML\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "import opensarlab_lib as asfn\n",
    "asfn.jupytertheme_matplotlib_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load Data Stack\n",
    "\n",
    "<img src=\"https://cdnuploads.aa.com.tr/uploads/Contents/2019/07/23/thumbs_b_c_c3d0986dd192f88d3a3289793ed4d3e6.jpg\" width=\"450\" style=\"padding:5px;\" align=\"right\" /> \n",
    "\n",
    "This notebook allows for the analysis of two recent flooding events: \n",
    "    \n",
    "1. **2020 South Asia Monsoon Floods:** If run without changes, the notebook will be using a Sentinel-1 data stack (VV only) acquired throughout a 2020 flooding event affecting Eastern India, Nepal, and Bangladesh. This data set studies a subset of a Sentinel-1 SAR time series acquired near the city of Malda, West Bengal, India. The time series covers June to August of 2020 and combines ascending and descending RTC imagery into a joint and consistent time series to monitoring this rapidly developing event. \n",
    "    \n",
    "1. **2016/2017 Flooding in Ecuador:** Alternatively, interested individuals can change the event flag in the code cell below to load a SAR data stack for an area north of Guayaquil, Ecuador into the notebook. Ecuador and other countries in western South America experienced widespread **flooding** during the 2016-2017 winter. [Guayaquil in Guayas](https://www.eluniverso.com/noticias/2017/03/01/nota/6068059/arboles-se-caen-medio-torrencial-lluvia-ayer) was among the affected regions, as precipitation in March 2017 was well above average. The increased precipitation was associated with a Coastal Niño event. The data provided allows to study the extent and progression of the flooding in the year 2016-2017 just north of Guayaquil. To analyze this event, please change the `flevent` from `flevent = 1` to `flevent = 2` in the code cell below.\n",
    "\n",
    "If you want, **you can change the data set to be analyzed</b> in the code cell below by changing the `flevent` flag from `flevent = 1` (2020 South Asia Monsoon Floods) to `flevent = 2` (2016/17 Ecuador Flooding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Pick Dataset to Analyze\n",
    "flevent = 1      # Options: 1 - 2020 Bangladesh & Eastern India Event   |    2 - Guayaquil flood of 2016-2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Before we get started, let's first **create a working directory for this analysis and change into it:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "name = \"Bangladesh\" if flevent == 1 else \"flood\"\n",
    "path = Path(f\"/home/jovyan/notebooks/SAR_Training/English/HydroSAR/{name}\")\n",
    "\n",
    "if not path.exists():\n",
    "    path.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will **retrieve the relevant data** from an [Amazon Web Service (AWS)](https://aws.amazon.com/) cloud storage bucket, **unzip the files** (overwriting previous extractions), and **clean up after ourselves:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_series_path = f\"s3://asf-jupyter-data-west/{name}.tar.gz\"\n",
    "time_series = Path(time_series_path).name\n",
    "!aws --region=us-west-2 --no-sign-request s3 cp $time_series_path $time_series\n",
    "!tar -xvzf {name}.tar.gz -C {path}\n",
    "\n",
    "if Path(f'{name}.tar.gz').exists():\n",
    "    Path(f'{name}.tar.gz').unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Define Data Directory and Path to VRT\n",
    "\n",
    "The following code cells **create a variable containing the VRT filename and the image acquisition dates.** To do that, we first **define some functions** we will use in the following code cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_dates(path):\n",
    "    pths = list(path.parent.rglob(path.name))\n",
    "    pths.sort()\n",
    "    dates = []\n",
    "    for pth in pths:\n",
    "        date = pth.name.split('T')[1].split('_')[1]\n",
    "        date = f\"{date[:4]}-{date[4:6]}-{date[6:]}\"\n",
    "        dates.append(date)\n",
    "    return dates\n",
    "\n",
    "def get_dates_sub(path):\n",
    "    pths = list(path.parent.rglob(path.name))\n",
    "    pths.sort()\n",
    "    dates = []\n",
    "    for pth in pths:\n",
    "        date = pth.name.split('_')[0]\n",
    "        date = f\"{date[:4]}-{date[4:6]}-{date[6:]}\"\n",
    "        dates.append(date)\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we **visualize the image acquision dates** to give you an idea of the time span that is covered by our data and of the temporal sampling the SAR sensor achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tiff_paths = path/f\"tiffsflood/*.tif*\"\n",
    "\n",
    "dates = get_dates_sub(tiff_paths) if flevent == 1 else get_dates(tiff_paths)\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Finally, we create a **Virtual Raster Table** or VRT, which will hold the paths to all images in our stack. VRTs are exceptionally useful to handle and manage deep stacks of image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "polarization = 'VV'\n",
    "if flevent == 1:\n",
    "    vrtcommand = f\"gdalbuildvrt -separate {path}/stack{name}_{polarization}.vrt {tiff_paths}\"\n",
    "    !{vrtcommand}\n",
    "image_file = path/f\"stack{name}_{polarization}.vrt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "## Data Exploration with an Animation\n",
    "\n",
    "To create an animation of all images in the time series stack, we first have to **read all image data** into memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img = gdal.Open(str(image_file))\n",
    "band = img.GetRasterBand(1)\n",
    "raster0 = band.ReadAsArray()\n",
    "band_number = 0 # Needed for updates\n",
    "rasterstack = img.ReadAsArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For visualization, we often **transform the data into a decibel (dB) space.** This is useful due to the enormous brightness difference between the darkest and brightest pixels in a SAR image. This high dynamic range is often difficult to visualize in a linear amplitude or power scale. A dB transformation compresses the dynamic range and improves the appearance of the images for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "use_dB = True\n",
    "\n",
    "def convert(raster, use_dB=use_dB):\n",
    "    # some Python trickery: \n",
    "    # if you call the convert function later, you can set the keyword \n",
    "    # argument use_dB to True or False\n",
    "    # if you do not provide a keyword argument, the value that you set\n",
    "    # above (when defining the function) is used\n",
    "    if use_dB:\n",
    "        return 10 * np.log10(raster)\n",
    "    else:\n",
    "        return raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's create an **animation** to get an idea of where and when flooding might have occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "figani = plt.figure(figsize=(12, 7))\n",
    "axani = figani.subplots()\n",
    "axani.axis('off')\n",
    "\n",
    "rasterstack_ = convert(rasterstack)\n",
    "\n",
    "mask = np.isnan(rasterstack_)\n",
    "rasterstack_[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), rasterstack_[~mask])\n",
    "\n",
    "imani = axani.imshow(rasterstack_[0,...], cmap='gray', vmin=np.nanpercentile(rasterstack_, 1), \n",
    "               vmax=np.nanpercentile(rasterstack_, 99))\n",
    "axani.set_title(f\"{dates}\")\n",
    "\n",
    "def animate(i):\n",
    "    axani.set_title(dates[i])\n",
    "    imani.set_data(rasterstack_[i,...])\n",
    "\n",
    "# Interval is given in milliseconds\n",
    "ani = an.FuncAnimation(figani, animate, frames=rasterstack_.shape[0], interval=300)\n",
    "rc('animation', embed_limit=40971520.0)  # We need to increase the limit maybe to show the entire animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Render**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>EXERCISE</u>:  </font> Backscatter dynamics</b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> What is the most striking change in February 2017? Can you explain why the backscatter changes the way it does during that period?\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create Minimum Image to Identify Inundated Areas\n",
    "\n",
    "As flooding is often associated with very low backscater, we first compute the minimum backscatter for each pixel to get a first impression of areas that could have been flooded during the entire period.\n",
    "\n",
    "The following line **calculates the minimum backscatter per pixel** across the time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.seterr(divide='ignore')\n",
    "np.seterr(invalid='ignore')\n",
    "rasterstack_masked = np.ma.masked_where(rasterstack==0, rasterstack)\n",
    "temporal_min = np.nanmin(convert(rasterstack_masked), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we **write a class to create an interactive plot** from which we can select interesting image locations for time series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class pixelPicker:\n",
    "    def __init__(self, image, width, height):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.fig = plt.figure(figsize=(width, height))\n",
    "        self.ax = self.fig.add_subplot(111, visible=False)\n",
    "        self.rect = patches.Rectangle(\n",
    "            (0.0, 0.0), width, height, \n",
    "            fill=False, clip_on=False, visible=False)\n",
    "        self.rect_patch = self.ax.add_patch(self.rect)\n",
    "        self.cid = self.rect_patch.figure.canvas.mpl_connect('button_press_event', \n",
    "                                                             self)\n",
    "        self.image = image\n",
    "        self.plot = self.gray_plot(self.image, fig=self.fig, return_ax=True)\n",
    "        self.plot.set_title('Select a Point of Interest')\n",
    "        \n",
    "        \n",
    "    def gray_plot(self, image, vmin=None, vmax=None, fig=None, return_ax=False):\n",
    "        '''\n",
    "        Plots an image in grayscale.\n",
    "        Parameters:\n",
    "        - image: 2D array of raster values\n",
    "        - vmin: Minimum value for colormap\n",
    "        - vmax: Maximum value for colormap\n",
    "        - return_ax: Option to return plot axis\n",
    "        '''\n",
    "        if vmin is None:\n",
    "            vmin = np.nanpercentile(self.image, 1)\n",
    "        if vmax is None:\n",
    "            vmax = np.nanpercentile(self.image, 99)\n",
    "        ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "        ax.imshow(image, cmap=plt.cm.gist_gray, vmin=vmin, vmax=vmax)\n",
    "        if return_ax:\n",
    "            return(ax)\n",
    "        \n",
    "    \n",
    "    def __call__(self, event):\n",
    "        print('click', event)\n",
    "        self.x = event.xdata\n",
    "        self.y = event.ydata\n",
    "        for pnt in self.plot.get_lines():\n",
    "            pnt.remove()\n",
    "        plt.plot(self.x, self.y, 'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we are ready to plot the minimum image. \n",
    "\n",
    "**Click a point interest for which you want to analyze radar brightness over time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig_xsize = 7.5\n",
    "fig_ysize = 7.5\n",
    "my_plot = pixelPicker(temporal_min.data, fig_xsize, fig_ysize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Save the selected coordinates:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sarloc = (ceil(my_plot.x), ceil(my_plot.y))\n",
    "print(sarloc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plot SAR Brightness Time Series at Point Locations\n",
    "\n",
    "We will pick a pixel location identified in the SAR image above and plot the time series for this identified point. By focusing on image locations undergoing deforestation, we should see the changes in the radar cross section related to the deforestation event.\n",
    "\n",
    "First, for processing of the imagery in this notebook we generate a list of image handles and retrieve projection and georeferencing information. We also define a function for mapping image pixels to a geographic projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img_handle = gdal.Open(str(image_file))\n",
    "geotrans = img_handle.GetGeoTransform()\n",
    "proj = img_handle.GetProjection()\n",
    "xsize = img_handle.RasterXSize\n",
    "ysize = img_handle.RasterYSize\n",
    "bands = img_handle.RasterCount\n",
    "projlatlon = pyproj.Proj('EPSG:4326') # WGS84\n",
    "projstring = proj.split('[')[-1][:-2].split(',')[-1][1:-1]\n",
    "projimg = pyproj.Proj(f'EPSG:{projstring}')\n",
    "\n",
    "def geolocation(x, y=None, latlon=True):\n",
    "    if len(x) == 2:\n",
    "        y = x[1]\n",
    "        x = x[0]\n",
    "    ref_x=geotrans[0]+sarloc[0]*geotrans[1]\n",
    "    ref_y=geotrans[3]+sarloc[1]*geotrans[5]\n",
    "    if latlon:\n",
    "        proj = pyproj.Transformer.from_crs(int(projstring), 4326, always_xy=True)\n",
    "        ref_y, ref_x = proj.transform(ref_x, ref_y)\n",
    "        #ref_y, ref_x = pyproj.transform(projimg, projlatlon, ref_x, ref_y)\n",
    "    return (ref_x, ref_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now, let's **pick a rectangle around a center pixel defined in variable *sarloc...***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "extent = (5, 5) # choose a 5 by 5 rectangle\n",
    "latlon = True # if False: return utm coordinates\n",
    "\n",
    "refsarloc = geolocation(sarloc, latlon=latlon)\n",
    "projsymbol = '°' if latlon else 'm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "... and **extract the time series** for this small area around the selected center pixel in a memory-efficient way (needed for larger stacks):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 9})\n",
    "bs_aggregated = []\n",
    "for band in range(bands):\n",
    "    rs = img_handle.GetRasterBand(band+1).ReadAsArray(sarloc[0], sarloc[1], extent[0], extent[1])\n",
    "    rs_mean = convert(np.nanmean(rs))\n",
    "    bs_aggregated.append(rs_mean)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9, 5))\n",
    "labeldB = 'dB' if use_dB else 'linear'\n",
    "ax.plot(dates, bs_aggregated, color='k', marker='o', markersize=3)\n",
    "plt.ylim((-28, 6))\n",
    "ax.set_xlabel('Date')\n",
    "plt.xticks(rotation=90)\n",
    "plt.gcf().subplots_adjust(bottom=0.25)\n",
    "ax.set_ylabel(f'Sentinel-1 $\\gamma^0$ [{labeldB}]')\n",
    "\n",
    "plt.grid()\n",
    "_ = fig.suptitle(f'Location: {refsarloc[0]:.3f}{projsymbol} {refsarloc[1]:.3f}{projsymbol}')\n",
    "# fig.tight_layout() \n",
    "figname = \"RCSTimeSeries-\" + f'{refsarloc[0]:.3f}{projsymbol} {refsarloc[1]:.3f}{projsymbol}' + '.png'\n",
    "plt.savefig(path/figname, dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>EXERCISE</u>:  </font> Explore Time Series at Different Point Locations </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Can you interpret and attribute the changes at various locations? Apart from the flooding, what other patterns do you observe?\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "**Version Log**\n",
    "\n",
    "*Lab1-ExploreSARTimeSeries.ipynb - Version 1.7.1 - November 2021*\n",
    "\n",
    "*Version Changes*\n",
    "\n",
    "- *`os` modules and obsolete `asfn` methods replaced with `pathlib` counterparts*\n",
    "- *Removed several redundancies in regards to flevent*\n",
    "- *html -> markdown*\n",
    "- *url_widget*\n",
    "- *asf_notebook -> opensarlab_lib*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtc_analysis",
   "language": "python",
   "name": "conda-env-.local-rtc_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
