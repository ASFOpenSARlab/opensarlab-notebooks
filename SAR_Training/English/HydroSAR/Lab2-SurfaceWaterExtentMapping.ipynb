{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![HydroSAR Banner](./NotebookAddOns/HydroSARbanner.jpg)\n",
    "\n",
    "# Flood Mapping from Single Sentinel-1 SAR Images\n",
    "\n",
    "**Franz J Meyer, University of Alaska Fairbanks**\n",
    "\n",
    "This notebook presents the SAR-based flood mapping approach developed and used in the HydroSAR project. In its general concepts, the approach follows a methodology developed by the German Aerospace Center and published in [Sentinel-1-based flood mapping: a fully automated processing chain](https://www.tandfonline.com/doi/full/10.1080/01431161.2016.1192304) by Twele et al. The approach is based on radiometrically terrain corrected (RTC processed) Sentinel-1 SAR data and applies a dynamic thresholding method followed by fuzzy-logic-based post processing procedure. This notebook has both steps of this process implemented, but by default, the fuzzy logic step is deactivated to save processing time. The notebook will explain how the fuzzy logic post processing step can be activated should full performance processing be of interest. \n",
    "\n",
    "The approach is based on image amplitude data and is capable of detecting standing surface water. Note that flooding under vegetation will not be detected by this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import url_widget as url_w\n",
    "notebookUrl = url_w.URLWidget()\n",
    "display(notebookUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "\n",
    "notebookUrl = notebookUrl.value\n",
    "user = !echo $JUPYTERHUB_USER\n",
    "env = !echo $CONDA_PREFIX\n",
    "if env[0] == '':\n",
    "    env[0] = 'Python 3 (base)'\n",
    "if env[0] != '/home/jovyan/.local/envs/hydrosar':\n",
    "    display(Markdown(f'<text style=color:red><strong>WARNING:</strong></text>'))\n",
    "    display(Markdown(f'<text style=color:red>This notebook should be run using the \"hydrosar\" conda environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>It is currently using the \"{env[0].split(\"/\")[-1]}\" environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Select \"hydrosar\" from the \"Change Kernel\" submenu of the \"Kernel\" menu.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>If the \"hydrosar\" environment is not present, use <a href=\"{notebookUrl.split(\"/user\")[0]}/user/{user[0]}/notebooks/conda_environments/Create_OSL_Conda_Environments.ipynb\"> Create_OSL_Conda_Environments.ipynb </a> to create it.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Note that you must restart your server after creating a new environment before it is usable by notebooks.</text>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Methodology and Workflow\n",
    "\n",
    "The workflow of the Sentinel-1-based processing chain, as outlined in the figure below, is composed of the following main elements: \n",
    "\n",
    "1. **Find relevant SAR data** over your area of interest at the [Alaska Satellite Facility's SAR archive](https://search.asf.alaska.edu/#/)\n",
    "1. **Perform geometric and radiometric terrain correction** using the RTC processing flow by [GAMMA Remote Sensing](https://www.gamma-rs.ch/)\n",
    "1. **initial flood detection** using automatic thresholding\n",
    "1. **fuzzy-logic-based classification refinement**\n",
    "1. **>final classification into permanent and flood waters** using auxiliary data\n",
    "1. **dissemination of the results**\n",
    "\n",
    "***Steps 1 and 2*** of this workflow are operationally implemented in the Alaska Satellite Facility's Hybrid Pluggable Processing Pipeline (HyP3) environment and accessible to the public at the [ASF Search (Vertex)](https://search.asf.alaska.edu/#/).\n",
    "\n",
    "<img style= \"padding: 7px\" src=\"https://courses.edx.org/asset-v1:AlaskaX+SAR-401+3T2020+type@asset+block@Watermappingworkflow2.jpg\" width=\"70%\"/>\n",
    "\n",
    "# Flood Mapping Procedure\n",
    "\n",
    "## Loading Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from pathlib import Path\n",
    "from os import system\n",
    "from typing import Tuple\n",
    "import json\n",
    "from shutil import rmtree\n",
    "\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "gdal.UseExceptions()\n",
    "from osgeo import osr\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import pyproj\n",
    "import skfuzzy\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt # for add_subplot, axis, figure, imshow, legend, plot, set_axis_off, set_data,\n",
    "                               # set_title, set_xlabel, set_ylabel, set_ylim, subplots, title, twinx\n",
    "\n",
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "import opensarlab_lib as asfn\n",
    "asfn.jupytertheme_matplotlib_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"How would you like to handle previously downloaded example data?\")\n",
    "delete = asfn.select_parameter([\"Delete old example data\", \"Save old example data\"], '')\n",
    "display(delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Delete' in delete.value:\n",
    "    if Path(f\"/home/jovyan/notebooks/SAR_Training/English/HydroSAR/BangladeshFloodMapping\").exists():\n",
    "        rmtree(Path(f\"/home/jovyan/notebooks/SAR_Training/English/HydroSAR/BangladeshFloodMapping\"))\n",
    "    if Path(f\"/home/jovyan/notebooks/SAR_Training/English/HydroSAR/TSAmandaElSalvador\").exists():\n",
    "        rmtree(Path(f\"/home/jovyan/notebooks/SAR_Training/English/HydroSAR/TSAmandaElSalvador\"))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Write Some Helper Scripts\n",
    "\n",
    "Write a function to pad an image, so it may be split into tiles with consistent dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def pad_image(image: np.ndarray, to: int) -> np.ndarray:\n",
    "    height, width = image.shape\n",
    "\n",
    "    n_rows, n_cols = get_tile_row_col_count(height, width, to)\n",
    "    new_height = n_rows * to\n",
    "    new_width = n_cols * to\n",
    "\n",
    "    padded = np.zeros((new_height, new_width))\n",
    "    padded[:image.shape[0], :image.shape[1]] = image\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Write a function to tile an image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#def tile_image(image: np.ndarray, width: int = 200, height: int = 200) -> np.ndarray:\n",
    "def tile_image(image: np.ndarray, width, height) -> np.ndarray:\n",
    "    _nrows, _ncols = image.shape\n",
    "    _strides = image.strides\n",
    "\n",
    "    nrows, _m = divmod(_nrows, height)\n",
    "    ncols, _n = divmod(_ncols, width)\n",
    "\n",
    "    assert _m == 0, \"Image must be evenly tileable. Please pad it first\"\n",
    "    assert _n == 0, \"Image must be evenly tileable. Please pad it first\"\n",
    "\n",
    "    return np.lib.stride_tricks.as_strided(\n",
    "        np.ravel(image),\n",
    "        shape=(nrows, ncols, height, width),\n",
    "        strides=(height * _strides[0], width * _strides[1], *_strides),\n",
    "        writeable=False\n",
    "    ).reshape(nrows * ncols, height, width)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Write a function for Kittler-Illingworth Thresholding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def Kittler(im):\n",
    "    \"\"\"\n",
    "    The reimplementation of Kittler-Illingworth Thresholding algorithm by Bob Pepin\n",
    "    Works on 8-bit images only\n",
    "    Original Matlab code: https://www.mathworks.com/matlabcentral/fileexchange/45685-kittler-illingworth-thresholding\n",
    "    Paper: Kittler, J. & Illingworth, J. Minimum error thresholding. Pattern Recognit. 19, 41â€“47 (1986).\n",
    "    \"\"\"\n",
    "    test = im.ravel()\n",
    "    tindex = np.nonzero(test>0)\n",
    "    h,g = np.histogram(test[tindex],256,[0,256])\n",
    "    h = h.astype(np.float)\n",
    "    g = g.astype(np.float)\n",
    "    g = g[:-1]\n",
    "    c = np.cumsum(h)\n",
    "    m = np.cumsum(h * g)\n",
    "    s = np.cumsum(h * g**2)\n",
    "    sigma_f = np.sqrt(s/c - (m/c)**2)\n",
    "    cb = c[-1] - c\n",
    "    mb = m[-1] - m\n",
    "    sb = s[-1] - s\n",
    "    sigma_b = np.sqrt(sb/cb - (mb/cb)**2)\n",
    "    p =  c / c[-1]\n",
    "    v = p * np.log10(sigma_f) + (1-p)*np.log10(sigma_b) - p*np.log10(p) - (1-p)*np.log10(1-p)\n",
    "    v[~np.isfinite(v)] = np.inf\n",
    "    idx = np.argmin(v)\n",
    "    t = g[idx]\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Write a function for multi-class Expectation Maximization Thresholding to replace Kittler-Illingworth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def EMSeg_opt(image, number_of_classes):\n",
    "    image_copy = image.copy()\n",
    "    image_copy2 = np.ma.filled(image.astype(float), np.nan) # needed for valid posterior_lookup keys\n",
    "    image = image.flatten()\n",
    "    minimum = np.amin(image)\n",
    "    image = image - minimum + 1\n",
    "    maximum = np.amax(image)\n",
    "\n",
    "    size = image.size\n",
    "    histogram = make_histogram(image)\n",
    "    nonzero_indices = np.nonzero(histogram)[0]\n",
    "    histogram = histogram[nonzero_indices]\n",
    "    histogram = histogram.flatten()\n",
    "    class_means = (\n",
    "            (np.arange(number_of_classes) + 1) * maximum /\n",
    "            (number_of_classes + 1)\n",
    "    )\n",
    "    class_variances = np.ones((number_of_classes)) * maximum\n",
    "    class_proportions = np.ones((number_of_classes)) * 1 / number_of_classes\n",
    "    sml = np.mean(np.diff(nonzero_indices)) / 1000\n",
    "    iteration = 0\n",
    "    while(True):\n",
    "        class_likelihood = make_distribution(\n",
    "            class_means, class_variances, class_proportions, nonzero_indices\n",
    "        )\n",
    "        sum_likelihood = np.sum(class_likelihood, 1) + np.finfo(\n",
    "                class_likelihood[0][0]).eps\n",
    "        log_likelihood = np.sum(histogram * np.log(sum_likelihood))\n",
    "        for j in range(0, number_of_classes):\n",
    "            class_posterior_probability = (\n",
    "                histogram * class_likelihood[:,j] / sum_likelihood\n",
    "            )\n",
    "            class_proportions[j] = np.sum(class_posterior_probability)\n",
    "            class_means[j] = (\n",
    "                np.sum(nonzero_indices * class_posterior_probability)\n",
    "                    / class_proportions[j]\n",
    "            )\n",
    "            vr = (nonzero_indices - class_means[j])\n",
    "            class_variances[j] = (\n",
    "                np.sum(vr *vr * class_posterior_probability)\n",
    "                    / class_proportions[j] +sml\n",
    "            )\n",
    "            del class_posterior_probability, vr\n",
    "        class_proportions = class_proportions + 1e-3\n",
    "        class_proportions = class_proportions / np.sum(class_proportions)\n",
    "        class_likelihood = make_distribution(\n",
    "            class_means, class_variances, class_proportions, nonzero_indices\n",
    "        )\n",
    "        sum_likelihood = np.sum(class_likelihood, 1) + np.finfo(\n",
    "                class_likelihood[0,0]).eps\n",
    "        del class_likelihood\n",
    "        new_log_likelihood = np.sum(histogram * np.log(sum_likelihood))\n",
    "        del sum_likelihood\n",
    "        if((new_log_likelihood - log_likelihood) < 0.000001):\n",
    "            break\n",
    "        iteration = iteration + 1\n",
    "    del log_likelihood, new_log_likelihood\n",
    "    class_means = class_means + minimum - 1\n",
    "    s = image_copy.shape\n",
    "    posterior = np.zeros((s[0], s[1], number_of_classes))\n",
    "    posterior_lookup = dict()\n",
    "    for i in range(0, s[0]):\n",
    "        for j in range(0, s[1]):\n",
    "            pixel_val = image_copy2[i,j] \n",
    "            if pixel_val in posterior_lookup:\n",
    "                for n in range(0, number_of_classes): \n",
    "                    posterior[i,j,n] = posterior_lookup[pixel_val][n]\n",
    "            else:\n",
    "                posterior_lookup.update({pixel_val: [0]*number_of_classes})\n",
    "                for n in range(0, number_of_classes): \n",
    "                    x = make_distribution(\n",
    "                        class_means[n], class_variances[n], class_proportions[n],\n",
    "                        image_copy[i,j]\n",
    "                    )\n",
    "                    posterior[i,j,n] = x * class_proportions[n]\n",
    "                    posterior_lookup[pixel_val][n] = posterior[i,j,n]\n",
    "    return posterior, class_means, class_variances, class_proportions\n",
    "\n",
    "def make_histogram(image):\n",
    "    image = image.flatten()\n",
    "    indices = np.nonzero(np.isnan(image))\n",
    "    image[indices] = 0\n",
    "    indices = np.nonzero(np.isinf(image))\n",
    "    image[indices] = 0\n",
    "    del indices\n",
    "    size = image.size\n",
    "    maximum = int(np.ceil(np.amax(image)) + 1)\n",
    "    #maximum = (np.ceil(np.amax(image)) + 1)\n",
    "    histogram = np.zeros((1, maximum))\n",
    "    for i in range(0,size):\n",
    "        #floor_value = int(np.floor(image[i]))\n",
    "        floor_value = np.floor(image[i]).astype(np.uint8)\n",
    "        #floor_value = (np.floor(image[i]))\n",
    "        if floor_value > 0 and floor_value < maximum - 1:\n",
    "            temp1 = image[i] - floor_value\n",
    "            temp2 = 1 - temp1\n",
    "            histogram[0,floor_value] = histogram[0,floor_value] + temp1\n",
    "            histogram[0,floor_value - 1] = histogram[0,floor_value - 1] + temp2\n",
    "    histogram = np.convolve(histogram[0], [1,2,3,2,1])\n",
    "    histogram = histogram[2:(histogram.size - 3)]\n",
    "    histogram = histogram / np.sum(histogram)\n",
    "    return histogram\n",
    "\n",
    "def make_distribution(m, v, g, x):\n",
    "    x = x.flatten()\n",
    "    m = m.flatten()\n",
    "    v = v.flatten()\n",
    "    g = g.flatten()\n",
    "    y = np.zeros((len(x), m.shape[0]))\n",
    "    for i in range(0,m.shape[0]):\n",
    "        d = x - m[i]\n",
    "        amp = g[i] / np.sqrt(2*np.pi*v[i])\n",
    "        y[:,i] = amp * np.exp(-0.5 * (d * d) / v[i])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Write a function to calculate the number of rows and columns of tiles needed to tile an image to a given size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_tile_row_col_count(height: int, width: int, tile_size: int) -> Tuple[int, int]:\n",
    "    return int(np.ceil(height / tile_size)), int(np.ceil(width / tile_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Write a function to extract the tiff dates from a wildcard path:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_dates(paths):\n",
    "    dates = []\n",
    "    pths = list(paths.parent.rglob(paths.name))\n",
    "    \n",
    "    for p in pths:\n",
    "        date = str(p).split('/')[-1].split(\"_\")[0]\n",
    "        dates.append(date)\n",
    "    dates.sort()\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Write a function to save a mask**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def write_mask_to_file(mask: np.ndarray, file_name: str, projection: str, geo_transform: str) -> None:\n",
    "    (width, height) = mask.shape\n",
    "    out_image = gdal.GetDriverByName('GTiff').Create(\n",
    "        file_name, height, width, bands=1\n",
    "    )\n",
    "    out_image.SetProjection(projection)\n",
    "    out_image.SetGeoTransform(geo_transform)\n",
    "    out_image.GetRasterBand(1).WriteArray(mask)\n",
    "    out_image.GetRasterBand(1).SetNoDataValue(0)\n",
    "    out_image.FlushCache()\n",
    "    \n",
    "    \n",
    "def gdal_write(ary, geoTransform, fileformat=\"GTiff\", filename='jupyter_rocks.tif', format=gdal.GDT_Float64, nodata=None, srs_proj4='+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs'):\n",
    "    '''gdal_write(ary, geoTransform, format=\"GTiff\", filename='jupyter_rocks.tif', format=gdal.GDT_Float64 nodata=None, srs_proj4='+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs')\n",
    "    ary: 2D array.\n",
    "    geoTransform: [top left x, w-e pixel resolution, rotation, top left y, rotation, n-s pixel resolution]\n",
    "    format: \"GTiff\"     \n",
    "    '''           \n",
    "    if ary.ndim == 2:\n",
    "        Ny, Nx = ary.shape\n",
    "        Nb = 1;\n",
    "    elif ary.ndim == 3:\n",
    "        Ny, Nx, Nb = ary.shape\n",
    "    else: \n",
    "        print(\"Input array has to be 2D or 3D.\")\n",
    "        return None\n",
    "    \n",
    "    driver = gdal.GetDriverByName(fileformat)\n",
    "    ds = driver.Create(filename, Nx, Ny, Nb, gdal.GDT_Float64)\n",
    "\n",
    "    #ds.SetGeoTransform( ... ) # define GeoTransform tuple\n",
    "    # top left x, w-e pixel resolution, rotation, top left y, rotation, n-s pixel resolution\n",
    "    ds.SetGeoTransform(geoTransform)    \n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromProj4(srs_proj4)\n",
    "    ds.SetProjection(srs.ExportToWkt())\n",
    "    if nodata is not None:\n",
    "        ds.GetRasterBand(1).SetNoDataValue(0)\n",
    "    if Nb == 1:\n",
    "        ds.GetRasterBand(1).WriteArray(ary)\n",
    "    else:\n",
    "        for b in range(Nb):\n",
    "            ds.GetRasterBand(b+1).WriteArray(ary[:,:,b])\n",
    "    ds = None\n",
    "\n",
    "    \n",
    "def get_proj4(filename):\n",
    "    f = rasterio.open(filename)\n",
    "    return pyproj.Proj(f.crs, preserve_units=True)  #used in pysheds\n",
    "    \n",
    "    \n",
    "def gdal_read(filename, ndtype=np.float64):\n",
    "    '''\n",
    "    z=readData('/path/to/file')\n",
    "    '''\n",
    "    filename = str(filename)\n",
    "    ds = gdal.Open(filename) \n",
    "    return np.array(ds.GetRasterBand(1).ReadAsArray()).astype(ndtype);\n",
    "\n",
    "\n",
    "def gdal_get_geotransform(filename):\n",
    "    '''\n",
    "    [top left x, w-e pixel resolution, rotation, top left y, rotation, n-s pixel resolution]=gdal_get_geotransform('/path/to/file')\n",
    "    '''\n",
    "    filename = str(filename)\n",
    "    #http://stackoverflow.com/questions/2922532/obtain-latitude-and-longitude-from-a-geotiff-file\n",
    "    ds = gdal.Open(filename)\n",
    "    return ds.GetGeoTransform()\n",
    "\n",
    "\n",
    "def fill_nan(arr):\n",
    "    \"\"\"\n",
    "    filled_arr=fill_nan(arr)\n",
    "    Fills Not-a-number values in arr using astropy. \n",
    "    \"\"\"    \n",
    "    kernel = astropy.convolution.Gaussian2DKernel(x_stddev=3) #kernel x_size=8*stddev\n",
    "    arr_type = arr.dtype          \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        while np.any(np.isnan(arr)):\n",
    "            arr = astropy.convolution.interpolate_replace_nans(arr.astype(float), kernel, convolve=astropy.convolution.convolve)\n",
    "    return arr.astype(arr_type) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load SAR Data Sets to Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_tiff_paths(paths: str) -> list:\n",
    "    tiff_paths = !ls $paths | sort -t_ -k5,5\n",
    "    return tiff_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Reading a SAR Data Stack:**\n",
    "\n",
    "There are two data sets available for this notebook: Option `fleven = 1` is a flood mapping example for Eastern India and shows flood extents during the summer 2020 period. Option `flevent = 2` is a data set over El Salvador, acquired as Tropical Storm Amanda passed over the country. While damages occurred in the area. Not much evidence of the storm can be extracted from the data. This may be related to the limited spatial extent of local flooding events or due to the heavy vegation of the country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Pick Dataset to Analyze\n",
    "flevent = 3     # Options: 1 - 2020 Bangladesh & Eastern India Event   |   2 - Guayaquil flood of 2016-2017\n",
    "#                          3 - Honduras 2020 Flooding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if flevent == 1:\n",
    "    name = \"BangladeshFloodMapping\"\n",
    "elif flevent == 2:\n",
    "    name = \"TSAmandaElSalvador\"\n",
    "else:\n",
    "    name = \"HondurasFloodSubset\"\n",
    "\n",
    "tiff_dir = path = Path.cwd()/name\n",
    "if not tiff_dir.exists():\n",
    "    tiff_dir.mkdir()\n",
    "    \n",
    "time_series_path = f\"s3://asf-jupyter-data-west/{name}.tar.gz\"\n",
    "if flevent == 3:\n",
    "    time_series_path = f\"s3://asf-jupyter-data-west/{name}.zip\"\n",
    "time_series = Path(time_series_path).name\n",
    "!aws --region=us-west-2 --no-sign-request s3 cp $time_series_path $time_series\n",
    "\n",
    "if flevent ==3:\n",
    "    !unzip {name}.zip\n",
    "    !rm *.zip\n",
    "else:\n",
    "    !tar -xvzf {name}.tar.gz -C {path}\n",
    "    !rm *.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Create a directory in which to store the water masks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mask_directory = tiff_dir/'Water_Masks'\n",
    "\n",
    "if not mask_directory.exists():\n",
    "    mask_directory.mkdir()\n",
    "    \n",
    "paths = tiff_dir/\"*_V*.tif*\"\n",
    "if tiff_dir.exists():\n",
    "    tiff_paths = get_tiff_paths(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SARDualPolError(Exception):\n",
    "    \"\"\"\n",
    "    Raise when expecting dual-pol SAR data\n",
    "    but single-pol found instead\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "vv_wild = tiff_dir/'*_VV.tif*'\n",
    "vh_wild = tiff_dir/'*_VH.tif*'\n",
    "\n",
    "if tiff_dir.exists():\n",
    "    vh_paths = get_tiff_paths(vh_wild)\n",
    "    vv_paths = get_tiff_paths(vv_wild)\n",
    "\n",
    "for i, pth in enumerate(vv_paths):\n",
    "    vh = f\"{pth.split('_V')[0]}_VH{Path(pth).suffix}\"\n",
    "    if vh not in vh_paths:\n",
    "        raise SARDualPolError(f\"Found {pth} but not {vh}\")        \n",
    "for i, pth in enumerate(vh_paths):\n",
    "    vv = f\"{pth.split('_V')[0]}_VV{Path(pth).suffix}\"\n",
    "    if vv not in vv_paths:\n",
    "        raise SARDualPolError(f\"Found {pth} but not {vv}\")\n",
    "        \n",
    "print(f\"Success: dual-pol data found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Write a function to create a dictionary containing lists of each vv/vh pair**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def group_polarizations(tiff_paths: list) -> dict:\n",
    "    pths = {}\n",
    "    for tiff in tiff_paths:\n",
    "        product_name = tiff.split('.')[0][:-2]\n",
    "        if product_name in pths:\n",
    "            pths[product_name].append(tiff)\n",
    "        else:\n",
    "            pths.update({product_name: [tiff]})\n",
    "            pths[product_name].sort()\n",
    "    return pths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Write a function to confirm the presence of both VV and VH images in all image sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def confirm_dual_polarizations(paths: dict) -> bool:\n",
    "    for p in paths:\n",
    "        if len(paths[p]) == 2:\n",
    "            if ('vv' not in paths[p][1] and 'VV' not in paths[p][1]) or \\\n",
    "            ('vh' not in paths[p][0] and 'VH' not in paths[p][0]):\n",
    "                return False\n",
    "    return True   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Create a dictionary of VV/VH pairs and check it for completeness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grouped_pths = group_polarizations(tiff_paths)\n",
    "if not confirm_dual_polarizations(grouped_pths):\n",
    "    print(\"ERROR: AI_Water requires both VV and VH polarizations.\")\n",
    "else:\n",
    "    print(\"Confirmed presence of VV and VH polarities for each product.\")\n",
    "    \n",
    "#print(grouped_pths) #uncomment to print VV/VH path pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Load HAND Layer for your AOI and Create HAND-Exclusion Mask (HAND-EM)\n",
    "\n",
    "**Note:** This notebook expects the HAND layer to be of the same extent, resolution, and projection as the SAR image stack. This can easily be fixed in future versions of the notebook. The HAND layer you will be using meets all of these requirements.\n",
    "\n",
    "**Please pick the file `Bangladesh_Training_DEM_hand.tif` or `AmandaDEM_hand.tif` using the path selector in the code cell below!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"Choose your HAND layer:\")\n",
    "f = FileChooser(Path.cwd())\n",
    "display(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NoHANDLayerException(Exception):\n",
    "    \"\"\"\n",
    "    Raised when expecting path to HAND layer but none found\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "#load HAND and derive HAND-EM\n",
    "Hthresh = 15\n",
    "\n",
    "HAND_file = Path(f.selected)\n",
    "print(f\"Selected HAND: {HAND_file}\")\n",
    "try:\n",
    "    HAND_gT = gdal_get_geotransform(HAND_file)\n",
    "except AttributeError:\n",
    "    raise NoHANDLayerException(\"You must select a HAND layer in the previous code cell\")\n",
    "HAND_proj4 = get_proj4(HAND_file)\n",
    "info = (gdal.Info(str(HAND_file), format='json'))\n",
    "info = info['coordinateSystem']['wkt']\n",
    "Hzone = info.split('ID')[-1].split(',')[1][0:-2]\n",
    "Hproj_type = info.split('ID')[-1].split('\"')[1]\n",
    "HAND=gdal_read(HAND_file)\n",
    "hand = np.nan_to_num(HAND)\n",
    "\n",
    "# Create Binary HAND-EM\n",
    "Hmask = hand < Hthresh\n",
    "handem = np.zeros_like(hand)\n",
    "sel = np.ones_like(hand)\n",
    "handem[Hmask] = sel[Hmask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 5))\n",
    "plt.suptitle('Height Above Nearest Drainage [HAND] (m)')\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "vmin = np.percentile(hand, 5)\n",
    "vmax = np.percentile(hand, 95)\n",
    "hh = ax1.imshow(hand, cmap='jet', vmin=vmin, vmax=vmax)\n",
    "ax1.set_title('HAND [m]')\n",
    "ax1.grid()\n",
    "fig.colorbar(hh,ax=ax1)\n",
    "ax2.imshow(handem, cmap='gray')\n",
    "ax2.set_title('HAND-EM')\n",
    "ax2.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Do Initial Flood Mapping using Adaptive Dynamic Thresholding\n",
    "\n",
    "**A bit of background on the approach:**\n",
    "\n",
    "An automatic tile-based thresholding procedure (Martinis, Twele, and Voigt 2009) is used to generate an initial land/water classification. The selection of tiles is performed on a bilevel quadtree structure with parent level $L^+$ and child level $L^âˆ’$:\n",
    "    \n",
    "1. Firstly, the entire image is separated into quadratic non-overlapping parent tiles on level $L^+$ with a size of $100 \\times 100$ pixels. Each parent object is further represented by four quadratic child objects on a second level $L^âˆ’$. The tile selection process is based on statistical hierarchical relations between parent and child objects. \n",
    "2. A number of parent tiles is automatically selected that offer the highest (>95% quantile) coefficient of variation $\\frac{\\sigma}{\\mu}$ on $L^+$ of the mean backscatter values of the respective child objects on $L^âˆ’$. This criterion serves as a measure of the degree of variation within a tile and can therefore be used as an indicator of the probability that a tile is characterized by spatial inhomogeneity and contain more than one semantic class. The selected parent objects should also have a mean individual backscatter value lower than the mean of all parent tiles on $L^+$. This ensures that tiles lying on the boundary between water and no water areas are selected. In case that no tiles fulfil these criteria, the tile size on $L^+$ and $L^âˆ’$ is halved and the quantile for the tile selection is reduced to 90% to guarantee a successful tile selection also in data with a relatively low extent of water surfaces or with smaller dispersed water bodies. \n",
    "3. To improve the robustness of the automatic threshold derivation we restrict the tile selection in Step (3) to only pixels situated in flood-prone regions as defined by a HAND-based binary Exclustion Mask (HAND-EM). To create the HAND-EM layer, a threshold is applied to a Height Above Nearest Drainage(HAND) data set to identify non-flood prone areas. A threshold value of $\\geq 15m$ is used. The HAND-EM further is shrunk by one pixel using an 8-neighbour function to account for potential geometric inaccuracies between the exclude layer and SAR data. Tiles are only considered in case less than 20% of its data pixels are excluded by HAND-EM. \n",
    "4. Out of the number of the initially selected tiles, a limited number of $N$ parent tiles are finally chosen for threshold computation. This selection is accomplished by ranking the parent tiles according to the standard deviation of the mean backscatter values of the respective child objects. Tiles with the highest values are chosen. Extensive testing yielded that $N = 5$ is a sufficient number of parent tiles for threshold computation. \n",
    "5. A multi-mode Expectation Maximization thresholding approach is then employed to derive local threshold values using a cost function which is based on the statistical parameterization of the sub-histograms of all selected tiles. In order to derive a global (i.e. scenebased) threshold, the locally derived thresholds are combined by computing their arithmetic mean.\n",
    "6. Using the dynamically calculated threshold, both the VV and VH scenes are thresholded for creating an initial surface water extent map.\n",
    "7. The surface water extent maps derived from the VV and VH channel are combined to arrive at a combined intial surface water extent mask that is further refined in a post processing (Section 2.6).\n",
    "\n",
    "**Now Let's do the Work:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define some variables you might want to change\n",
    "precentile = 0.95        # Standard deviation percentile threshold for pivotal tile selection\n",
    "tilesize = 100           # Setting tile size to use in thresholding algorithm\n",
    "tilesize2 = 50\n",
    "Hpick = 0.8              # Threshold for required fraction of valid HAND-EM pixels per tile\n",
    "vv_corr = -15.0          # VV threshold to use if threshold calculation did not succeed\n",
    "vh_corr = -23.0          # VH threshold to use if threshold calculation did not succeed\n",
    "\n",
    "# Tile up HAND-EM data\n",
    "handem_p = pad_image(handem, tilesize)\n",
    "hand_tiles = tile_image(handem_p,width=tilesize,height=tilesize)\n",
    "Hsum = np.sum(hand_tiles, axis=(1,2))\n",
    "Hpercent = Hsum/(tilesize*tilesize)\n",
    "\n",
    "# Now do adaptive threshold selection\n",
    "vv_thresholds = np.array([])\n",
    "vh_thresholds = np.array([])\n",
    "floodarea = np.array([])\n",
    "vh_thresholds_corr = np.array([])\n",
    "vv_thresholds_corr = np.array([])\n",
    "\n",
    "posterior_lookup = dict()\n",
    "\n",
    "for i, pair in enumerate(grouped_pths):\n",
    "    print(f\"Processing pair {i+1} of {len(grouped_pths)}\")\n",
    "    for tiff in grouped_pths[pair]:\n",
    "        f = gdal.Open(tiff)\n",
    "        img_array = f.ReadAsArray()\n",
    "        original_shape = img_array.shape\n",
    "        n_rows, n_cols = get_tile_row_col_count(*original_shape, tile_size=tilesize)\n",
    "        print(f'tiff: {tiff}')\n",
    "        if 'vv' in tiff or 'VV' in tiff:\n",
    "            vv_array = pad_image(f.ReadAsArray(), tilesize)\n",
    "            invalid_pixels = np.nonzero(vv_array == 0.0)\n",
    "            vv_tiles = tile_image(vv_array,width=tilesize,height=tilesize)\n",
    "            a = np.shape(vv_tiles)\n",
    "            vv_std = np.zeros(a[0])\n",
    "            vvt_masked = np.ma.masked_where(vv_tiles==0, vv_tiles)\n",
    "            vv_picktiles = np.zeros_like(vv_tiles)\n",
    "            for k in range(a[0]):\n",
    "                vv_subtiles = tile_image(vvt_masked[k,:,:],width=tilesize2,height=tilesize2)\n",
    "                vvst_mean = np.ma.mean(vv_subtiles, axis=(1,2))\n",
    "                vvst_std = np.ma.std(vvst_mean)\n",
    "                vv_std[k] = np.ma.std(vvst_mean) \n",
    "            \n",
    "            # find tiles with largest standard deviations\n",
    "            vv_mean = np.ma.median(vvt_masked, axis=(1,2))\n",
    "            x_vv = np.sort(vv_std/vv_mean)\n",
    "            y_vv = np.arange(1, x_vv.size+1) / x_vv.size\n",
    "            \n",
    "            percentile2 = precentile\n",
    "            sort_index = 0\n",
    "            while np.size(sort_index) < 5: \n",
    "                threshold_index_vv = np.ma.min(np.where(y_vv>percentile2))\n",
    "                threshold_vv = x_vv[threshold_index_vv]\n",
    "                #sd_select_vv = np.nonzero(vv_std/vv_mean>threshold_vv)\n",
    "                s_select_vv = np.nonzero(vv_std/vv_mean>threshold_vv) \n",
    "                h_select_vv = np.nonzero(Hpercent > Hpick)               # Includes HAND-EM in selection\n",
    "                sd_select_vv = np.intersect1d(s_select_vv, h_select_vv)\n",
    "            \n",
    "                # find tiles with mean values lower than the average mean\n",
    "                omean_vv = np.ma.median(vv_mean[h_select_vv])\n",
    "                mean_select_vv = np.nonzero(vv_mean<omean_vv)\n",
    "            \n",
    "                # Intersect tiles with large std with tiles that have small means\n",
    "                msdselect_vv = np.intersect1d(sd_select_vv, mean_select_vv)\n",
    "                sort_index = np.flipud(np.argsort(vv_std[msdselect_vv]))\n",
    "                percentile2 = percentile2 - 0.01\n",
    "            finalselect_vv = sort_index[0:5]\n",
    "            \n",
    "            # find local thresholds for 5 \"best\" tiles in the image\n",
    "            l_thresh_vv = np.zeros(5)\n",
    "            EMthresh_vv = np.zeros(5)\n",
    "            temp = np.ma.masked_where(vv_array==0, vv_array)\n",
    "            dbvv = np.ma.log10(temp)+30\n",
    "            scaling = 256/(np.mean(dbvv) + 3*np.std(dbvv))\n",
    "            #scaling = 256/(np.mean(vv_array) + 3*np.std(vv_array))\n",
    "            dbtile = np.ma.log10(vvt_masked)+30\n",
    "            for k in range(5):\n",
    "                test = dbtile[msdselect_vh[finalselect_vh[k]]] * scaling\n",
    "                #test = vvt_masked[msdselect_vv[finalselect_vv[k]]] * scaling\n",
    "                A = np.around(test)\n",
    "                A = A.astype(int)\n",
    "                #t_thresh = Kittler(A)\n",
    "                [posterior, cm, cv, cp] = EMSeg_opt(A, 3)\n",
    "                sorti = np.argsort(cm)\n",
    "                cms = cm[sorti]\n",
    "                cvs = cv[sorti]\n",
    "                cps = cp[sorti]\n",
    "                xvec = np.arange(cms[0],cms[1],step=.05)\n",
    "                x1 = make_distribution(cms[0], cvs[0], cps[0], xvec)\n",
    "                x2 = make_distribution(cms[1], cvs[1], cps[1], xvec)\n",
    "                dx = np.abs(x1 - x2)\n",
    "                diff1 = posterior[:,:,0] - posterior[:,:,1]\n",
    "                t_ind = np.argmin(dx)\n",
    "                EMthresh_vv[k] = xvec[t_ind]/scaling\n",
    "                \n",
    "                #l_thresh_vv[k] = t_thresh / scaling\n",
    "                #dbtile = np.ma.log10(vvt_masked)+30\n",
    "                \n",
    "                # Mark Tiles used for Threshold Estimation\n",
    "                vv_picktiles[msdselect_vh[finalselect_vh[k]],:,:]= np.ones_like(vv_tiles[msdselect_vh[finalselect_vh[k]],:,:])\n",
    "            \n",
    "            # Calculate best threshold for VV and VH as the mean of the 5 thresholds calculated in the previous section \n",
    "            #m_thresh_vv = np.median(l_thresh_vv)\n",
    "            #print(EMthresh_vv-30)\n",
    "            EMts = np.sort(EMthresh_vv)\n",
    "            #m_thresh_vv = np.median(EMthresh_vv)\n",
    "            m_thresh_vv = np.median(EMts[0:4])\n",
    "            print(\"Best VV Flood Mapping Threshold [dB]: %.2f\" % (10*(m_thresh_vv-30)))\n",
    "            print(\" \")\n",
    "            \n",
    "            # Derive flood mask using the best threshold\n",
    "            if m_thresh_vv < (vv_corr/10.0+30):\n",
    "                change_mag_mask_vv = np.ma.masked_where(dbvv==0, dbvv) < m_thresh_vv\n",
    "                vv_thresholds_corr = np.append(vv_thresholds_corr, 10.0*(m_thresh_vv-30))\n",
    "                #change_mag_mask_vv = np.ma.masked_where(vv_array==0, vv_array) < m_thresh_vv\n",
    "            else:\n",
    "                change_mag_mask_vv = np.ma.masked_where(dbvv==0, dbvv) < (vv_corr/10.0+30)\n",
    "                vv_thresholds_corr = np.append(vv_thresholds_corr, vv_corr)\n",
    "            \n",
    "            # Create Binary masks showing flooded pixels as \"1\"s\n",
    "            flood_vv = np.zeros_like(vv_array)\n",
    "            sel = np.ones_like(vv_array)\n",
    "            flood_vv[change_mag_mask_vv] = sel[change_mag_mask_vv]\n",
    "            np.putmask(flood_vv,vv_array==0 , 0)\n",
    "            \n",
    "            # Export flood maps as GeoTIFFs\n",
    "            filename, ext = Path(tiff).name.split('.')\n",
    "            outfile = f\"{mask_directory}/{filename}_water_mask.{ext}\"\n",
    "            write_mask_to_file(flood_vv, outfile, f.GetProjection(), f.GetGeoTransform())\n",
    "        \n",
    "        else:\n",
    "            vh_array = pad_image(f.ReadAsArray(), tilesize)\n",
    "            invalid_pixels = np.nonzero(vh_array == 0.0)\n",
    "            vh_tiles = tile_image(vh_array,width=tilesize,height=tilesize)\n",
    "            a = np.shape(vh_tiles)\n",
    "            vh_std = np.zeros(a[0])\n",
    "            vht_masked = np.ma.masked_where(vh_tiles==0, vh_tiles)\n",
    "            vh_picktiles = np.zeros_like(vh_tiles)\n",
    "            for k in range(a[0]):\n",
    "                vh_subtiles = tile_image(vht_masked[k,:,:],width=tilesize2,height=tilesize2)\n",
    "                vhst_mean = np.ma.mean(vh_subtiles, axis=(1,2))\n",
    "                vhst_std = np.ma.std(vhst_mean)\n",
    "                vh_std[k] = np.ma.std(vhst_mean)\n",
    "            \n",
    "            # find tiles with largest standard deviations\n",
    "            vh_mean = np.ma.median(vht_masked, axis=(1,2))\n",
    "            x_vh = np.sort(vh_std/vh_mean)\n",
    "            xm_vh = np.sort(vh_mean)\n",
    "            #x_vh = np.sort(vh_std)            \n",
    "            y_vh = np.arange(1, x_vh.size+1) / x_vh.size\n",
    "            ym_vh = np.arange(1, xm_vh.size+1) / xm_vh.size\n",
    "            \n",
    "            percentile2 = precentile\n",
    "            sort_index = 0\n",
    "            while np.size(sort_index) < 5:\n",
    "                threshold_index_vh = np.ma.min(np.where(y_vh>percentile2))\n",
    "                threshold_vh = x_vh[threshold_index_vh]\n",
    "                #sd_select_vh = np.nonzero(vh_std/vh_mean>threshold_vh)\n",
    "                s_select_vh = np.nonzero(vh_std/vh_mean>threshold_vh) \n",
    "                h_select_vh = np.nonzero(Hpercent > Hpick)               # Includes HAND-EM in selection\n",
    "                sd_select_vh = np.intersect1d(s_select_vh, h_select_vh)\n",
    "    \n",
    "                # find tiles with mean values lower than the average mean \n",
    "                omean_vh = np.ma.median(vh_mean[h_select_vh])\n",
    "                mean_select_vh = np.nonzero(vh_mean<omean_vh)\n",
    "            \n",
    "                # Intersect tiles with large std with tiles that have small means\n",
    "                msdselect_vh = np.intersect1d(sd_select_vh, mean_select_vh)\n",
    "                sort_index = np.flipud(np.argsort(vh_std[msdselect_vh]))\n",
    "                percentile2 = percentile2 - 0.01\n",
    "            finalselect_vh = sort_index[0:5]\n",
    "    \n",
    "    \n",
    "            # find local thresholds for 5 \"best\" tiles in the image\n",
    "            l_thresh_vh = np.zeros(5)\n",
    "            EMthresh_vh = np.zeros(5)\n",
    "            temp = np.ma.masked_where(vh_array==0, vh_array)\n",
    "            dbvh = np.ma.log10(temp)+30\n",
    "            scaling = 256/(np.mean(dbvh) + 3*np.std(dbvh))\n",
    "            #scaling = 256/(np.mean(vh_array) + 3*np.std(vh_array))\n",
    "            dbtile = np.ma.log10(vht_masked)+30\n",
    "            for k in range(5):\n",
    "                test = dbtile[msdselect_vh[finalselect_vh[k]]] * scaling\n",
    "                #test = vht_masked[msdselect_vh[finalselect_vh[k]]] * scaling\n",
    "                A = np.around(test)\n",
    "                A = A.astype(int)\n",
    "                #t_thresh = Kittler(A)\n",
    "                [posterior, cm, cv, cp] = EMSeg_opt(A, 3)\n",
    "                sorti = np.argsort(cm)\n",
    "                cms = cm[sorti]\n",
    "                cvs = cv[sorti]\n",
    "                cps = cp[sorti]\n",
    "                xvec = np.arange(cms[0],cms[1],step=.05)\n",
    "                x1 = make_distribution(cms[0], cvs[0], cps[0], xvec)\n",
    "                x2 = make_distribution(cms[1], cvs[1], cps[1], xvec)\n",
    "                dx = np.abs(x1 - x2)\n",
    "                diff1 = posterior[:,:,0] - posterior[:,:,1]\n",
    "                t_ind = np.argmin(dx)\n",
    "                EMthresh_vh[k] = xvec[t_ind]/scaling\n",
    "                \n",
    "                #l_thresh_vh[k] = t_thresh / scaling\n",
    "                \n",
    "                \n",
    "                # Mark Tiles used for Threshold Estimation\n",
    "                vh_picktiles[msdselect_vh[finalselect_vh[k]],:,:]= np.ones_like(vh_tiles[msdselect_vh[finalselect_vh[k]],:,:])\n",
    "    \n",
    "            # Calculate best threshold for VV and VH as the mean of the 5 thresholds calculated in the previous section \n",
    "            #m_thresh_vh = np.median(l_thresh_vh)\n",
    "            #print(EMthresh_vh-30)\n",
    "            EMts = np.sort(EMthresh_vh)\n",
    "            #m_thresh_vh = np.median(EMthresh_vh)\n",
    "            m_thresh_vh = np.median(EMts[0:4])\n",
    "            print(\"Best VH Flood Mapping Threshold [dB]: %.2f\" % (10*(m_thresh_vh-30)))\n",
    "            print(\" \")\n",
    "    \n",
    "            # Derive flood mask using the best threshold\n",
    "            maskedarray = np.ma.masked_where(dbvh==0, dbvh)\n",
    "            \n",
    "            #maskedarray = np.ma.masked_where(vh_array==0, vh_array)\n",
    "            if m_thresh_vh < (vh_corr/10.0+30):\n",
    "                change_mag_mask_vh = maskedarray < m_thresh_vh\n",
    "                vh_thresholds_corr = np.append(vh_thresholds_corr, 10.0*(m_thresh_vh-30)) \n",
    "                #change_mag_mask_vv = np.ma.masked_where(vv_array==0, vv_array) < m_thresh_vv\n",
    "            else:\n",
    "                change_mag_mask_vh = maskedarray < (vh_corr/10.0+30)\n",
    "                vh_thresholds_corr = np.append(vh_thresholds_corr, vh_corr) \n",
    "            # change_mag_mask_vh = vh_array < m_thresh_vh\n",
    "    \n",
    "            # Create Binary masks showing flooded pixels as \"1\"s\n",
    "            sel = np.ones_like(vh_array)\n",
    "            flood_vh = np.zeros_like(vh_array)\n",
    "            flood_vh[change_mag_mask_vh] = sel[change_mag_mask_vh]\n",
    "            np.putmask(flood_vh,vh_array==0 , 0)\n",
    "\n",
    "            # Export flood maps as GeoTIFFs\n",
    "            filename, ext = Path(tiff).name.split('.')\n",
    "            outfile = f\"{mask_directory}/{filename}_water_mask.{ext}\"\n",
    "            write_mask_to_file(flood_vh, outfile, f.GetProjection(), f.GetGeoTransform())\n",
    "        \n",
    "    \n",
    "    # Create Maps (Pickfiles) that show which tiles were used for adaptive threshold calculation\n",
    "    vv_picks = vv_picktiles.reshape((n_rows, n_cols, tilesize, tilesize)) \\\n",
    "                .swapaxes(1, 2) \\\n",
    "                .reshape(n_rows * tilesize, n_cols * tilesize)  # yapf: disable\n",
    "    vh_picks = vh_picktiles.reshape((n_rows, n_cols, tilesize, tilesize)) \\\n",
    "                .swapaxes(1, 2) \\\n",
    "                .reshape(n_rows * tilesize, n_cols * tilesize)  # yapf: disable\n",
    "    \n",
    "    # Write Pickfiles to GeoTIFFs\n",
    "    #outfile = f\"{mask_directory}/{filename[:-3]}_vv_pickfile.{ext}\"\n",
    "    #write_mask_to_file(vv_picks, outfile, f.GetProjection(), f.GetGeoTransform())\n",
    "    #outfile = f\"{mask_directory}/{filename[:-3]}_vh_pickfile.{ext}\"\n",
    "    #write_mask_to_file(vh_picks, outfile, f.GetProjection(), f.GetGeoTransform())\n",
    "\n",
    "    # Combine VV and VH flood maps to produce a combined flood mapping product\n",
    "    comb = flood_vh + flood_vv\n",
    "    comb_mask = comb > 0\n",
    "    flood_comb = np.zeros_like(vv_array)\n",
    "    flood_comb[comb_mask] = sel[comb_mask]\n",
    "    filename, ext = Path(tiff).name.split('.')\n",
    "    outfile = f\"{mask_directory}/{filename[:-3]}_water_mask_combined.{ext}\"\n",
    "    write_mask_to_file(flood_comb, outfile, f.GetProjection(), f.GetGeoTransform())\n",
    "    \n",
    "    # Create Information on Thresholds used as well as Flood extent information in km2\n",
    "    vv_thresholds = np.append(vv_thresholds, 10.0*(m_thresh_vv-30))\n",
    "    vh_thresholds = np.append(vh_thresholds, 10.0*(m_thresh_vh-30)) \n",
    "    floodarea = np.append(floodarea,(np.sum(flood_comb)*30**2./(1000**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Fuzzy Logic Post Processing to Clean up Initial Surface Water Extent Map\n",
    "\n",
    "1. The radar cross section in a pixel relative to the determined detection threshold.\n",
    "1. The HAND elevation (surface elevation relative to the nearest dranage basin).\n",
    "1. The surface slope.\n",
    "1. The size of a detected flood feature.\n",
    "\n",
    "Fuzzy membership functions are calculated for each of these four indicators using a Z-shaped activation function. Membership functions are combined using arithmetric averaging to form a final decision map. This map is then thresholded using a fuzzy threshold of 0.45.\n",
    "\n",
    "**Upper and lower thresholds for the fuzzy activation functions are calculated as follows:**\n",
    "\n",
    "1. **RCS:** $\\begin{Bmatrix} \n",
    "    x_{u,RCS} & = & \\tau_g \\\\\n",
    "    x_{l,RCS} & = & \\mu_{\\sigma^0(\\tau_g)}\n",
    "    \\end{Bmatrix}$ \n",
    "    with $\\sigma^0(\\tau_g)$ = initial flood classification and flood mapping threshold $\\tau_g$.<br><br></li>\n",
    "1. **HAND:** $\\begin{Bmatrix} \n",
    "    x_{u,HAND} & = & \\mu_{HAND(water)} + 3 \\cdot \\sigma_{HAND(water)} \\\\\n",
    "    x_{l,HAND} & = & \\mu_{HAND(water)}\n",
    "    \\end{Bmatrix}$. This is a departure from <cite><a href=\"https://www.sciencedirect.com/science/article/pii/S0924271614001981\" target=\"_blank\"><i>the paper</i></a> by Martinis et al. (2015)</cite>.<br><br></li>\n",
    "1. **Surface slope $\\alpha$:** $\\begin{Bmatrix} \n",
    "    x_{u,\\alpha} & = & 0^{\\circ} \\\\\n",
    "    x_{l,\\alpha} & = & 15^{\\circ}\n",
    "    \\end{Bmatrix}$.<br><br></li>\n",
    "1. **Area $A$:**$\\begin{Bmatrix} \n",
    "    x_{u,A} & = & 10px \\\\\n",
    "    x_{l,A} & = & 3px\n",
    "    \\end{Bmatrix}$. These threshold values are different differently than in [the paper by Martinis et al. (2015)](https://www.sciencedirect.com/science/article/pii/S0924271614001981)\n",
    "    \n",
    "---\n",
    "\n",
    "**Note:** By default, this post-processing step is not used in this notebook. Deactivating the post processing procedure is done to save processing time for this course exercise. Feel free to activate this step by setting the `do_PP` flag to `True` in the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "do_PP = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "**This next code cell does the actual fuzzy logic-based post processing work:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if do_PP:\n",
    "    import skimage.measure\n",
    "    import skimage.color\n",
    "    from skimage import morphology\n",
    "    from skimage import filters\n",
    "    import time\n",
    "    import astropy.convolution\n",
    "    import warnings #Suppress warnings on occasion\n",
    "    from tqdm.auto import tqdm\n",
    "\n",
    "    vvcount = 0\n",
    "    vhcount = 0\n",
    "    floodareaPP = np.array([])\n",
    "\n",
    "    print('FUZZY LOGIC POST PROCESSING TO REFINE INITIAL SURFACE WATER EXTENT MAPS:')\n",
    "    print(' ')\n",
    "\n",
    "    for pair in grouped_pths:\n",
    "        for tiff in grouped_pths[pair]:\n",
    "            print(type(tiff))\n",
    "            \n",
    "            start = time.time()\n",
    "            print('-----------------------------------------------------------------------------------')\n",
    "            print(f'Image: {tiff}')\n",
    "            resampled_dem_path=f'{tiff_dir}/resamp_dem.tif'\n",
    "            f = gdal.Open(tiff)\n",
    "            img_array = f.ReadAsArray()\n",
    "            original_shape = img_array.shape\n",
    "            img_array = 0     # free up RAM\n",
    "            radar_array = pad_image(f.ReadAsArray(), tilesize)\n",
    "            temp = np.ma.masked_where(radar_array==0, radar_array)\n",
    "            np.seterr(divide='ignore')\n",
    "            np.seterr(invalid='ignore')\n",
    "            dbarray = np.log10(temp)+30\n",
    "            del temp\n",
    "\n",
    "            # ------------------------------------------------------------#\n",
    "            # Loading Water Mask File                                     #\n",
    "            #-------------------------------------------------------------#\n",
    "            filename, ext = Path(tiff).name.split('.')\n",
    "            waterfile = f\"{mask_directory}/{filename}_water_mask.{ext}\"\n",
    "            h = gdal.Open(waterfile)\n",
    "            maskimage = h.ReadAsArray()\n",
    "\n",
    "\n",
    "            print('   - Extracting Relevant Subset from HAND Layer ...')\n",
    "\n",
    "            info1 = (gdal.Info(tiff, options = ['-json']))\n",
    "            info1 = json.dumps(info1)\n",
    "            ul = (json.loads(info1))['cornerCoordinates']['upperLeft']\n",
    "            lr = (json.loads(info1))['cornerCoordinates']['lowerRight']\n",
    "            coordsys = (json.loads(info1))['coordinateSystem']['wkt']\n",
    "            Szone = coordsys.split('ID')[-1].split(',')[1][0:-2]\n",
    "            Sproj_type = coordsys.split('ID')[-1].split('\"')[1]\n",
    "\n",
    "            west= ul[0]\n",
    "            east= lr[0]\n",
    "            south= lr[1]\n",
    "            north= ul[1]\n",
    "\n",
    "            cmd_resamp=f\"gdalwarp -overwrite -s_srs {Hproj_type}:\"\\\n",
    "            f\"{Hzone} -t_srs EPSG:{Szone} -te {west} {south} {east} {north} -ts {original_shape[1]} {original_shape[0]} -r lanczos {HAND_file} {resampled_dem_path}\"\n",
    "            #print(cmd_resamp)\n",
    "            system(cmd_resamp)\n",
    "\n",
    "            g = gdal.Open(resampled_dem_path)\n",
    "            hand = pad_image(g.ReadAsArray(), tilesize)\n",
    "\n",
    "            print('   - Interpolate NaNs in HAND Layer ...')\n",
    "\n",
    "            hand_interp= fill_nan(hand)\n",
    "            del hand\n",
    "\n",
    "            print('   - Calculate DEM (HAND) Slope magnitude ...')\n",
    "\n",
    "            vgrad = np.gradient(hand_interp)\n",
    "            mag = np.sqrt(vgrad[0]**2 + vgrad[1]**2)\n",
    "            geotransform = g.GetGeoTransform()\n",
    "            res = geotransform[1]\n",
    "            slope = np.arctan(mag/res)/np.pi*180\n",
    "\n",
    "            print('   - Segment initial flood mask to calculate area of connected patches ...')\n",
    "\n",
    "            # Here an attempt to perform a sequence of opening and closing steps to \n",
    "            # reduce the number of segments in the inital flood maps and speed up the next processing steps\n",
    "            med = filters.median(maskimage, morphology.disk(2))\n",
    "            selem = morphology.disk(3)\n",
    "            closed = skimage.morphology.closing(med, selem)\n",
    "            labeled_image = skimage.measure.label(closed, connectivity=2)\n",
    "            label_areas = np.bincount(labeled_image.ravel())[1:]\n",
    "\n",
    "\n",
    "            # Define upper and lower limit of the Z fuzzy activation function\n",
    "\n",
    "            print('   - Now Calculate Fuzzy Weights ...')\n",
    "\n",
    "            ## sigma zero upper and lower fuzzy threshold calculation\n",
    "            maskedarray = np.ma.masked_where((maskimage==0) | (radar_array < 0), radar_array)\n",
    "            db_lowerlimit = np.log10(np.ma.median(maskedarray))+30\n",
    "            if 'vv' in tiff or 'VV' in tiff:\n",
    "                db_upperlimit = (vv_thresholds_corr[vvcount]/10.0+30)\n",
    "                vvcount = vvcount + 1\n",
    "            else:\n",
    "                db_upperlimit = (vh_thresholds_corr[vhcount]/10.0+30)\n",
    "                vhcount = vhcount + 1\n",
    "\n",
    "            ## HAND upper and lower fuzzy threshold calculation\n",
    "            maskedarray = np.ma.masked_where(maskimage==0, hand_interp)\n",
    "            ma2 = np.ma.masked_where(maskedarray > np.percentile(maskedarray, 90), maskedarray)\n",
    "            hand_lowerlimit = np.ma.median(np.ma.masked_invalid(ma2))\n",
    "            hand_upperlimit = hand_lowerlimit + (np.ma.std(np.ma.masked_invalid(ma2)) + 3.5)*np.ma.std(np.ma.masked_invalid(ma2))\n",
    "            hand_upperlimit = hand_lowerlimit + 3.0*(np.ma.std(np.ma.masked_invalid(ma2)))\n",
    "\n",
    "            # Create vector spanning all possible values for db, HAND, Slope, and Area values for the selected data set\n",
    "            x_db = np.arange(np.min(dbarray), np.max(dbarray), 0.005)\n",
    "            x_hand = np.arange(np.min(np.ma.masked_invalid(hand_interp)), np.max(np.ma.masked_invalid(hand_interp)), 0.1)\n",
    "            x_slope = np.arange(np.min(np.ma.masked_invalid(slope)), np.max(np.ma.masked_invalid(slope)), 0.1)\n",
    "\n",
    "            largestCC = labeled_image == np.argmax(np.bincount(labeled_image.flat, weights=maskimage.flat))\n",
    "            x_area = np.arange(1, np.sum(largestCC)+10, 1)\n",
    "\n",
    "            # Create activation functions for db, HAND, SLope and Area\n",
    "            activation_db = skfuzzy.zmf(x_db,db_lowerlimit,db_upperlimit)\n",
    "            activation_hand = skfuzzy.zmf(x_hand,hand_lowerlimit,hand_upperlimit)\n",
    "            activation_slope = skfuzzy.zmf(x_slope,0,15)\n",
    "            activation_area = 1-skfuzzy.zmf(x_area,3,10)\n",
    "\n",
    "            # Calculate membership functions given your activation function rule\n",
    "            db_membership = skfuzzy.interp_membership(x_db, activation_db, dbarray)\n",
    "            print('      -- Calculating Radar Cross Section Membership ... [min thresholds: %6.2f' % (db_lowerlimit-30),'; max threshold: %6.2f]' % (db_upperlimit-30))     \n",
    "            hand_membership = skfuzzy.interp_membership(x_hand, activation_hand, hand_interp)\n",
    "            print('      -- Calculating HAND Membership ... [min thresholds: %6.2f' % (hand_lowerlimit),'; max threshold: %6.2f]' % (hand_upperlimit)) \n",
    "            slope_membership = skfuzzy.interp_membership(x_slope, activation_slope, slope)\n",
    "            print('      -- Calculating Slope Membership ... [min thresholds: 0 deg; max threshold: 15 deg]') \n",
    "            area_membership = np.zeros_like(radar_array)\n",
    "\n",
    "            print('      -- Calculating Area Membership ... [This may take a while!]')\n",
    "            test = np.array([])\n",
    "            for x in tqdm(range(1, np.max(labeled_image))):\n",
    "                #clear_output(wait=True)\n",
    "                #np.putmask(area_membership,labeled_image==x,skfuzzy.interp_membership(x_area, activation_area, np.sum(labeled_image==x)))\n",
    "                np.putmask(area_membership,labeled_image==x,skfuzzy.interp_membership(x_area, activation_area, label_areas[x-1]))\n",
    "                \n",
    "            water_gT=gdal_get_geotransform(waterfile)\n",
    "            water_proj4=get_proj4(waterfile)\n",
    "\n",
    "            # Uncomment these following lines if you want more intermediary files to be saved off as GeoTIFFs\n",
    "            #filename, ext = Path(tiff).name.split('.')\n",
    "            #outfile = f\"{mask_directory}/{filename}_dbmembership.{ext}\"\n",
    "            #gdal_write(db_membership, water_gT, filename=outfile, srs_proj4=water_proj4.srs, nodata=np.nan, format=gdal.GDT_Float32)\n",
    "            #outfile = f\"{mask_directory}/{filename}_handmembership.{ext}\"\n",
    "            #gdal_write(hand_membership, water_gT, filename=outfile, srs_proj4=water_proj4.srs, nodata=np.nan, format=gdal.GDT_Float32)\n",
    "            #outfile = f\"{mask_directory}/{filename}_slopemembership.{ext}\"\n",
    "            #gdal_write(slope_membership, water_gT, filename=outfile, srs_proj4=water_proj4.srs, nodata=np.nan, format=gdal.GDT_Float32)\n",
    "            #outfile = f\"{mask_directory}/{filename}_areamembership.{ext}\"\n",
    "            #gdal_write(area_membership, water_gT, filename=outfile, srs_proj4=water_proj4.srs, nodata=np.nan, format=gdal.GDT_Float32)\n",
    "\n",
    "\n",
    "            print('   - Combine all fuzzy membership functions to make final flood mapping decision')\n",
    "            dbmask = db_membership != 0.0\n",
    "            handmask = hand_membership != 0.0\n",
    "            slopemask = slope_membership != 0.0\n",
    "            areamask = area_membership != 0.0\n",
    "            combinedm = dbmask * handmask * slopemask * areamask\n",
    "            combinedmask = np.zeros_like(radar_array)\n",
    "            sel = np.ones_like(dbarray)\n",
    "            combinedmask[combinedm] = sel[combinedm]\n",
    "            combinedweights = ((db_membership + hand_membership + slope_membership + area_membership) / 4.0) * combinedmask \n",
    "            acceptance = combinedweights > 0.45\n",
    "\n",
    "            # Uncomment these following lines if you want more intermediary files to be saved off as GeoTIFFs\n",
    "            #outfile = f\"{mask_directory}/{filename}_totalmembership.{ext}\"\n",
    "            #gdal_write(combinedweights, water_gT, filename=outfile, srs_proj4=water_proj4.srs, nodata=np.nan, format=gdal.GDT_Float32)\n",
    "\n",
    "            sel = np.ones_like(radar_array)\n",
    "            floodmap = np.zeros_like(radar_array)\n",
    "            floodmap[acceptance] = sel[acceptance]\n",
    "            np.putmask(floodmap,radar_array==0 , 0)\n",
    "            if 'vv' in tiff or 'VV' in tiff:\n",
    "                floodmap_vv = floodmap\n",
    "            else:\n",
    "                floodmap_vh = floodmap\n",
    "\n",
    "            # Export flood maps as GeoTIFFs\n",
    "            #filename, ext = Path(tiff).name.split('.')\n",
    "            #outfile = f\"{mask_directory}/{filename}_final_water_mask.{ext}\"\n",
    "            #write_mask_to_file(floodmap, outfile, f.GetProjection(), f.GetGeoTransform())\n",
    "            del floodmap\n",
    "            print('   - Processing time: %6.2f minutes' % ((time.time() - start)/60.0))\n",
    "            print('-----------------------------------------------------------------------------------')\n",
    "            print(' ')\n",
    "\n",
    "        # Combine VV and VH flood maps to produce a combined flood mapping product\n",
    "        comb = floodmap_vh + floodmap_vv\n",
    "        comb_mask = comb > 0\n",
    "        flood_comb = np.zeros_like(radar_array)\n",
    "        flood_comb[comb_mask] = sel[comb_mask]\n",
    "        filename, ext = Path(tiff).name.split('.')\n",
    "        outfile = f\"{mask_directory}/{filename[:-3]}_fcWM.{ext}\"\n",
    "        write_mask_to_file(flood_comb, outfile, f.GetProjection(), f.GetGeoTransform())\n",
    "        floodareaPP = np.append(floodareaPP,(np.sum(flood_comb)*30**2./(1000**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Evaluate Flood Mapping Results\n",
    "\n",
    "This section allows to evaluate the flood mapping information that was created. Different types of plots are offered to visualze the time series of surface water area as well as individual flood extent maps and statistical plots.\n",
    "\n",
    "This first code cell **plots the time series of surface water extent that was found in the analyzed SAR scenes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "validarea = np.array([])\n",
    "floodpercent = np.array([])\n",
    "agreggatepx = np.zeros_like(vv_array)\n",
    "k = 0\n",
    "for pair in grouped_pths:\n",
    "    for tiff in grouped_pths[pair]:\n",
    "        f = gdal.Open(tiff)\n",
    "        if 'vv' in tiff or 'VV' in tiff:\n",
    "            vv_array = pad_image(f.ReadAsArray(), tilesize)\n",
    "            temp = vv_array > 0\n",
    "            sel = np.ones_like(vv_array)\n",
    "            valid_pixels = np.zeros_like(vv_array)\n",
    "            valid_pixels[temp] = sel[temp]\n",
    "            #np.putmask(valid_pixels,vv_array==0 , 0)\n",
    "            validarea = np.append(validarea,sum(sum(valid_pixels))*30**2./(1000**2))\n",
    "            if do_PP:\n",
    "                floodpercent = np.append(floodpercent,floodareaPP[k]/validarea[k] * 100.0)\n",
    "            else:\n",
    "                floodpercent = np.append(floodpercent,floodarea[k]/validarea[k] * 100.0)\n",
    "            agreggatepx = agreggatepx + valid_pixels\n",
    "            k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 12})\n",
    "temp_path = tiff_dir/\"*VV.tiff\"\n",
    "dates = get_dates(temp_path)\n",
    "time_index = pd.DatetimeIndex(dates)\n",
    "\n",
    "fig = plt.figure(figsize=(9, 4))\n",
    "ax1 = fig.add_subplot(111)  # 121 determines: 2 rows, 2 plots, first plot\n",
    "ax1.plot(np.unique(time_index), floodpercent, color='b', marker='o', markersize=3, label='Area Covered in Water [%]')\n",
    "ax1.set_ylim([np.min(floodpercent)-np.min(floodpercent)*0.1, np.max(floodpercent)+np.min(floodpercent)*0.1])\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.axhline(y=np.mean(floodpercent), color='k', linestyle='--', label='Average Water Coverage [%]')\n",
    "ax1.set_ylabel('Image Area Covered in Water [%]')\n",
    "ax1.grid()\n",
    "figname = ('ThresholdAndAreaTS.png')\n",
    "ax1.legend(loc='lower right')\n",
    "plt.savefig(path/figname, dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "**The following code cells allow you to visualize individual flood maps superimposed on the respective SAR image they were derived from.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tif_suffix = \"*fcWM.tif*\" if do_PP else \"*combined.tif*\"\n",
    "wpaths = tiff_dir/f\"Water_Masks/{tif_suffix}\"\n",
    "\n",
    "spaths = tiff_dir/\"*VV.tif*\"\n",
    "\n",
    "vrtcommand = f\"gdalbuildvrt -separate {path}/Water.vrt {wpaths}\"\n",
    "!{vrtcommand}\n",
    "water_file = path/\"Water.vrt\"\n",
    "vrtcommand = f\"gdalbuildvrt -separate {path}/SAR.vrt {spaths}\"\n",
    "!{vrtcommand}\n",
    "SAR_file = path/\"SAR.vrt\"\n",
    "\n",
    "img = gdal.Open(str(SAR_file))\n",
    "wm = gdal.Open(str(water_file))\n",
    "SARstack = img.ReadAsArray(5, 20, 5, 5)\n",
    "SARsize = np.shape(SARstack)\n",
    "SARbands = SARsize[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "**Please change the `band_num` setting in the next code cell** to visualize flood mapping results for different SAR image acquisition dates.\n",
    "\n",
    "Note the tool bar in the bottom left corner of the image that's created. Feel free to use the toolbar to zoom into the image and navigate around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "band_num = 5# Change the band number to visualize different SAR acquisitions and respective flood mapping results\n",
    "\n",
    "if band_num > SARbands:\n",
    "    band_num = SARbands\n",
    "\n",
    "SARraster = img.GetRasterBand(band_num).ReadAsArray()\n",
    "waterraster = wm.GetRasterBand(band_num).ReadAsArray()\n",
    "water_masked = np.ma.masked_where(waterraster==0, waterraster)\n",
    "waterraster = 0\n",
    "plt.figure(figsize=(9, 6))\n",
    "vmin = np.percentile(SARraster, 5)  #vh_array\n",
    "vmax = np.percentile(SARraster, 95)\n",
    "plt.imshow(SARraster, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "plt.suptitle(f'Water Mask on SAR Image: {time_index.year[band_num-1]} / {time_index.month[band_num-1]} / {time_index.day[band_num-1]}')\n",
    "plt.grid()\n",
    "plt.imshow(water_masked, cmap='Blues',interpolation=\"nearest\", vmin=0, vmax=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>EXERCISE</u>:  </font> Analyze the Quality of the Water Masks</b></font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Look at different Flood Maps for your 16 dates and evaluate the performance of the flood map. To do so, use the toolbar in the bottom left corner of the image above to zoom in and navigate around: \n",
    "- Zoom into the map and look at the details. Are there some pxiels that you would have added to the mask? \n",
    "- If you think flood areas were missed, do you seen anything in the underlying image that may explain why a pixel was not detected? </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create Summary Statistics\n",
    "\n",
    "Once flood maps for each individual image acquisition date were created, summary statistics can be derived that describe the severity and duration of an event. In the following, <b>we will be deriving a metric describing how many days each image pixel was inundated during an analyzed event</b>. This should provide a template for other metrics to be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add empty buffer to match the size of matrices when flevent is 2.\n",
    "\n",
    "if flevent == 2:\n",
    "    rasterstack = wm.ReadAsArray()\n",
    "    floodcount = np.sum(rasterstack,0)\n",
    "    \n",
    "    if len(agreggatepx) < len(floodcount):\n",
    "        buffer = np.zeros((len(agreggatepx[0]),), dtype=float)\n",
    "        agreggatepx = np.vstack([agreggatepx, buffer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.seterr(invalid='ignore')\n",
    "rasterstack = wm.ReadAsArray()\n",
    "srs = np.shape(rasterstack)\n",
    "floodcount = np.sum(rasterstack,0)\n",
    "\n",
    "\n",
    "print('floodcount:')\n",
    "# print(floodcount)\n",
    "print('len:', len(floodcount))\n",
    "\n",
    "print('\\nagreggatepx:')\n",
    "# print(agreggatepx)\n",
    "print('len:', len(agreggatepx))\n",
    "\n",
    "# print('\\nflood percent:')\n",
    "# print((floodcount/agreggatepx) * 100.0)\n",
    "\n",
    "floodpercent = floodcount / agreggatepx * 100.0\n",
    "np.putmask(floodpercent, floodpercent>100.0, 100.0)\n",
    "temptime = time_index.to_julian_date()\n",
    "dt = temptime[SARbands-1] - temptime[0]\n",
    "flooddays = floodpercent / 100 * float(dt)\n",
    "rasterstack = 0\n",
    "fd_masked = np.ma.masked_where(flooddays==0, flooddays)\n",
    "\n",
    "flood_gT=gdal_get_geotransform(tiff)\n",
    "flood_proj4=get_proj4(tiff)\n",
    "outfile = f\"{mask_directory}/flooddays.tiff\"\n",
    "gdal_write(flooddays, flood_gT, filename=outfile, srs_proj4=flood_proj4.srs, nodata=np.nan, format=gdal.GDT_Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "SARraster = img.GetRasterBand(SARbands).ReadAsArray()\n",
    "plt.figure(figsize=(9, 6))\n",
    "vmin = np.percentile(SARraster, 5)  #vh_array\n",
    "vmax = np.percentile(SARraster, 95)\n",
    "plt.suptitle('Number of Inundated Days Per Pixel - Minimum SAR Image as Background')\n",
    "plt.imshow(SARraster, interpolation = 'nearest', cmap='gray', vmin=vmin, vmax=vmax)\n",
    "im = plt.imshow(fd_masked, interpolation = 'nearest', cmap='jet')\n",
    "plt.colorbar(im, orientation='vertical')\n",
    "plt.grid()\n",
    "outfile = f\"{mask_directory}/flooddaysBG.tif\"\n",
    "write_mask_to_file(flooddays, outfile, img.GetProjection(), img.GetGeoTransform())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>EXERCISE</u>:  </font> Analyze the Summary Statistic Plot</b></font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Look at different colors in the plot above and try to understand what they mean and whether or not they make sense to you. To do so, use the toolbar in the bottom left corner of the image above to zoom in and navigate around. </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "# Version Log\n",
    "\n",
    "*FloodMappingFromSARImages.ipynb - version 1.5.2 February 2024*\n",
    "\n",
    "*Version Changes:*\n",
    "\n",
    "- *Don't hardcode path to sample data*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.local-hydrosar]",
   "language": "python",
   "name": "conda-env-.local-hydrosar-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
