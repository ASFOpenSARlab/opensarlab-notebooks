{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![OpenSARlab notebook banner](NotebookAddons/blackboard-banner.png)\n",
    "\n",
    "# Exploring SAR Time Series Data over Ecosystems and Deforestation Sites\n",
    "\n",
    "<img style=\"padding:7px;\" src=\"NotebookAddons/UAFLogo_A_647.png\" width=\"170\" align=\"right\" />\n",
    "\n",
    "### Franz J Meyer; University of Alaska Fairbanks & Josef Kellndorfer, [Earth Big Data, LLC](http://earthbigdata.com/)\n",
    "\n",
    "This notebook introduces you to the time series signatures over forested sites and sites affected by deforestation. The data analysis is done in the framework of *Jupyter Notebooks*. The Jupyter Notebook environment is easy to launch in any web browser for interactive data exploration with provided or new training data. Notebooks are comprised of text written in a combination of executable python code and markdown formatting including latex style mathematical equations. Another advantage of Jupyter Notebooks is that they can easily be expanded, changed, and shared with new data sets or newly available time series steps. Therefore, they provide an excellent basis for collaborative and repeatable data analysis.\n",
    "\n",
    "**This notebook covers the following data analysis concepts:**\n",
    "\n",
    "<img style=\"padding:7px;\" src=\"NotebookAddons/OpenSARlab_logo.svg\" width=\"170\" align=\"right\" />\n",
    "\n",
    "- How to load time series stacks into Jupyter Notebooks and how to explore image content using basic functions such as mean value calculation and histogram analysis.\n",
    "- How to extract time series information for individual pixels of an image.\n",
    "- Typical time series signatures over forests and deforestation sites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Important Notes about JupyterHub**\n",
    "\n",
    "Your JupyterHub server will automatically shutdown when left idle for more than 1 hour. Your notebooks will not be lost but you will have to restart their kernels and re-run them from the beginning. You will not be able to seamlessly continue running a partially run notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import url_widget as url_w\n",
    "notebookUrl = url_w.URLWidget()\n",
    "display(notebookUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "\n",
    "notebookUrl = notebookUrl.value\n",
    "user = !echo $JUPYTERHUB_USER\n",
    "env = !echo $CONDA_PREFIX\n",
    "if env[0] == '':\n",
    "    env[0] = 'Python 3 (base)'\n",
    "if env[0] != '/home/jovyan/.local/envs/rtc_analysis':\n",
    "    display(Markdown(f'<text style=color:red><strong>WARNING:</strong></text>'))\n",
    "    display(Markdown(f'<text style=color:red>This notebook should be run using the \"rtc_analysis\" conda environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>It is currently using the \"{env[0].split(\"/\")[-1]}\" environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Select the \"rtc_analysis\" from the \"Change Kernel\" submenu of the \"Kernel\" menu.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>If the \"rtc_analysis\" environment is not present, use <a href=\"{notebookUrl.split(\"/user\")[0]}/user/{user[0]}/notebooks/conda_environments/Create_OSL_Conda_Environments.ipynb\"> Create_OSL_Conda_Environments.ipynb </a> to create it.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Note that you must restart your server after creating a new environment before it is usable by notebooks.</text>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing Relevant Python Packages\n",
    "\n",
    "In this notebook we will use the following scientific libraries:\n",
    "\n",
    "- [Pandas](https://pandas.pydata.org/) is a Python library that provides high-level data structures and a vast variety of tools for analysis. The great feature of this package is the ability to translate rather complex operations with data into one or two commands. Pandas contains many built-in methods for filtering and combining data, as well as the time-series functionality.\n",
    "- [GDAL](https://www.gdal.org/) is a software library for reading and writing raster and vector geospatial data formats. It includes a collection of programs tailored for geospatial data processing. Most modern GIS systems (such as ArcGIS or QGIS) use GDAL in the background.\n",
    "- [NumPy](http://www.numpy.org/) is one of the principal packages for scientific applications of Python. It is intended for processing large multidimensional arrays and matrices, and an extensive collection of high-level mathematical functions and implemented methods makes it possible to perform various operations with these objects.\n",
    "- [Matplotlib](https://matplotlib.org/index.html) is a low-level library for creating two-dimensional diagrams and graphs. With its help, you can build diverse charts, from histograms and scatterplots to non-Cartesian coordinates graphs. Moreover, many popular plotting libraries are designed to work in conjunction with matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from pathlib import Path\n",
    "from math import ceil\n",
    "\n",
    "import pandas as pd # for DatetimeIndex\n",
    "import numpy as np #for log10, mean, percentile, power\n",
    "from osgeo import gdal # for GetRasterBand, Open, ReadAsArray\n",
    "gdal.UseExceptions()\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib.patches as patches  # for Rectangle\n",
    "import matplotlib.pyplot as plt # for add_subplot, axis, figure, imshow, legend, plot, set_axis_off, set_data,\n",
    "                                # set_title, set_xlabel, set_ylabel, set_ylim, subplots, title, twinx\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "import opensarlab_lib as asfn\n",
    "asfn.jupytertheme_matplotlib_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Load Data Stack\n",
    "\n",
    "<img src=\"NotebookAddons/Deforest-MadreDeDios.jpg\" width=\"350\" style=\"padding:5px;\" align=\"right\" /> \n",
    "\n",
    "This notebook will be using a 78-image deep dual-polarization C-band SAR data stack over Madre de Dios in Peru to analyze time series signatures of vegetation covers, water bodies, and areas affected by deforestation. The C-band data were acquired by ESA's Sentinel-1 SAR sensor constellation and are available to you through the services of the [Alaska Satellite Facility](https://www.asf.alaska.edu/\" target).\n",
    "\n",
    "The site in question is interesting as it has experienced extensive logging over the last 10 years (see image to the right; [Monitoring of the Andean Amazon Project](https://blog.globalforestwatch.org/). Since the 1980s, people have been clearing forests in this area for farming, cattle ranching, logging, and (recently) gold mining. Creating RGB color composites is an easy way to visualize ongoing changes in the landscape.\n",
    "\n",
    "Before we get started, let's first **create a working directory for this analysis and change into it:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"/home/jovyan/notebooks/SAR_Training/English/Hazards/data_Ex2-4_S1-MadreDeDios\")\n",
    "\n",
    "if not path.exists():\n",
    "    path.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will **retrieve the relevant data** from an [Amazon Web Service (AWS)](https://aws.amazon.com/) cloud storage bucket **using the following command:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_path = 's3://asf-jupyter-data-west/MadreDeDios.zip'\n",
    "time_series = Path(time_series_path).name\n",
    "!aws --region=us-west-2 --no-sign-request s3 cp $time_series_path $time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's **unzip the file (overwriting previous extractions) and clean up after ourselves:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path(time_series).exists():\n",
    "    asfn.asf_unzip(str(path), time_series)  \n",
    "    Path(time_series).unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Data Directory and Path to VRT\n",
    "\n",
    "**Create a variable containing the VRT filename and the image acquisition dates:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdalbuildvrt -separate {path}/raster_stack.vrt {path}/tiffs/*_VV.tiff\n",
    "image_file_VV = path/\"raster_stack.vrt\"\n",
    "!gdalbuildvrt -separate {path}/raster_stack_VH.vrt {path}/tiffs/*_VH.tiff\n",
    "image_file_VH = path/\"raster_stack_VH.vrt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create an index of timedelta64 data with Pandas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {path}/tiffs/*_VV.tiff | sort | sed 's/[^0-9]*//g' | cut -c 4-11 > {path}/raster_stack_VV.dates\n",
    "datefile_VV = path/'raster_stack_VV.dates'\n",
    "dates_VV = open(str(datefile_VV)).readlines()\n",
    "tindex_VV = pd.DatetimeIndex(dates_VV)\n",
    "\n",
    "!ls {path}/tiffs/*_VH.tiff | sort | sed 's/[^0-9]*//g' | cut -c 4-11 > {path}/raster_stack_VH.dates\n",
    "datefile_VH = path/'raster_stack_VH.dates'\n",
    "dates_VH = open(str(datefile_VH)).readlines()\n",
    "tindex_VH = pd.DatetimeIndex(dates_VH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Assess Image Acquisition Dates\n",
    "\n",
    "Before we start analyzing the available image data, we want to examine the content of our data stack. From the date index, we **make and print a lookup table for band numbers and dates:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stindex=[]\n",
    "for i in [datefile_VV,datefile_VH]:\n",
    "    sdates=open(i).readlines()\n",
    "    stindex.append(pd.DatetimeIndex(sdates))\n",
    "    j=1\n",
    "    print('\\nBands and dates for',str(i).strip('.dates'))\n",
    "    for k in stindex[-1]:\n",
    "        print(\"{:4d} {}\".format(j, k.date()),end=' ')\n",
    "        j+=1\n",
    "        if j%5==1: print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Create Minimum Image to Identify Likely Areas of Deforestation\n",
    "\n",
    "### 4.1 Load Time Series Stack\n",
    "\n",
    "**First, we load the raster stack into memory and calculate the minimum backscatter in the time series:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = gdal.Open(str(image_file_VV))\n",
    "band = img.GetRasterBand(1)\n",
    "raster0 = band.ReadAsArray()\n",
    "band_number = 0 # Needed for updates\n",
    "rasterstack_VV = img.ReadAsArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To **explore the image (number of bands, pixels, lines),** you can use several functions associated with the image object (img) created in the last code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.RasterCount) # Number of Bands\n",
    "print(img.RasterXSize) # Number of Pixels\n",
    "print(img.RasterYSize) # Number of Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following line **calculates the minimum backscatter per pixel** across the time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_mean = np.min(rasterstack_VV, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Visualize the Minimum Image and Select a Coordinate for a Time Series\n",
    "\n",
    "**Write a class to create an interactive plot from which we can select interesting image locations for a time series.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pixelPicker:\n",
    "    def __init__(self, image, width, height):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.fig = plt.figure(figsize=(width, height))\n",
    "        self.ax = self.fig.add_subplot(111, visible=False)\n",
    "        self.rect = patches.Rectangle(\n",
    "            (0.0, 0.0), width, height, \n",
    "            fill=False, clip_on=False, visible=False)\n",
    "        self.rect_patch = self.ax.add_patch(self.rect)\n",
    "        self.cid = self.rect_patch.figure.canvas.mpl_connect('button_press_event', \n",
    "                                                             self)\n",
    "        self.image = image\n",
    "        self.plot = self.gray_plot(self.image, fig=self.fig, return_ax=True)\n",
    "        self.plot.set_title('Select a Point of Interest')\n",
    "        \n",
    "        \n",
    "    def gray_plot(self, image, vmin=None, vmax=None, fig=None, return_ax=False):\n",
    "        '''\n",
    "        Plots an image in grayscale.\n",
    "        Parameters:\n",
    "        - image: 2D array of raster values\n",
    "        - vmin: Minimum value for colormap\n",
    "        - vmax: Maximum value for colormap\n",
    "        - return_ax: Option to return plot axis\n",
    "        '''\n",
    "        if vmin is None:\n",
    "            vmin = np.nanpercentile(self.image, 1)\n",
    "        if vmax is None:\n",
    "            vmax = np.nanpercentile(self.image, 99)\n",
    "        #if fig is None:\n",
    "        #   my_fig = plt.figure() \n",
    "        ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "        ax.imshow(image, cmap=plt.cm.gist_gray, vmin=vmin, vmax=vmax)\n",
    "        if return_ax:\n",
    "            return(ax)\n",
    "        \n",
    "    \n",
    "    def __call__(self, event):\n",
    "        print('click', event)\n",
    "        self.x = event.xdata\n",
    "        self.y = event.ydata\n",
    "        for pnt in self.plot.get_lines():\n",
    "            pnt.remove()\n",
    "        plt.plot(self.x, self.y, 'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to plot the minimum image. **Click a point interest for which you want to analyze radar brightness over time:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large plot of multi-temporal average of VV values to inspect pixel values\n",
    "fig_xsize = 7.5\n",
    "fig_ysize = 7.5\n",
    "my_plot = pixelPicker(db_mean, fig_xsize, fig_ysize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the selected coordinates:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarloc = (ceil(my_plot.x), ceil(my_plot.y))\n",
    "print(sarloc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot SAR Brightness Time Series at Point Locations\n",
    "\n",
    "### 5.1 SAR Brightness Time Series at Point Locations\n",
    "\n",
    "We will pick a pixel location identified in the SAR image above and plot the time series for this identified point. By focusing on image locations undergoing deforestation, we should see the changes in the radar cross section related to the deforestation event.\n",
    "    \n",
    "First, for processing of the imagery in this notebook we **generate a list of image handles and retrieve projection and georeferencing information.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagelist=[image_file_VV, image_file_VH]\n",
    "geotrans=[]\n",
    "proj=[]\n",
    "img_handle=[]\n",
    "xsize=[]\n",
    "ysize=[]\n",
    "bands=[]\n",
    "for i in imagelist:\n",
    "    img_handle.append(gdal.Open(str(i)))\n",
    "    geotrans.append(img_handle[-1].GetGeoTransform())\n",
    "    proj.append(img_handle[-1].GetProjection())\n",
    "    xsize.append(img_handle[-1].RasterXSize)\n",
    "    ysize.append(img_handle[-1].RasterYSize)\n",
    "    bands.append(img_handle[-1].RasterCount)\n",
    "# for i in proj:\n",
    "#     print(i)\n",
    "# for i in geotrans:\n",
    "#     print(i)\n",
    "# for i in zip(['C-VV','C-VH','NDVI','B3','B4','B5'],bands,ysize,xsize):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's **pick a 5x5 image area around a center pixel defined in variable *sarloc*...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_x=geotrans[0][0]+sarloc[0]*geotrans[0][1]\n",
    "ref_y=geotrans[0][3]+sarloc[1]*geotrans[0][5]\n",
    "print('UTM Coordinates      ',ref_x, ref_y)\n",
    "print('SAR pixel/line       ',sarloc[0], sarloc[1])\n",
    "subset_sentinel=(sarloc[0], sarloc[1], 5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and **extract the time series** for this small area around the selected center pixel: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ts=[]\n",
    "for idx in (0, 1):\n",
    "    means=[]\n",
    "    for i in range(bands[idx]):\n",
    "        rs=img_handle[idx].GetRasterBand(i+1).ReadAsArray(*subset_sentinel)\n",
    "        rs_means_pwr = np.mean(rs)\n",
    "        rs_means_dB = 10.*np.log10(rs_means_pwr)\n",
    "        means.append(rs_means_dB)\n",
    "    s_ts.append(pd.Series(means,index=stindex[idx]))\n",
    "        \n",
    "means = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the extracted time series** for VV and VH polarizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "\n",
    "s_ts[0].plot(ax=ax, color='red', label='C-VV')#,xlim=(min(min(stindex),min(stindex[0])),\n",
    "                                             #     max(max(stindex),max(stindex[0]))))\n",
    "s_ts[1].plot(ax=ax, color='blue', label='C-VH')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Sentinel-1 $\\gamma^o$ [dB]')\n",
    "\n",
    "ax.set_title('Sentinel-1 Backscatter')\n",
    "plt.grid()\n",
    "_ = ax.legend(loc='best')\n",
    "_ = fig.suptitle('Time Series Profiles of Sentinel-1 SAR Backscatter')\n",
    "figname = f\"RCSTimeSeries-{ref_x:.0f}_{ref_y:.0f}.png\"\n",
    "plt.savefig(path/figname, dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>EXERCISE</u>:  </font> Explore Time Series at Different Point Locations </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Explore this data set some more by picking different point coordinates to explore. Use the time series animation together with the minimum plot to identify interesting areas and explore the radar brightness history. Discuss with your colleagues what you find.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise3B-ExploreSARTimeSeriesDeforestation.ipynb - Version 1.7.0 - November 2021*\n",
    "\n",
    "*Version Changes*\n",
    "\n",
    "- *asf_notebook -> opensarlab-lib*\n",
    "- *url_widget*\n",
    "- *html -> markdown*\n",
    "- *%matplotlib widget*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtc_analysis [conda env:.local-rtc_analysis]",
   "language": "python",
   "name": "conda-env-.local-rtc_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
