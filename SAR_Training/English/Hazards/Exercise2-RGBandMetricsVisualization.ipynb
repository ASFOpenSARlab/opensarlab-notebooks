{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "<img src=\"NotebookAddons/blackboard-banner.png\" width=\"100%\" />\n",
    "<font face=\"Calibri\">\n",
    "<br>\n",
    "<font size=\"5\"> <b>Exploring RGB Visualzations of SAR and Deriving SAR Time Series Metrics</b></font>\n",
    "\n",
    "<br>\n",
    "<font size=\"4\"> <b> Franz J Meyer; University of Alaska Fairbanks & Josef Kellndorfer, <a href=\"http://earthbigdata.com/\" target=\"_blank\">Earth Big Data, LLC</a> </b> <br>\n",
    "<img style=\"padding:7px;\" src=\"NotebookAddons/UAFLogo_A_647.png\" width=\"170\" align=\"right\" /></font>\n",
    "\n",
    "<font size=\"3\">This notebook introduces you to some popular RGB visualizations of multi-temporal and multi-polarization SAR data. The exercise is done in the framework of *Jupyter Notebooks*. The Jupyter Notebook environment is easy to launch in any web browser for interactive data exploration with provided or new training data. Notebooks are comprised of text written in a combination of executable python code and markdown formatting including latex style mathematical equations. Another advantage of Jupyter Notebooks is that they can easily be expanded, changed, and shared with new data sets or newly available time series steps. Therefore, they provide an excellent basis for collaborative and repeatable data analysis. <br>\n",
    "\n",
    "<b>This notebook covers the following data analysis concepts:</b>\n",
    "\n",
    "- How to create RGB visualizations of multi-temporal SAR data\n",
    "- How to interprete these RGB images\n",
    "- Popular RGB visualizations of dual-polarization SAR data\n",
    "- How do derive time-series metrics from deep SAR data stacks\n",
    "- How to export RGB products as GeoTiffs for visualization in a GIS\n",
    "</font>\n",
    "\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"5\" color='rgba(200,0,0,0.2)'> <b>Important Note about JupyterHub</b> </font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"> <b>Your JupyterHub server will automatically shutdown when left idle for more than 1 hour. Your notebooks will not be lost but you will have to restart their kernels and re-run them from the beginning. You will not be able to seamlessly continue running a partially run notebook.</b> </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "\n",
    "env = !echo $CONDA_PREFIX\n",
    "if env[0] == '':\n",
    "    env[0] = 'Python 3 (base)'\n",
    "if env[0] != '/home/jovyan/.local/envs/rtc_analysis':\n",
    "    display(Markdown(f'<text style=color:red><strong>WARNING:</strong></text>'))\n",
    "    display(Markdown(f'<text style=color:red>This notebook should be run using the \"rtc_analysis\" conda environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>It is currently using the \"{env[0].split(\"/\")[-1]}\" environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Select the \"rtc_analysis\" from the \"Change Kernel\" submenu of the \"Kernel\" menu.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>If the \"rtc_analysis\" environment is not present, use Create_OSL_Conda_Environments.ipynb to create it.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Note that you must restart your server after creating a new environment before it is usable by notebooks.</text>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\">\n",
    "\n",
    "<font size=\"5\"> <b> 0. Importing Relevant Python Packages </b> </font>\n",
    "\n",
    "<font size=\"3\">In this notebook we will use the following scientific libraries:\n",
    "<ol type=\"1\">\n",
    "    <li> <b><a href=\"https://pandas.pydata.org/\" target=\"_blank\">Pandas</a></b> is a Python library that provides high-level data structures and a vast variety of tools for analysis. The great feature of this package is the ability to translate rather complex operations with data into one or two commands. Pandas contains many built-in methods for filtering and combining data, as well as the time-series functionality. </li>\n",
    "    <li> <b><a href=\"https://www.gdal.org/\" target=\"_blank\">GDAL</a></b> is a software library for reading and writing raster and vector geospatial data formats. It includes a collection of programs tailored for geospatial data processing. Most modern GIS systems (such as ArcGIS or QGIS) use GDAL in the background.</li>\n",
    "    <li> <b><a href=\"http://www.numpy.org/\" target=\"_blank\">NumPy</a></b> is one of the principal packages for scientific applications of Python. It is intended for processing large multidimensional arrays and matrices, and an extensive collection of high-level mathematical functions and implemented methods makes it possible to perform various operations with these objects. </li>\n",
    "    <li> <b><a href=\"https://matplotlib.org/index.html\" target=\"_blank\">Matplotlib</a></b> is a low-level library for creating two-dimensional diagrams and graphs. With its help, you can build diverse charts, from histograms and scatterplots to non-Cartesian coordinates graphs. Moreover, many popular plotting libraries are designed to work in conjunction with matplotlib. </li>\n",
    "   \n",
    "</font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Our first step is to <b>import them:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import os # for chdir, getcwd, path.exists\n",
    "\n",
    "import pandas as pd # for DatetimeIndex\n",
    "from osgeo import gdal # for Info\n",
    "import numpy as np # for copy, isnan, log10, ma.masked_where, max, mean, min, percentile, power, unique, var, where \n",
    "from skimage import exposure # to enhance image display\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plb # for figure, grid, rcParams, savefig\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from matplotlib import rc\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "import asf_notebook as asfn\n",
    "asfn.jupytertheme_matplotlib_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\">\n",
    "\n",
    "<font size=\"5\"> <b> 1. Load Data Stack</b> </font> <img src=\"NotebookAddons/Deforest-MadreDeDios.jpg\" width=\"350\" style=\"padding:7px;\" align=\"right\" /> \n",
    "\n",
    "<font size=\"3\"> This notebook will be using a 78-image deep dual-polarization C-band SAR data stack over Madre de Dios in Peru to demonstrate how to create color composites from multi temporal and dual-polarization SAR data and how to derive higher level parameters such as the multi-temporal mean, the coefficient of variation, and others. The C-band data were acquired by ESA's Sentinel-1 SAR sensor constellation and are available to you through the services of the <a href=\"https://www.asf.alaska.edu/\" target=\"_blank\">Alaska Satellite Facility</a>. \n",
    "\n",
    "The site in question is interesting as it has experienced extensive logging over the last 10 years (see image to the right; <a href=\"https://blog.globalforestwatch.org/\" target=\"_blank\">Monitoring of the Andean Amazon Project</a>). Since the 1980s, people have been clearing forests in this area for farming, cattle ranching, logging, and (recently) gold mining. Creating RGB color composites is an easy way to visualize ongoing changes in the landscape.\n",
    "</font></font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\">Before we get started, let's first <b>create a working directory for this analysis and change into it:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/jovyan/notebooks/SAR_Training/English/Hazards/data_Ex2-4_S1-MadreDeDios\"\n",
    "asfn.new_directory(path)\n",
    "os.chdir(path)\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">We will <b>retrieve the relevant data</b> from an <a href=\"https://aws.amazon.com/\" target=\"_blank\">Amazon Web Service (AWS)</a> cloud storage bucket <b>using the following command</b>:</font></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_path = 's3://asf-jupyter-data/MadreDeDios.zip'\n",
    "time_series = os.path.basename(time_series_path)\n",
    "!aws --region=us-east-1 --no-sign-request s3 cp $time_series_path $time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"> Now, let's <b>unzip the file (overwriting previous extractions) and clean up after ourselves:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if asfn.path_exists(time_series):\n",
    "    asfn.asf_unzip(os.getcwd(), time_series)\n",
    "    os.remove(time_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"5\"> <b> 2. Define Data Directory and Path to VRT </b> </font> \n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>Create a variable containing the VRT filename and the image acquisition dates:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdalbuildvrt -separate raster_stack.vrt tiffs/*_VV.tiff\n",
    "image_file_VV = \"raster_stack.vrt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create an index of timedelta64 data with Pandas:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls tiffs/*_VV.tiff | sort | cut -c 7-21 > raster_stack_VV.dates\n",
    "datefile_VV = 'raster_stack_VV.dates'\n",
    "dates_VV = open(datefile_VV).readlines()\n",
    "tindex_VV = pd.DatetimeIndex(dates_VV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Print the bands and dates for all images in the virtual raster table (VRT):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Bands and dates for {image_file_VV}\")\n",
    "for i, d in enumerate(tindex_VV):\n",
    "    print(\"{:4d} {}\".format(i+1, d.date()), end=' ')\n",
    "    if (i+1)%5 == 1:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>\n",
    "<font face=\"Calibri\" size=\"5\"> <b> 3. Open Your Data Stack and Visualize Some Layers </b> </font> \n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> We will <b>open your VRT</b> and visualize some layers using Matplotlib. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = gdal.Open(image_file_VV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Print the bands, pixels, and lines:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of  bands: {img.RasterCount}\")\n",
    "print(f\"Number of pixels: {img.RasterXSize}\")\n",
    "print(f\"Number of  lines: {img.RasterYSize}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Read in raster data for the first two bands:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_1 = img.GetRasterBand(1).ReadAsArray() # change the number passed to GetRasterBand() to \n",
    "where_are_NaNs = np.isnan(raster_1)           # read rasters from different bands\n",
    "raster_1[where_are_NaNs] = 0\n",
    "\n",
    "raster_2 = img.GetRasterBand(78).ReadAsArray() #must pass a valid band number to GetRasterBand()\n",
    "where_are_NaNs = np.isnan(raster_2)\n",
    "raster_2[where_are_NaNs] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Plot images and histograms for bands 1 and 2:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the pyplot plots\n",
    "fig = plb.figure(figsize=(18, 16)) # Initialize figure with a size\n",
    "ax1 = fig.add_subplot(221)  # 221 determines: 2 rows, 2 plots, first plot\n",
    "ax2 = fig.add_subplot(222)  # 222 determines: 2 rows, 2 plots, second plot\n",
    "ax3 = fig.add_subplot(223)  # 223 determines: 2 rows, 2 plots, third plot\n",
    "ax4 = fig.add_subplot(224)  # 224 determines: 2 rows, 2 plots, fourth plot\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "# Plot the band 1 image\n",
    "band_number = 1\n",
    "ax1.imshow(raster_1, cmap='gray', vmin=0, vmax=0.3) \n",
    "ax1.set_title('Image Band {} {}'.format(band_number, tindex_VV[band_number-1].date()))\n",
    "\n",
    "# Flatten the band 1 image into a 1 dimensional vector and plot the histogram:\n",
    "h = ax2.hist(raster_1.flatten(), bins=200, range=(0, 0.3))\n",
    "ax2.xaxis.set_label_text('Calibrated Radar Cross Section (RCS) [Power Scale]')\n",
    "ax2.set_title('Histogram Band {} {}'.format(band_number, tindex_VV[band_number-1].date()))\n",
    "\n",
    "# Plot the band 2 image\n",
    "band_number = 78\n",
    "ax3.imshow(raster_2, cmap='gray', vmin=0, vmax=0.3)\n",
    "ax3.set_title('Image Band {} {}'.format(band_number, tindex_VV[band_number-1].date()))\n",
    "\n",
    "# Flatten the band 2 image into a 1 dimensional vector and plot the histogram:\n",
    "h = ax4.hist(raster_2.flatten(), bins=200, range=(0, 0.3))\n",
    "ax4.xaxis.set_label_text('Calibrated Radar Cross Section (RCS) [Power Scale]')\n",
    "ax4.set_title('Histogram Band {} {}'.format(band_number, tindex_VV[band_number-1].date()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>\n",
    "<font face=\"Calibri\" size=\"5\"> <b> 4. Create a Time Series Animation to get an Idea of the Dynamics at the Site </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 4.1 Load Time Series Stack </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\">Now we are ready to create a time series animation from the calibrated SAR data.\n",
    "<br><br>\n",
    "<b>First, create a raster from band 0 and a raster stack from all the images:</b>\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band = img.GetRasterBand(1)\n",
    "raster0 = band.ReadAsArray()\n",
    "band_number = 0 # Needed for updates\n",
    "rasterstack_VV = img.ReadAsArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 4.2 Create Time Series Animation </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"><b>Create and move into a directory in which to store our plots and animations:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path)\n",
    "product_path = 'plots_and_animations'\n",
    "asfn.new_directory(product_path)\n",
    "if asfn.path_exists(product_path) and os.getcwd() != f\"{path}/{product_path}\":\n",
    "    os.chdir(product_path)\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.subplots()\n",
    "ax.axis('off')\n",
    "vmin = np.percentile(rasterstack_VV.flatten(), 5)\n",
    "vmax = np.percentile(rasterstack_VV.flatten(), 95)\n",
    "\n",
    "im = ax.imshow(raster0, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "ax.set_title(\"{}\".format(tindex_VV[0].date()))\n",
    "\n",
    "def animate(i):\n",
    "    ax.set_title(\"{}\".format(tindex_VV[i].date()))\n",
    "    im.set_data(rasterstack_VV[i])\n",
    "\n",
    "# Interval is given in milliseconds\n",
    "ani = animation.FuncAnimation(fig, animate, frames=rasterstack_VV.shape[0], interval=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Configure matplotlib's RC settings for the animation:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc('animation', embed_limit=40971520.0)  # We need to increase the limit maybe to show the entire animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create a javascript animation of the time-series running inline in the notebook:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Delete the dummy png</b> that was saved to the current working directory while generating the javascript animation in the last code cell.</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove('None0000000.png')\n",
    "except FileNotFoundError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Save the animation (animation.gif):</b> </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.save('animation.gif', writer='pillow', fps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>\n",
    "<font face=\"Calibri\" size=\"5\"> <b> 5. Create RGB Visualization from Multi-Temporal SAR Images</b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\">Now we are ready to create our first RGB visualization. We will pick images from different dates/times/years to form an RGB. The colors in the RGB will then provide information on changes that occurred during the time span covered by the data.\n",
    "<br><br>\n",
    "<b>First, we mask out pixels without relevant information to be unbiased in statical number we calculate later:</b>\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = rasterstack_VV == 0\n",
    "rasterPwr = np.ma.array(rasterstack_VV, mask=mask, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"3\">We make an RGB stack to display the first, center, and last time step of our available stack as a multi-temporal color composite. The np.dstack results in an array of the form [lines,pixels,bands], which is the format we need for RGB display with matplotlib's imshow() function. Note that numpy array indexing starts with 0, so band 1 is raster[0].</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_bands = (1, int(img.RasterCount/2), img.RasterCount)  # first, center, last band\n",
    "\n",
    "rgb_idx = np.array(rgb_bands)-1  # get array index from bands by subtracting 1\n",
    "\n",
    "rgb = np.dstack((rasterPwr[rgb_idx[0]], \n",
    "                 rasterPwr[rgb_idx[1]], \n",
    "                 rasterPwr[rgb_idx[2]]))\n",
    "\n",
    "rgb_dates = (tindex_VV[rgb_idx[0]].date(),\n",
    "             tindex_VV[rgb_idx[1]].date(), \n",
    "             tindex_VV[rgb_idx[2]].date())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"3\">We are also interested in displaying the image enhanced with histogram equalization. We can use the function exposure.equalize_hist() from the skimage.exposure module.</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_stretched = rgb.copy()\n",
    "# For each band we apply the strech\n",
    "for i in range(rgb_stretched.shape[2]):\n",
    "    rgb_stretched[:,:,i] = exposure.\\\n",
    "    equalize_hist(rgb_stretched[:,:,i].data,\n",
    "    mask =~ np.equal(rgb_stretched[:,:,i].data,0.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"3\">Now let's <b>display the the unstrechted and histogram equalized images side by side.</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "fig.suptitle('Multi-temporal Sentinel-1 backscatter image R:{} G:{} B:{}'\n",
    "             .format(rgb_dates[0],rgb_dates[1],rgb_dates[2]))\n",
    "plt.axis('off')\n",
    "ax[0].imshow(rgb)\n",
    "ax[0].set_title('Unstreched')\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(rgb_stretched)\n",
    "ax[1].set_title('Histogram Equalized')\n",
    "_ = ax[1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>EXERCISE</u>:  </font> Pick Different Time Steps and Interpret Resulting RGB Visualization </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> To get a feeling for the RGB visualizations, please explore the 78 image deep data stack a bit more. Pick different mutli-temporal image layers and form more RGB visualizations. Interpret the colors you see in terms of the change that likely occurred on the ground.\n",
    "</font>\n",
    "</div>\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">Ideally, you may want to analyze these images in a GIS framework, where you can combine the SAR RGBs with other relevant data layers. To do so, we will export <font color='rgba(200,0,0,0.2)'><b>your favorite multi-temporal RGB image</b></font> as a GeoTiff. First, we <b>write a function to convert our plots into GeoTiffs:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vrt = gdal.Open(f\"{path}/{image_file_VV}\")\n",
    "vrt_info = gdal.Info(vrt, format='json')\n",
    "coords = [vrt_info['cornerCoordinates']['upperLeft'], \n",
    "          vrt_info['cornerCoordinates']['lowerRight']]\n",
    "print(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utm_zone = vrt_info['coordinateSystem']['wkt'].split('EPSG\",')[-1][0:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not include a file extension in out_filename\n",
    "# extent must be in the form of a list: [[upper_left_x, upper_left_y], [lower_right_x, lower_right_y]]\n",
    "def geotiff_from_plot(source_image, out_filename, extent, utm_zone, cmap=None, vmin=None, vmax=None, interpolation=None, dpi=300):\n",
    "    plt.figure()\n",
    "    plt.axis('off')\n",
    "    plt.imshow(source_image, cmap=cmap, vmin=vmin, vmax=vmax, interpolation=interpolation)\n",
    "    temp = f\"{out_filename}_temp.png\"\n",
    "    plt.savefig(temp, dpi=dpi, transparent='true', bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "    cmd = f\"gdal_translate -of Gtiff -a_ullr {extent[0][0]} {extent[0][1]} {extent[1][0]} {extent[1][1]} -a_srs EPSG:{utm_zone} {temp} {out_filename}.tiff\"\n",
    "    !{cmd}\n",
    "    try:\n",
    "        os.remove(temp)\n",
    "    except FileNotFoundError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Now we can save your last RGB image as a GeoTIFF (MadreDeDios-RGB.tiff):</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(rgb_stretched, 'MadreDeDios-multitemp-RGB', coords, utm_zone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>\n",
    "<font face=\"Calibri\" size=\"5\"> <b> 6. Create RGB Visualization from Dual-Pol SAR Images</b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\">Now let's demonstrate another popular RGB visualization, one that is particularly useful for dual-pol SAR data such as Sentinel-1. The color composites are constructed with co-polarized (VV-channel) data assigned to the red channel, cross-polarized (VH) data to the green channel, and the co-/cross-polarized ratio (VV/VH ratio) to the blue channel. A nice effect for forest applications with this color assignment strategy is that forests tend to be shown in shades of green, and typically the brightness of green corresponds to the amount of biomass in the forest. Also, water tends to be represented in blue colors, which also represents other surface scattering components. Naturally, different histogram stretches may be applied to enhance various surface components.\n",
    "<br><br>\n",
    "<b>To create this visualization, we first need to load the cross-polarized VH data into the notebook:</b>\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path)\n",
    "!gdalbuildvrt -separate raster_stack_VH.vrt tiffs/*_VH.tiff\n",
    "image_file_VH = \"raster_stack_VH.vrt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls tiffs/*_VH.tiff | sort | cut -c 7-21 > raster_stack_VH.dates\n",
    "datefile_VH = 'raster_stack_VH.dates'\n",
    "dates_VH = open(datefile_VH).readlines()\n",
    "tindex_VH = pd.DatetimeIndex(dates_VH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if asfn.path_exists(image_file_VH):\n",
    "    print(f\"Bands and dates for {image_file_VH}\")\n",
    "    for i, d in enumerate(tindex_VH):\n",
    "        print(\"{:4d} {}\".format(i+1, d.date()),end=' ')\n",
    "        if (i+1)%5 == 1: print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Now we load the VH data stack and prepare it for visualization:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_VH = gdal.Open(image_file_VH)\n",
    "band_VH = img_VH.GetRasterBand(1)\n",
    "raster0_VH = band_VH.ReadAsArray()\n",
    "band_number = 0 # Needed for updates\n",
    "rasterstack_VH = img_VH.ReadAsArray()\n",
    "mask = rasterstack_VH == 0\n",
    "rasterPwr_VH = np.ma.array(rasterstack_VH, mask=mask, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b><font color='rgba(200,0,0,0.2)'>Pick a band number</font> you would like to visualize:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick a band number for visualization\n",
    "bandno = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Now we can create an RGB image using the mentioned color assignments (R: VV; G: VH; B: VV/VH), color stretch the RGB, and visualize it:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_band = (bandno, bandno, bandno)  # first, center, last band\n",
    "rgb_idx = np.array(rgb_bands)-1  # get array index from bands by subtracting 1\n",
    "rgb = np.dstack((rasterPwr[rgb_idx[0]], rasterPwr_VH[rgb_idx[0]], rasterPwr[rgb_idx[0]]/rasterPwr_VH[rgb_idx[0]]))\n",
    "rgb_date = (tindex_VH[rgb_idx[0]].date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_stretched_POL = rgb.copy()\n",
    "# For each band we apply the strech\n",
    "for i in range(rgb_stretched_POL.shape[2]):\n",
    "    rgb_stretched_POL[:,:,i] = exposure.\\\n",
    "    equalize_hist(rgb_stretched_POL[:,:,i].data,\n",
    "    mask =~ np.equal(rgb_stretched_POL[:,:,i].data,0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plb.figure(figsize=(16, 16)) # Initialize figure with a size\n",
    "ax1 = fig.add_subplot(221)  # 221 determines: 2 rows, 2 plots, first plot\n",
    "ax2 = fig.add_subplot(222)  # 222 determines: 2 rows, 2 plots, second plot\n",
    "ax3 = fig.add_subplot(223)  # 223 determines: 2 rows, 2 plots, third plot\n",
    "ax4 = fig.add_subplot(224)  # 224 determines: 2 rows, 2 plots, fourth plot\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "# Plot the VV band\n",
    "r_1 = img.GetRasterBand(bandno).ReadAsArray()\n",
    "vmin = np.percentile(r_1.flatten(), 5)\n",
    "vmax = np.percentile(r_1.flatten(), 95)\n",
    "ax1.imshow(r_1, cmap='gray', vmin=vmin, vmax=vmax) \n",
    "ax1.set_title('VV Channel')\n",
    "ax1.axis('off')\n",
    "\n",
    "# Plot the VH band\n",
    "r_1 = img_VH.GetRasterBand(bandno).ReadAsArray()\n",
    "vmin = np.percentile(r_1.flatten(), 5)\n",
    "vmax = np.percentile(r_1.flatten(), 95)\n",
    "ax2.imshow(r_1, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "ax2.set_title('VH Channel')\n",
    "ax2.axis('off')\n",
    "\n",
    "# Plot the VV/VH band\n",
    "r_1 = img.GetRasterBand(bandno).ReadAsArray()/img_VH.GetRasterBand(bandno).ReadAsArray()\n",
    "vmin = np.percentile(r_1.flatten(), 5)\n",
    "vmax = np.percentile(r_1.flatten(), 95)\n",
    "ax3.imshow(r_1, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "ax3.set_title('VV/VH Ratio Channel')\n",
    "ax3.axis('off')\n",
    "\n",
    "# Plot the RGB Composite band\n",
    "ax4.imshow(rgb_stretched_POL)\n",
    "ax4.set_title('Color Composite')\n",
    "ax4.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">We will again <b>export the RGB composite as a GeoTiff to allow further analysis in your favorite GIS environment:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(rgb_stretched_POL, 'plots_and_animations/MadreDeDios-multipol-RGB', coords, utm_zone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>EXERCISE</u>:  </font> Pick Different Time Steps and Interpret Resulting Dual-Pol RGB Images </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Explore the 78 image deep data stack a bit more. Pick different time steps in the data stack and create additional RGB composites. You may see interesting changes in the color patterns. Answer the following questions for yourself:\n",
    "\n",
    "<ul>\n",
    "  <li>What are the green areas and what are different shades of green mean?</li>\n",
    "  <li>Why is there fewer green in the visualization than you might have expected?</li>\n",
    "  <li>What are the blue-shaded regions?</li>\n",
    "  <li>What kind of differences in color patterns do you see between different time steps? What might be the reasons for these changes?</li>\n",
    "</ul>\n",
    "\n",
    "</font>\n",
    "</div>\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<font face=\"Calibri\" size=\"5\"> <b> 7. Plot the Time Series of Means Calculated Across the Subset </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> To create the time series of means, we will go through the following steps:\n",
    "1. Ensure that you use the data in **power scale** ($\\gamma^o_{pwr}$) for your mean calculations.\n",
    "2. compute means.\n",
    "3. convert the resulting mean values into dB scale for visualization.\n",
    "4. plot time series of means. </font> \n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"> <b>Compute the means:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_means_pwr_VH = np.mean(rasterPwr_VH, axis=(1, 2))\n",
    "rs_means_pwr_VV = np.mean(rasterPwr, axis=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Convert resulting mean value time-series to dB scale for visualization:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_means_dB_VH = 10.*np.log10(rs_means_pwr_VH)\n",
    "rs_means_dB_VV = 10.*np.log10(rs_means_pwr_VV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Plot and save the time series of means (RCSoverTime.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Now let's plot the time series of means\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(tindex_VV, rs_means_dB_VV)\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('VV Channel $\\overline{\\gamma^o}$ [dB]')\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(tindex_VH, rs_means_dB_VH, color='red')\n",
    "ax2.set_ylabel('VH Channel $\\overline{\\gamma^o}$ [dB]')\n",
    "#fig.legend(['VV Channel', 'VH Channel'], loc=1)\n",
    "fig.legend(['VV Channel', 'VH Channel'], loc=3, bbox_to_anchor=(0.07, 0.18))\n",
    "plt.title('Time series profile of average band backscatter $\\gamma^o$ ')\n",
    "plt.savefig('time_series_means', dpi=72, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>\n",
    "<font face=\"Calibri\" size=\"5\"> <b> 8. Computation and Visualization of Time Series Metrics</b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\">Once a time-series was constructed, we can compute <b>a set of metrics</b> that will aid us later in applications such as <i>change detection and active agriculture detection</i>. In the next code cells, we will compute the following variables for each pixel in the stack:\n",
    "\n",
    "- Mean \n",
    "- Median\n",
    "- Maximum\n",
    "- Minimum\n",
    "- Range (Maximum - Minimum)\n",
    "- 5th Percentile\n",
    "- 95th Percentile\n",
    "- PRange (95th - 5th Percentile)\n",
    "- Variance\n",
    "- Coefficient of Variation (Variance/Mean)\n",
    "\n",
    "<hr>\n",
    "Let's first <b>define a function for calculating the intended time-series metrics</b>:\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_metrics(raster, ndv=0): \n",
    "    # Make use of numpy nan functions\n",
    "    # Check if type is a float array\n",
    "    if not raster.dtype.name.find('float') > -1:\n",
    "        raster = raster.astype(np.float32)\n",
    "    # Set ndv to nan\n",
    "    if ndv != np.nan:\n",
    "        raster[np.equal(raster,ndv)] = np.nan\n",
    "    # Build dictionary of the metrics\n",
    "    tsmetrics = {}\n",
    "    rperc = np.nanpercentile(raster, [5, 50, 95], axis=0)\n",
    "    tsmetrics['mean'] = np.nanmean(raster, axis=0)\n",
    "    tsmetrics['max'] = np.nanmax(raster, axis=0)\n",
    "    tsmetrics['min'] = np.nanmin(raster, axis=0)\n",
    "    tsmetrics['range'] = tsmetrics['max'] - tsmetrics['min']\n",
    "    tsmetrics['median'] = rperc[1]\n",
    "    tsmetrics['p5'] = rperc[0]\n",
    "    tsmetrics['p95'] = rperc[2]\n",
    "    tsmetrics['prange'] = rperc[2] - rperc[0]\n",
    "    tsmetrics['var'] = np.nanvar(raster, axis=0)\n",
    "    tsmetrics['CV'] = tsmetrics['var'] / tsmetrics['mean']\n",
    "    return tsmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = timeseries_metrics(rasterPwr.filled(np.nan), ndv=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_keys = list(metrics.keys())\n",
    "print(metric_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">Let's look at the histograms for the time series variance and coeficient of variation to aid displaying those images:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 4))\n",
    "ax[0].hist(metrics['var'].flatten(), bins=100, range=(0, 0.001))\n",
    "ax[1].hist(metrics['CV'].flatten(), bins=100, range=(0, 0.01))\n",
    "_ = ax[0].set_title('Variance')\n",
    "_ = ax[1].set_title('Coefficient of Variation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">We use thresholds determined from those histograms to set the scaling in the time series visualization. For the backscatter metrics we choose a typical range appropriate for this ecosystem and radar sensor. A typical range is -30 dB (0.0001) to -5.2 dB (0.3).</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# List the metrics keys you want to plot\n",
    "fig = plt.figure(figsize=(16, 40))\n",
    "for i, key in enumerate(metric_keys):\n",
    "    ax = fig.add_subplot(5, 2, i+1)\n",
    "    if key == 'var': \n",
    "        vmin, vmax = (0.0, 0.001)\n",
    "    elif key == 'CV':\n",
    "        vmin, vmax = (0.0, 0.004)\n",
    "    else:\n",
    "        vmin, vmax = (0.0001, 0.3)\n",
    "    ax.imshow(metrics[key], vmin=vmin, vmax=vmax, cmap='gray')\n",
    "    ax.set_title(key.upper())\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">We will again <b>export the RGB composite as a GeoTiff to allow further analysis in your favorite GIS environment:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "Names = [] # List to keep track of all the names\n",
    "for i in metric_keys:\n",
    "    # Name, Array, DataType, NDV,bandnames=None,ref_image\n",
    "    Name = os.path.join(path, f'plots_and_animations/MadreDeDios-'+i)\n",
    "    print(Name)\n",
    "    if i == 'var': \n",
    "        vmin, vmax = (0.0, 0.001)\n",
    "    elif i == 'CV': \n",
    "        vmin, vmax = (0.0, 0.004)\n",
    "    else:\n",
    "        vmin, vmax = (0.0001, 0.3)\n",
    "    geotiff_from_plot(metrics[i], Name, coords, utm_zone, cmap='gray', vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>\n",
    "<font face=\"Calibri\" size=\"5\"> <b> 8. Conclusion</b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\">RGB Visualizations can be a powerful tool to visually analyze multi-temporal or multi-polarization SAR images. For multi-temporal data, the different color bands of an RGB composite relate to different time steps; hence, color tones represent changes of the landscape over time. \n",
    "    \n",
    "For multi-polarization data, the RGB representation gives some indication of the type of surface cover present in an area. Areas shown in green in these composites usually are areas of high biomass while areas in blue are often regions covered in water. \n",
    "\n",
    "Please use caution when interpreting multi-polarization composites made from Sentinel-1 dual-pol data. As Sentinel-1 does not penetrate deep into vegetation, the composites often are not a correct representation of biomass in an area (composites don't look as green as they should).  \n",
    "\n",
    "For a bit more information on change detection and SAR in general, please look at the recently published <a href=\"https://gis1.servirglobal.net/TrainingMaterials/SAR/SARHB_FullRes.pdf\" target=\"_blank\">SAR Handbook: Comprehensive Methodologies for Forest Monitoring and Biomass Estimation</a>.\n",
    "</font> \n",
    "<hr>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"2\"> <i>Exercise2-RGBandMetricsVisualization.ipynb - Version 1.4.0 - April 2021 </i>\n",
    "    <br>\n",
    "    <b>Version Changes</b>\n",
    "    <ul>\n",
    "        <li>namespace asf_notebook</li>\n",
    "    </ul>\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtc_analysis",
   "language": "python",
   "name": "rtc_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
