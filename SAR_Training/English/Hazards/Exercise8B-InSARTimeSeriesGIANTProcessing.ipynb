{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![OpenSARlab notebook banner](NotebookAddons/blackboard-banner.png)\n",
    "\n",
    "# Exercise8B-InSARTimeSeriesGIANTProcessing\n",
    "\n",
    "<img style=\"padding: 7px\" src=\"NotebookAddons/UAFLogo_A_647.png\" width=\"170\" align=\"right\" />\n",
    "\n",
    "### Franz J Meyer & Joshua J C Knicely; University of Alaska Fairbanks\n",
    "\n",
    "The primary goal of this lab is to demonstrate how to process InSAR data, specifically interferograms, using the Generic InSAR Analysis Toolbox ([GIAnT](http://earthdef.caltech.edu/projects/giant/wiki)) in the framework of *Jupyter Notebooks*. GIAnT takes multiple connected InSAR-based surface deformation measurements as input and estimates the deformation time series relative to the first acquisition time.\n",
    "\n",
    "**Our specific objectives for this lab are to:**\n",
    "\n",
    "- Learn how to prepare data for GIAnT. \n",
    "- Use GIAnT to create maps of surface deformation. \n",
    "\n",
    "<img style=\"padding:7px;\" src=\"NotebookAddons/OpenSARlab_logo.svg\" width=\"170\" align=\"right\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<font face=\"Calibri\">\n",
    "<img style=\"padding: 7px\" src=\"NotebookAddons/sierranegra.jpg\"  width=300  align=\"right\"><font size=\"5\"> <b> Volcanic deformation: Sierra Negra, Gal√°pagos Islands </b> </font> <br>\n",
    "\n",
    "<font size=\"3\"> We will use time series of InSAR data to analyze surface deformation at Sierra Negra, a highly active shield volcano in the Galapagos Islands. It is located in the south of Isabela Island, approximately 40 km west of Cerro Azul, which we studied in the previous lab.\n",
    "    \n",
    "The most recent eruption occurred from 26 June to 23 August 2018. We will be looking at the deformation before and during the eruption (picture by Benjamin Ayala), using Sentinel-1 data.\n",
    "<br><br>\n",
    "\n",
    "Over the course of more than two months, <a href=\"https://volcano.si.edu/volcano.cfm?vn=353050&vtab=Weekly\">multiple fissures opened</a>. Lava that emerged from the fissures covered several tens of square kilometers. One lava flow reached the coastline on 6 July. \n",
    "<br><br>\n",
    "</font>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Overview\n",
    "\n",
    "**About GIAnT:**\n",
    "\n",
    "GIAnT is a Python framework for performing InSAR time series analysis. It is capable of performing several types of Small BAseline Subset (SBAS) processing workflows. It also includes simple filtering approaches for separating deformation from tropospheric phase contributions.\n",
    "\n",
    "**Limitations:**\n",
    "\n",
    "GIAnT has a number of limitations that are important to keep in mind as these can affect its effectiveness for certain applications. It implements the simplest time-series inversion methods. Its single coherence threshold is very conservative in terms of pixel selection. It does not include any consistency checks for unwrapping errors. It has a limited dictionary of temporal model functions. It has limited capabilities for removing tropospheric errors.\n",
    "\n",
    "**Using GIAnT:**\n",
    "\n",
    "GIAnT requires very specific input. Because of the input requirements, the majority of one's effort goes to getting the data into a form that GIAnT can manipulate and to creating files that tell GIAnT what to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>GIAnT processing steps</b>\n",
    "                            \n",
    "   1. Prepare Data: Process interferograms and convert to GIAnT-friendly format<br><br>\n",
    "   2. Run GIAnT to estimate deformation and mitigate atmospheric impacts<br><br>\n",
    "   3. Data visualization and interpretation\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will focus on the actual processing and visualization. The preparation steps have been completed for you in order to save disk space and computation time. The code to create the preparatory files has been included in the Exercise8A-InSARTimeSeriesGIAnTPreparation notebook. More information about GIAnT can be found here: http://earthdef.caltech.edu/projects/giant/wiki.\n",
    "\n",
    "**Important Note about JupyterHub**\n",
    "\n",
    "Your JupyterHub server will automatically shutdown when left idle for more than 1 hour. Your notebooks will not be lost but you will have to restart their kernels and re-run them from the beginning. You will not be able to seamlessly continue running a partially run notebook.</b> </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import url_widget as url_w\n",
    "notebookUrl = url_w.URLWidget()\n",
    "display(notebookUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "\n",
    "notebookUrl = notebookUrl.value\n",
    "user = !echo $JUPYTERHUB_USER\n",
    "env = !echo $CONDA_PREFIX\n",
    "if env[0] == '':\n",
    "    env[0] = 'Python 3 (base)'\n",
    "if env[0] != '/home/jovyan/.local/envs/insar_analysis':\n",
    "    display(Markdown(f'<text style=color:red><strong>WARNING:</strong></text>'))\n",
    "    display(Markdown(f'<text style=color:red>This notebook should be run using the \"insar_analysis\" conda environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>It is currently using the \"{env[0].split(\"/\")[-1]}\" environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Select \"insar_analysis\" from the \"Change Kernel\" submenu of the \"Kernel\" menu.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>If the \"insar_analysis\" environment is not present, use <a href=\"{notebookUrl.split(\"/user\")[0]}/user/{user[0]}/notebooks/conda_environments/Create_OSL_Conda_Environments.ipynb\"> Create_OSL_Conda_Environments.ipynb </a> to create it.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Note that you must restart your server after creating a new environment before it is usable by notebooks.</text>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Python Libraries:\n",
    "\n",
    "**Import the Python libraries and modules we will need to run this lab:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from datetime import date\n",
    "from pathlib import Path\n",
    "import h5py # for is_hdf5\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "gdal.UseExceptions()\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "import matplotlib.dates\n",
    "from matplotlib import rc\n",
    "\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import opensarlab_lib as asfn\n",
    "asfn.jupytertheme_matplotlib_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download GIAnT from the `asf-jupyter-data-west` S3 bucket**\n",
    "\n",
    "GIAnT is no longer supported (Python 2). This unofficial version of GIAnT has been partially ported to Python 3 to run this notebook. Only the portions of GIAnT used in this notebook have been tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_path = Path(\"/home/jovyan/.local/GIAnT/SCR\")\n",
    "\n",
    "if not giant_path.parent.exists():\n",
    "    download_path = 's3://asf-jupyter-data-west/GIAnT_5_21.zip'\n",
    "    output_path = f\"/home/jovyan/.local/{Path(download_path).name}\"\n",
    "    !aws --region=us-west-2 --no-sign-request s3 cp $download_path $output_path\n",
    "    if Path(output_path).is_file():\n",
    "        !unzip $output_path -d /home/jovyan/.local/\n",
    "        Path(output_path).unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preparation for GIAnT\n",
    "\n",
    "Ordinarily, the first step of any SBAS analysis would consist of processing individual interferogram pairs. The rationale of SBAS (Short BAseline Subset) is to choose those pairs for which a high coherence can be expected. These are typically those pairs with a short temporal (horizontal axis) and spatial (vertical axis; less important for Sentinel-1 because they are always small) baselines. However, all these preparation steps have already been accomplished. \n",
    "\n",
    "The prepared data cube that consists of the stack of unwrapped interferograms and several other required files have been created and stored on a server. We will download this data to a local directory and unzip it. \n",
    "\n",
    "Before we download anything, **create a working directory for this analysis:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"/home/jovyan/notebooks/SAR_Training/English/Hazards/CBCInSAR\")\n",
    "data_path = path/'data_ts' \n",
    "\n",
    "if not path.exists():\n",
    "    path.mkdir()\n",
    "    \n",
    "    if not data_path.exists():\n",
    "        data_path.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Copy the zip file to your data directory:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws --region=us-west-2 --no-sign-request s3 cp s3://asf-jupyter-data-west/Lab9Files.zip .\n",
    "!mv Lab9Files.zip InSARSierraNegra.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the directories where we will perform the GIAnT analysis and store the data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_path = data_path/\"Stack\"\n",
    "\n",
    "if not stack_path.exists():\n",
    "    stack_path.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract the zipped file to path and delete it:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped = Path('InSARSierraNegra.zip')\n",
    "\n",
    "if zipped.exists():\n",
    "    asfn.asf_unzip(str(path), str(zipped))\n",
    "    zipped.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Move the unzipped files into the Stack folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir = path/'Lab9Files'\n",
    "\n",
    "if not (stack_path/'RAW-STACK.h5').exists():\n",
    "    shutil.move(str(temp_dir/'RAW-STACK.h5'), stack_path)\n",
    "\n",
    "files = list(temp_dir.rglob('*.*'))\n",
    "for file in files:\n",
    "    if file.exists():\n",
    "        try:\n",
    "            shutil.move(str(file), data_path)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "if temp_dir.exists():\n",
    "    shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data preparation from scratch *(OPTIONAL)***\n",
    "\n",
    "If you want to use a different stack of interferograms than those provided, please refer to the InSARTimeSeriesGIANTPreparation notebook for more information on how to prepare the unwrapped interferograms that a pair-wise processor (e.g., SNAP, ISCE, GAMMA) produces for GIAnT. \n",
    "\n",
    "## 3. Run GIAnT\n",
    "\n",
    "We have now created all of the necessary files to run GIAnT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>GIAnT workflow</b>\n",
    "<br><br>\n",
    "There are three functions that need to be called. The first one reads in all the previously prepared data and stores them in the RAW-STACK.h5 file. This file has already been created.\n",
    "<br><br>\n",
    "<ol>\n",
    "    <li> <font  color=\"LightSlateGrey\"><b>More data preparation: </b>PrepIgramStack.py</font></li>\n",
    "    <li><b>Phase ramp removal: </b>ProcessStack.py</li>\n",
    "    <li><b>Phase inversion and deformation estimation</b>: SBASInvert.py</li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run PrepIgramStack.py (in our case, this has already been done):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python $giant_path/PrepIgramStack.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Confirm That The Stack is an HDF5 File and Declare Parameters\n",
    "\n",
    "PrepIgramStack.py creates a file called 'RAW-STACK.h5'. **Verify that RAW-STACK.h5 is an HDF5 file as required by the rest of GIAnT.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_h5 = stack_path/'RAW-STACK.h5'\n",
    "\n",
    "if not h5py.is_hdf5(raw_h5):\n",
    "    print(f\"Not an HDF5 file: {raw_h5}\")\n",
    "else:\n",
    "    print(f\"Confirmed: {raw_h5} is an HDF5 file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up parameters**\n",
    "\n",
    "A range of parameters that are needed for the subsequent two processing steps need to be set. We will focus on the atmospheric filtering parameter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Filtering parameter</b>\n",
    "<br><br>\n",
    "GIAnT smoothes the inverted phase history in time. The degree of smoothing is determined by a filter parameter <b>filt</b>, given in the unit of [years].\n",
    "\n",
    "<img src='NotebookAddons/filter.png' align='center' width=500>\n",
    "\n",
    "A value of 0.5 (6 months) implies that any component (due to deformation, the atmosphere, etc.) that happens on a time scale of less than approximately 6 months will be smoothed out. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GIAnT requires that the parameters be stored in an XML file sbas.xml. We already provided you with a functional sbas.xml. **Thus, you do not have to execute the code below, which overwrites the file. The only thing the code does is change the filtering parameter in the file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# OPTIONAL #\n",
    "############\n",
    "\n",
    "filt = 0.5 # in years, change to vary the degree of smoothing\n",
    "\n",
    "### change the parameter\n",
    "\n",
    "fnxml = next(giant_path.parent.rglob('sbas.xml'))\n",
    "fnxmlbu = giant_path.parent/'sbas_backup.xml'\n",
    "\n",
    "# make a backup copy\n",
    "\n",
    "if not fnxmlbu.exists():\n",
    "    shutil.copyfile(fnxml, fnxmlbu)\n",
    "\n",
    "# read the xml file\n",
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse(fnxml)\n",
    "root = tree.getroot()\n",
    "\n",
    "# find the element we need\n",
    "filter_element = root[0].find('filterlen').find('value')\n",
    "# overwrite its content\n",
    "filter_element.text = f'{filt}'\n",
    "# store as xml\n",
    "with open(fnxml, 'wb') as f:\n",
    "    f.write(ET.tostring(root))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run this cell to retrieve the filter size if you opted to not run the code cell above**\n",
    "\n",
    "Note: If you ran the optional cell above, running this one isn't necessary but doing so won't hurt anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### change the parameter\n",
    "fnxml = next(giant_path.parent.rglob('sbas.xml'))\n",
    "fnxmlbu = giant_path.parent/'sbas_backup.xml'\n",
    "\n",
    "# make a backup copy\n",
    "\n",
    "if not fnxmlbu.exists():\n",
    "    shutil.copyfile(fnxml, fnxmlbu)\n",
    "\n",
    "# read the xml file\n",
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse(fnxml)\n",
    "root = tree.getroot()\n",
    "# find the element we need\n",
    "filter_element = root[0].find('filterlen').find('value')\n",
    "filt = filter_element.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Ramp removal: ProcessStack.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font face='Calibri' size='3'> <img src=\"NotebookAddons/deramped.png\" align=\"right\" width=400></font>\n",
    "<br>   \n",
    "<font face='Calibri' size='3'>\n",
    "<b>Ramps in the interferogram</b><br>\n",
    "Interferograms can often have pronounced ramps. One origin of such ramps are slightly inaccurate baseline estimates due to uncertainty in the satellite orbits. It is thus common to remove ramps from the interferogram, in particular if one is interested in localized deformation. We will use the standard ramp removal implemented in GIAnT (netramp=True in our sbas.xml). Owing to the excellent accuracy of the orbits used, we do not expect major ramps. Also, we are looking at a relatively confined area. <br><br>\n",
    "\n",
    "<b>Large-scale atmospheric corrections</b> (not done here)<br>\n",
    "It is also possible to use a priori weather model data to mitigate predictable large-scale tropospheric phase patterns. There is an additional option for estimating and removing stratified tropospheric contributions. We will not take advantage of these advanced processing options in this tutorial. <br><br>\n",
    "\n",
    "<b>Implementation in ProcessStack.py</b><br>\n",
    "To remove ramps, we call ProcessStack.py. It produces a file called PROC-STACK.h5, on which the later processing (phase inversion and deformation estimation) operates.  \n",
    "</font> <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run ProcessStack.py:**\n",
    "\n",
    "Note: The progress bars may not fully complete. This is okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with asfn.work_dir(data_path):\n",
    "  !python {giant_path/'ProcessStack.py'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='4'> <b>3.3 Phase inversion and deformation estimation: Run SBASInvert.py </b></font>\n",
    "<br>\n",
    "<font face='Calibri' size='3'> SBAS Invert.py takes the PROC-STACK.h5 file produced by the previous step and estimates the deformation time series. It incorporates two steps:\n",
    "<br>\n",
    "<div class=\"alert alert-warning\">\n",
    "    <b> Obtaining the raw and smoothed phase history</b><br>\n",
    "    \n",
    "   <b>1. Phase inversion to obtain the raw estimate: </b> \n",
    "    Solve the least-squares problem to get a best-fit phase history from the interferogram phases. We refer to this as the raw estimate. No constraints (and temporal model) are assumed for the phase history: each scene phase is a separate unknown in the estimation. The inversion enforces a least-norm constraint whenever there are multiple non-connected clusters of interferograms.<br><br>\n",
    "   <b>2. Temporal smoothing:</b>\n",
    "      As the raw phase history still contains noise (e.g. from the atmospheric phase screen), the inverted phase history is smoothed.\n",
    "    The default choice for the temporal smoothing that we use in this lab is very strong (i.e. a long filter length). The choice of smoothing to mitigate artefacts due to e.g. the troposphere is a critical one. We will analyze the choice in detail later. \n",
    "</div>\n",
    "\n",
    "The output, most importantly the line-of-sight deformation time series, is stored in the file LS-PARAMS.h5.\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='3'><b>Run SBASInvert.py:</b>\n",
    "<br>\n",
    "Note: The progress bar may not fully complete. This is okay.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with asfn.work_dir(data_path):\n",
    "  !python {giant_path/'SBASInvert.py'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Visualization\n",
    "\n",
    "To explore our results, we will now produce a number of plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Interpreting the results</b>\n",
    "<br><br>\n",
    "Each plot will be followed by a question that will let you explore and interpret a particular aspect of the results. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We first create a folder in which to store the figures:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir = path/'plots'\n",
    "\n",
    "if not plot_dir.exists():\n",
    "    plot_dir.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the stack produced by GIAnT and read it into an array so we can manipulate and display it:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_h5 = f\"{stack_path}/LS-PARAMS.h5\"\n",
    "params_h5 = stack_path/\"LS-PARAMS.h5\"\n",
    "f = h5py.File(str(params_h5), 'r')\n",
    "data_cube = f['recons'][()] # filtered deformation time series\n",
    "data_cube_raw = f['rawts'][()] # raw (unfiltered) deformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read and convert the dates:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = list(f['dates']) # these dates appear to be given in Rata Die style: floor(Julian Day Number - 1721424.5). \n",
    "tindex = [date.fromordinal(int(d)) for d in dates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Amplitude image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "radar_tiff = data_path/'20161119-20170106_amp.tiff'\n",
    "radar=gdal.Open(str(radar_tiff))\n",
    "im_radar = radar.GetRasterBand(1).ReadAsArray()\n",
    "radar = None\n",
    "dbplot = np.ma.log10(im_radar)\n",
    "vmin=np.percentile(dbplot.data, 3)\n",
    "vmax=np.percentile(dbplot.data, 97)\n",
    "fig = plt.figure(figsize=(16,7)) # Initialize figure with a size\n",
    "ax1 = fig.add_subplot(111) # 221 determines: 2 rows, 2 plots, first plot\n",
    "ax1.imshow(dbplot, cmap='gray',vmin=vmin,vmax=vmax,alpha=1);\n",
    "plt.title('Amplitude [logarithmic]')\n",
    "plt.grid()\n",
    "fnfig = plot_dir/'SierraNegra-dBScaled-AmplitudeImage.png'\n",
    "plt.savefig(fnfig,dpi=200,transparent='false')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<img style=\"padding: 7px\" src=\"NotebookAddons/calderasierranegra.jpg\" align=\"right\" width=300>\n",
    "    \n",
    "<font face='Calibri' size='3'><b>Studying the caldera</b>\n",
    "\n",
    "\n",
    "The caldera, the large circular depression in the central portion of the image, formed due to the collapse of a magma chamber in a previous eruption. \n",
    "    \n",
    "Compare the photograph (from Nature Galapagos) with the SAR image: \n",
    "- Try to see which parts correspond to each other (Hint: also look at the background). \n",
    "- Can you infer the radar look direction from this figure? \n",
    "    </font>\n",
    "<br><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Deformation map:\n",
    "\n",
    "**We will first write a helper function that produces the plot given a cumulative deformation estimate:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defNradar_plot(deformation, radar, title=\"Cumulative deformation [mm]\"):\n",
    "    fig = plt.figure(figsize=(18, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    vmin = np.percentile(radar.data, 3)\n",
    "    vmax = np.percentile(radar.data, 97)\n",
    "    ax.imshow(radar, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    fin_plot = ax.imshow(deformation, cmap='RdBu', vmin=-50.0, vmax=50.0, alpha=0.75)\n",
    "    fig.colorbar(fin_plot, fraction=0.24, pad=0.02)\n",
    "    ax.set(title=title)\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we call the function. The scene variable is set to -1 (the last one), so that the cumulative deformation over the entire period is plotted. You can also change it to a smaller value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose scene for which to plot deformation\n",
    "scene = data_cube.shape[0] - 1  # try any number between 0 and 45\n",
    "\n",
    "# Make a nice title for the figure\n",
    "title = f'Cumulative deformation [mm] {tindex[0].strftime(\"%Y-%m-%d\")} to {tindex[scene].strftime(\"%Y-%m-%d\")}'\n",
    "\n",
    "# Get deformation map and radar image we wish to plot\n",
    "deformation = data_cube[scene, ...]\n",
    "\n",
    "# Call function to plot an overlay of our deformation map and radar image.\n",
    "defNradar_plot(deformation, dbplot, title=title)\n",
    "fnfig = plot_dir/'SierraNegra-DeformationComposite.png'\n",
    "plt.savefig(fnfig, dpi=200, transparent='false')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font face='Calibri' size='3'>    \n",
    "<b>Location and direction of the deformation</b>\n",
    "<br><br>\n",
    "The deformation map shows a clear contrast between the rim of the caldera and the the rest of the map. The sign convention is such that positive values correspond to a movement toward the satellite. Did the area near the caldera move up or down? What about the gray areas?\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Deformation time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.grid()\n",
    "\n",
    "# choose a stable (?) point\n",
    "point = (300, 50) # first axis is vertical, second axis horizontal, (0,0) upper left\n",
    "\n",
    "l1 = ax.plot(tindex, data_cube[:, point[0], point[1]], label='Filtered')\n",
    "l2 = ax.plot(tindex, data_cube_raw[:, point[0], point[1]], label='Not filtered')\n",
    "ax.legend()\n",
    "ax.xaxis.set_major_locator(matplotlib.dates.MonthLocator(bymonth=[1,7]))\n",
    "ax.set_title('Comparing filtered and unfiltered solution')\n",
    "fnfig = plot_dir/'SierraNegraTimeSeries.png'\n",
    "plt.savefig(fnfig, transparent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font face='Calibri' size='3'>\n",
    "<b>Atmospheric filtering</b>\n",
    "<br><br>\n",
    "GIAnT applied a very strong temporal smoothing filter to the data. The idea was to reduce the noise, in particular that due to the troposphere. Do you think the smoothing was adequate? Do you think the difference between the filtered and the unfiltered time series is entirely due to noise, or could some of the discrepancy be due to temporally variable deformation. What time period could most plausibly be affected by a transient deformation signal that got lost due to the smoothing?    \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Spatiotemporal deformation - Animation:\n",
    "\n",
    "**First, write a function to create an animation:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_animation(deformation=data_cube):\n",
    "    fig = plt.figure(figsize=(14, 8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axis('off')\n",
    "    vmin=np.percentile(deformation.flatten(), 5)\n",
    "    vmax=np.percentile(deformation.flatten(), 95)\n",
    "\n",
    "\n",
    "    im = ax.imshow(deformation[-1, ...], cmap='RdBu', vmin=-50.0, vmax=50.0)\n",
    "    ax.set_title(\"Cumulative deformation until {} [mm]\".format(tindex[-1]))\n",
    "    fig.colorbar(im)\n",
    "    plt.grid()\n",
    "\n",
    "    def animate(i):\n",
    "        ax.set_title(\"Cumulative deformation until {} [mm]\".format(tindex[i]))\n",
    "        im.set_data(deformation[i])\n",
    "\n",
    "    ani = matplotlib.animation.FuncAnimation(fig, animate, frames=deformation.shape[0], interval=400)\n",
    "    return ani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will animate the filtered time series.**\n",
    "\n",
    "If you uncomment the third line, you can animate the raw unfiltered time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "type_time_series = 'filtered'\n",
    "# type_time_series = 'not_filtered'\n",
    "\n",
    "if type_time_series == 'filtered':\n",
    "    ani = create_animation(deformation=data_cube)\n",
    "else:\n",
    "    ani = create_animation(deformation=data_cube_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a javascript animation of the time-series running inline in the notebook and save it as .gif:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc('animation', embed_limit=10.0**9)\n",
    "fnani = plot_dir/f'SierraNegraDeformationTS{type_time_series}_{filt}.gif'\n",
    "ani.save(fnani, writer='pillow', fps=2)\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font face='Calibri' size='3'>\n",
    "<b>Atmospheric filtering II</b>\n",
    "<br><br>\n",
    "Compare the animations for the filtered and non-filtered time series. Where and when are the differences largest? \n",
    "\n",
    "<b>Reprocess the data</b> using a shorter filter (e.g. one month: filt = 0.082) and compare the differences.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise8B-InSARTimeSeriesGIANTProcessing.ipynb - Version 1.5.0 - November 2021*\n",
    "\n",
    "*Version Changes:*\n",
    "\n",
    "- *asf_notebook -> opensarlab_lib*\n",
    "- *html -> markdown*\n",
    "- *url_widget*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insar_analysis [conda env:.local-insar_analysis]",
   "language": "python",
   "name": "conda-env-.local-insar_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
