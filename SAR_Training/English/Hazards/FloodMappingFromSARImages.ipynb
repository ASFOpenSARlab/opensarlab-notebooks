{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![OpenSARlab notebook banner](NotebookAddons/blackboard-banner.png)\n",
    "\n",
    "# Flood Mapping from Single Sentinel-1 SAR Images\n",
    "\n",
    "<img style=\"padding: 7px\" src=\"../Master/NotebookAddons/UAFLogo_A_647.png\" width=\"170\" align=\"right\"/>\n",
    "\n",
    "## Franz J Meyer, University of Alaska Fairbanks\n",
    "\n",
    "This notebook presents a SAR-based flood mapping approach that largely follows a methodology developed by the German Aerospace Center and published in *[Sentinel-1-based flood mapping: a fully automated processing chain](https://www.tandfonline.com/doi/full/10.1080/01431161.2016.1192304) by Twele et al.* The approach is based on radiometricall terrain corrected (RTC processed) Sentinel-1 SAR data and applies a dynamic thresholding method followed by fuzzy-logic-based post processing procedure. This notebook implements the initial threshold-based flood mapping approach but, for simplicity, does not include the fuzzy-logic post processing steps. \n",
    "\n",
    "The approach is based on image amplitude data and is capable of detecting standing surface water. Note that flooding under vegetation will not be detected by this approach.\n",
    "\n",
    "<br>\n",
    "<img style=\"padding:7px;\" src=\"NotebookAddons/OpenSARlab_logo.svg\" width=\"170\" align=\"right\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import url_widget as url_w\n",
    "notebookUrl = url_w.URLWidget()\n",
    "display(notebookUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "\n",
    "notebookUrl = notebookUrl.value\n",
    "user = !echo $JUPYTERHUB_USER\n",
    "env = !echo $CONDA_PREFIX\n",
    "if env[0] == '':\n",
    "    env[0] = 'Python 3 (base)'\n",
    "if env[0] != '/home/jovyan/.local/envs/hydrosar':\n",
    "    display(Markdown(f'<text style=color:red><strong>WARNING:</strong></text>'))\n",
    "    display(Markdown(f'<text style=color:red>This notebook should be run using the \"hydrosar\" conda environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>It is currently using the \"{env[0].split(\"/\")[-1]}\" environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Select \"hydrosar\" from the \"Change Kernel\" submenu of the \"Kernel\" menu.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>If the \"hydrosar\" environment is not present, use <a href=\"{notebookUrl.split(\"/user\")[0]}/user/{user[0]}/notebooks/conda_environments/Create_OSL_Conda_Environments.ipynb\"> Create_OSL_Conda_Environments.ipynb </a> to create it.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Note that you must restart your server after creating a new environment before it is usable by notebooks.</text>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Methodology and Workflow\n",
    "\n",
    "The workflow of the Sentinel-1-based processing chain, as outlined in the figure below, is composed of the following main elements: \n",
    "\n",
    "- **Find relevant SAR data** over your area of interest at the [Alaska Satellite Facility's Data Search (Vertex)](https://search.asf.alaska.edu/#/)\n",
    "- **Perform geometric and radiometric terrain correction** using the RTC processing flow by [GAMMA Remote Sensing](https://www.gamma-rs.ch/)\n",
    "- **initial flood detection** using automatic thresholding\n",
    "- **fuzzy-logic-based classification refinement**\n",
    "- **final classification into permanent and flood waters** using auxiliary data\n",
    "- **dissemination of the results**\n",
    "\n",
    "***Steps 1 and 2*** of this workflow are operationally implemented in the Alaska Satellite Facility's Hybrid Pluggable Processing Pipeline (HyP3) environment and accessible to the public at [ASF Search](https://search.asf.alaska.edu/).\n",
    "\n",
    "<img style= \"padding: 7px\" src=\"https://courses.edx.org/asset-v1:AlaskaX+SAR-401+3T2020+type@asset+block@Watermappingworkflow2.jpg\" width=\"70%\"/>\n",
    "\n",
    "## Flood Mapping Procedure\n",
    "\n",
    "### Loading Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "gdal.UseExceptions()\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import pyproj\n",
    "import skfuzzy\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt # for add_subplot, axis, figure, imshow, legend, plot, set_axis_off, set_data,\n",
    "                               # set_title, set_xlabel, set_ylabel, set_ylim, subplots, title, twinx\n",
    "\n",
    "from ipyfilechooser import FileChooser\n",
    "import ipywidgets as ui\n",
    "\n",
    "import opensarlab_lib as asfn\n",
    "asfn.jupytertheme_matplotlib_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Some Helper Scripts\n",
    "\n",
    "**Write a function to pad an image, so it may be split into tiles with consistent dimensions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image(image: np.ndarray, to: int) -> np.ndarray:\n",
    "    height, width = image.shape\n",
    "\n",
    "    n_rows, n_cols = get_tile_row_col_count(height, width, to)\n",
    "    new_height = n_rows * to\n",
    "    new_width = n_cols * to\n",
    "\n",
    "    padded = np.zeros((new_height, new_width))\n",
    "    padded[:image.shape[0], :image.shape[1]] = image\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write a function to tile an image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_image(image: np.ndarray, width, height) -> np.ndarray:\n",
    "    _nrows, _ncols = image.shape\n",
    "    _strides = image.strides\n",
    "\n",
    "    nrows, _m = divmod(_nrows, height)\n",
    "    ncols, _n = divmod(_ncols, width)\n",
    "\n",
    "    assert _m == 0, \"Image must be evenly tileable. Please pad it first\"\n",
    "    assert _n == 0, \"Image must be evenly tileable. Please pad it first\"\n",
    "\n",
    "    return np.lib.stride_tricks.as_strided(\n",
    "        np.ravel(image),\n",
    "        shape=(nrows, ncols, height, width),\n",
    "        strides=(height * _strides[0], width * _strides[1], *_strides),\n",
    "        writeable=False\n",
    "    ).reshape(nrows * ncols, height, width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write a function for Kittler-Illingworth Thresholding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kittler(im):\n",
    "    \"\"\"\n",
    "    The reimplementation of Kittler-Illingworth Thresholding algorithm by Bob Pepin\n",
    "    Works on 8-bit images only\n",
    "    Original Matlab code: https://www.mathworks.com/matlabcentral/fileexchange/45685-kittler-illingworth-thresholding\n",
    "    Paper: Kittler, J. & Illingworth, J. Minimum error thresholding. Pattern Recognit. 19, 41â€“47 (1986).\n",
    "    \"\"\"\n",
    "    test = im.ravel()\n",
    "    tindex = np.nonzero(test>0)\n",
    "    h,g = np.histogram(test[tindex],256,[0,256])\n",
    "    h = h.astype(np.float)\n",
    "    g = g.astype(np.float)\n",
    "    g = g[:-1]\n",
    "    c = np.cumsum(h)\n",
    "    m = np.cumsum(h * g)\n",
    "    s = np.cumsum(h * g**2)\n",
    "    sigma_f = np.sqrt(s/c - (m/c)**2)\n",
    "    cb = c[-1] - c\n",
    "    mb = m[-1] - m\n",
    "    sb = s[-1] - s\n",
    "    sigma_b = np.sqrt(sb/cb - (mb/cb)**2)\n",
    "    p =  c / c[-1]\n",
    "    v = p * np.log10(sigma_f) + (1-p)*np.log10(sigma_b) - p*np.log10(p) - (1-p)*np.log10(1-p)\n",
    "    v[~np.isfinite(v)] = np.inf\n",
    "    idx = np.argmin(v)\n",
    "    t = g[idx]\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write a function for multi-class Expectation Maximization Thresholding to replace Kittler-Illingworth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EMSeg_opt(image, number_of_classes):\n",
    "    image_copy = image.copy()\n",
    "    image = image.flatten()\n",
    "    minimum = np.amin(image)\n",
    "    image = image - minimum + 1\n",
    "    maximum = np.amax(image)\n",
    "    size = image.size\n",
    "    histogram = make_histogram(image)\n",
    "    nonzero_indices = np.nonzero(histogram)[0]\n",
    "    histogram = histogram[nonzero_indices]\n",
    "    histogram = histogram.flatten()\n",
    "    class_means = (\n",
    "            (np.arange(number_of_classes) + 1) * maximum /\n",
    "            (number_of_classes + 1)\n",
    "    )\n",
    "    class_variances = np.ones((number_of_classes)) * maximum\n",
    "    class_proportions = np.ones((number_of_classes)) * 1 / number_of_classes\n",
    "    sml = np.mean(np.diff(nonzero_indices)) / 1000\n",
    "    iteration = 0\n",
    "    while(True):\n",
    "        class_likelihood = make_distribution(\n",
    "            class_means, class_variances, class_proportions, nonzero_indices\n",
    "        )\n",
    "        sum_likelihood = np.sum(class_likelihood, 1) + np.finfo(\n",
    "                class_likelihood[0][0]).eps\n",
    "        log_likelihood = np.sum(histogram * np.log(sum_likelihood))\n",
    "        for j in range(0, number_of_classes):\n",
    "            class_posterior_probability = (\n",
    "                histogram * class_likelihood[:,j] / sum_likelihood\n",
    "            )\n",
    "            class_proportions[j] = np.sum(class_posterior_probability)\n",
    "            class_means[j] = (\n",
    "                np.sum(nonzero_indices * class_posterior_probability)\n",
    "                    / class_proportions[j]\n",
    "            )\n",
    "            vr = (nonzero_indices - class_means[j])\n",
    "            class_variances[j] = (\n",
    "                np.sum(vr *vr * class_posterior_probability)\n",
    "                    / class_proportions[j] +sml\n",
    "            )\n",
    "            del class_posterior_probability, vr\n",
    "        class_proportions = class_proportions + 1e-3\n",
    "        class_proportions = class_proportions / np.sum(class_proportions)\n",
    "        class_likelihood = make_distribution(\n",
    "            class_means, class_variances, class_proportions, nonzero_indices\n",
    "        )\n",
    "        sum_likelihood = np.sum(class_likelihood, 1) + np.finfo(\n",
    "                class_likelihood[0,0]).eps\n",
    "        del class_likelihood\n",
    "        new_log_likelihood = np.sum(histogram * np.log(sum_likelihood))\n",
    "        del sum_likelihood\n",
    "        if((new_log_likelihood - log_likelihood) < 0.000001):\n",
    "            break\n",
    "        iteration = iteration + 1\n",
    "    del log_likelihood, new_log_likelihood\n",
    "    class_means = class_means + minimum - 1\n",
    "    s = image_copy.shape\n",
    "    posterior = np.zeros((s[0], s[1], number_of_classes))\n",
    "    for i in range(0, s[0]):\n",
    "        for j in range(0, s[1]):\n",
    "            for n in range(0, number_of_classes):\n",
    "                x = make_distribution(\n",
    "                    class_means[n], class_variances[n], class_proportions[n],\n",
    "                    image_copy[i,j]\n",
    "                )\n",
    "                posterior[i,j,n] = x * class_proportions[n]\n",
    "    return posterior, class_means, class_variances, class_proportions\n",
    "\n",
    "def make_histogram(image):\n",
    "    image = image.flatten()\n",
    "    indices = np.nonzero(np.isnan(image))\n",
    "    image[indices] = 0\n",
    "    indices = np.nonzero(np.isinf(image))\n",
    "    image[indices] = 0\n",
    "    del indices\n",
    "    size = image.size\n",
    "    maximum = int(np.ceil(np.amax(image)) + 1)\n",
    "    #maximum = (np.ceil(np.amax(image)) + 1)\n",
    "    histogram = np.zeros((1, maximum))\n",
    "    for i in range(0,size):\n",
    "        #floor_value = int(np.floor(image[i]))\n",
    "        floor_value = np.floor(image[i]).astype(np.uint8)\n",
    "        #floor_value = (np.floor(image[i]))\n",
    "        if floor_value > 0 and floor_value < maximum - 1:\n",
    "            temp1 = image[i] - floor_value\n",
    "            temp2 = 1 - temp1\n",
    "            histogram[0,floor_value] = histogram[0,floor_value] + temp1\n",
    "            histogram[0,floor_value - 1] = histogram[0,floor_value - 1] + temp2\n",
    "    histogram = np.convolve(histogram[0], [1,2,3,2,1])\n",
    "    histogram = histogram[2:(histogram.size - 3)]\n",
    "    histogram = histogram / np.sum(histogram)\n",
    "    return histogram\n",
    "\n",
    "def make_distribution(m, v, g, x):\n",
    "    x = x.flatten()\n",
    "    m = m.flatten()\n",
    "    v = v.flatten()\n",
    "    g = g.flatten()\n",
    "    y = np.zeros((len(x), m.shape[0]))\n",
    "    for i in range(0,m.shape[0]):\n",
    "        d = x - m[i]\n",
    "        amp = g[i] / np.sqrt(2*np.pi*v[i])\n",
    "        y[:,i] = amp * np.exp(-0.5 * (d * d) / v[i])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write a function to calculate the number of rows and columns of tiles needed to tile an image to a given size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tile_row_col_count(height: int, width: int, tile_size: int) -> Tuple[int, int]:\n",
    "    return int(np.ceil(height / tile_size)), int(np.ceil(width / tile_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write a function to extract the tiff dates from a wildcard path:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(paths, ext):\n",
    "    dates = []\n",
    "    pths = paths.rglob(ext)\n",
    "    for p in pths:\n",
    "        date = str(p).split('/')[-1].split(\"_\")[0]\n",
    "        dates.append(date)\n",
    "    dates.sort()\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write a function to save a mask**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_mask_to_file(mask: np.ndarray, file_name: str, projection: str, geo_transform: str) -> None:\n",
    "    (width, height) = mask.shape\n",
    "    out_image = gdal.GetDriverByName('GTiff').Create(\n",
    "        file_name, height, width, bands=1\n",
    "    )\n",
    "    out_image.SetProjection(projection)\n",
    "    out_image.SetGeoTransform(geo_transform)\n",
    "    out_image.GetRasterBand(1).WriteArray(mask)\n",
    "    out_image.GetRasterBand(1).SetNoDataValue(0)\n",
    "    out_image.FlushCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proj4(filename):\n",
    "    f=rasterio.open(filename)\n",
    "    return pyproj.Proj(f.crs, preserve_units=True)  #used in pysheds\n",
    "    \n",
    "def gdal_read(filename, ndtype=np.float64):\n",
    "    '''\n",
    "    z=readData('/path/to/file')\n",
    "    '''\n",
    "    ds = gdal.Open(filename) \n",
    "    return np.array(ds.GetRasterBand(1).ReadAsArray()).astype(ndtype);\n",
    "def gdal_get_geotransform(filename):\n",
    "    '''\n",
    "    [top left x, w-e pixel resolution, rotation, top left y, rotation, n-s pixel resolution]=gdal_get_geotransform('/path/to/file')\n",
    "    '''\n",
    "    #http://stackoverflow.com/questions/2922532/obtain-latitude-and-longitude-from-a-geotiff-file\n",
    "    ds = gdal.Open(filename)\n",
    "    return ds.GetGeoTransform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SAR Data Sets to Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tiff_paths(paths: str) -> list:\n",
    "    tiff_paths = !ls $paths | sort -t_ -k5,5\n",
    "    return tiff_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading a SAR Data Stack:**\n",
    "\n",
    "There are two data sets available for this notebook: Option `fleven = 1` is a flood mapping example for Eastern India and shows flood extents during the summer 2020 period. Option `flevent = 2` is a data set over El Salvador, acquired as Tropical Storm Amanda passed over the country. While damages occurred in the area. Not much evidence of the storm can be extracted from the data. This may be related to the limited spatial extent of local flooding events or due to the heavy vegation of the country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick Dataset to Analyze\n",
    "flevent = 1     # Options: 1 - Guayaquil flood of 2016-2017   |    2 - 2020 Bangladesh & Eastern India Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name = \"BangladeshFloodMapping\" if flevent == 1 else \"TSAmandaElSalvador\"\n",
    "path = Path.cwd()/name\n",
    "\n",
    "if not path.exists():\n",
    "    path.mkdir()\n",
    "    \n",
    "tiff_dir = path/'tiffs'\n",
    "if not tiff_dir.exists():\n",
    "    tiff_dir.mkdir()\n",
    "\n",
    "time_series_path = f\"s3://asf-jupyter-data-west/{name}.tar.gz\"\n",
    "time_series = Path(time_series_path).name\n",
    "\n",
    "!aws --region=us-west-2 --no-sign-request s3 cp $time_series_path {tiff_dir}/$time_series\n",
    "!tar -xvzf {tiff_dir}/{name}.tar.gz -C {tiff_dir}\n",
    "!rm {tiff_dir}/*.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Move into the parent directory of the directory containing the data and create a directory in which to store the water masks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_directory = path/'Water_Masks'\n",
    "if not mask_directory.exists():\n",
    "    mask_directory.mkdir()\n",
    "\n",
    "if tiff_dir.exists():\n",
    "    tiff_paths = get_tiff_paths(f'{tiff_dir}/*_V*.tif*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write a function to create a dictionary containing lists of each vv/vh pair**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_polarizations(tiff_paths: list) -> dict:\n",
    "    pths = {}\n",
    "    for tiff in tiff_paths:\n",
    "        product_name = tiff.split('.')[0][:-2]\n",
    "        if product_name in pths:\n",
    "            pths[product_name].append(tiff)\n",
    "        else:\n",
    "            pths.update({product_name: [tiff]})\n",
    "            pths[product_name].sort()\n",
    "    return pths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write a function to confirm the presence of both VV and VH images in all image sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confirm_dual_polarizations(paths: dict) -> bool:\n",
    "    for p in paths:\n",
    "        if len(paths[p]) == 2:\n",
    "            if ('vv' not in paths[p][1] and 'VV' not in paths[p][1]) or \\\n",
    "            ('vh' not in paths[p][0] and 'VH' not in paths[p][0]):\n",
    "                return False\n",
    "    return True   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a dictionary of VV/VH pairs and check it for completeness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pths = group_polarizations(tiff_paths)\n",
    "if not confirm_dual_polarizations(grouped_pths):\n",
    "    print(\"ERROR: AI_Water requires both VV and VH polarizations.\")\n",
    "else:\n",
    "    print(\"Confirmed presence of VV and VH polarities for each product.\")\n",
    "    \n",
    "#print(grouped_pths) #uncomment to print VV/VH path pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load HAND Layer for your AOI and Create HAND-Exclusion Mask (HAND-EM)\n",
    "\n",
    "**Note:** This notebook expects the HAND layer to be of the same extent, resolution, and projection as the SAR image stack. This can easily be fixed in future versions of the notebook. The HAND layer you will be using meets all of these requirements.\n",
    "\n",
    "**Please pick the file `Bangladesh_Training_DEM_hand.tif` or `AmandaDEM_hand.tif` using the path selector in the code cell below!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Choose your HAND layer:\")\n",
    "\n",
    "f = FileChooser('.')\n",
    "display(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoHANDLayerException(Exception):\n",
    "    \"\"\"\n",
    "    Raised when expecting path to HAND layer but none found\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "#load HAND and derive HAND-EM\n",
    "Hthresh = 15\n",
    "\n",
    "HAND_file = f.selected\n",
    "print(f\"Selected HAND: {HAND_file}\")\n",
    "try:\n",
    "    HAND_gT=gdal_get_geotransform(HAND_file)\n",
    "except AttributeError:\n",
    "    raise NoHANDLayerException(\"You must select a HAND layer in the previous code cell\")\n",
    "HAND_proj4=get_proj4(HAND_file)\n",
    "HAND=gdal_read(HAND_file)\n",
    "hand = np.nan_to_num(HAND)\n",
    "\n",
    "# Create Binary HAND-EM\n",
    "Hmask = hand < Hthresh\n",
    "handem = np.zeros_like(hand)\n",
    "sel = np.ones_like(hand)\n",
    "handem[Hmask] = sel[Hmask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 5))\n",
    "plt.suptitle('Height Above Nearest Drainage [HAND] (m)')\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "vmin = np.percentile(hand, 5)\n",
    "vmax = np.percentile(hand, 95)\n",
    "hh = ax1.imshow(hand, cmap='jet', vmin=vmin, vmax=vmax)\n",
    "ax1.set_title('HAND [m]')\n",
    "ax1.grid()\n",
    "fig.colorbar(hh,ax=ax1)\n",
    "ax2.imshow(handem, cmap='gray')\n",
    "ax2.set_title('HAND-EM')\n",
    "ax2.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do Initial Flood Mapping using Adaptive Dynamic Thresholding\n",
    "\n",
    "**A bit of background on the implemented approach:**\n",
    "\n",
    "**This is what is implemented in this notebook:** An automatic tile-based thresholding procedure (Martinis, Twele, and Voigt 2009) is used to generate an land/water classification. The selection of tiles is performed on a bilevel quadtree structure with parent level $L^+$ and child level $L^âˆ’$:\n",
    "    \n",
    "1. Firstly, the entire data are separated into quadratic non-overlapping parent tiles on level $L^+$ with a size of $100 \\times 100$ pixels. Each parent object is further represented by four quadratic child objects on a second level $L^âˆ’$. The tile selection process is based on statistical hierarchical relations between parent and child objects. \n",
    "1. A number of parent tiles is automatically selected which offer the highest (>95% quantile) coefficient of variation on $L^+$ of the mean backscatter values of the respective child objects on $L^âˆ’$. This criterion serves as a measure of the degree of variation within the data and can therefore be used as an indicator of the probability that the tiles are characterized by spatial inhomogeneity and contain more than one semantic class. The selected parent objects should also have a mean individual backscatter value lower than the mean of all parent tiles on $L^+$. This ensures that tiles lying on the boundary between water and no water areas are selected. In case that no tiles fulfil these criteria, the tile size on $L^+$ and $L^âˆ’$ is halved and the quantile for the tile selection is reduced to 90% to guarantee a successful tile selection also in data with a relatively low extent of water surfaces or with smaller dispersed water bodies. \n",
    "1. To improve the robustness of the automatic threshold derivation the approach restricts the tile selection in Step (3) to only pixels situated in flood-prone regions defined by a Height Above Nearest Drainage (HAND)-based binary Exclustion Mask (HAND-EM). To create HAND-EM, a threshold is applied to HAND to identify non-flood prone areas. A threshold value of $\\geq 15m$ is proposed. The HAND-EM further is shrunk by one pixel using an 8-neighbour function to account for potential geometric inaccuracies between the exclude layer and SAR data. Tiles are only considered in case less than 20% of its data pixels are excluded by HAND-EM.\n",
    "1. Out of the number of the initially selected tiles, a limited number of N parent tiles are finally chosen for threshold computation. This selection is accomplished by ranking the parent tiles according to the standard deviation of the mean backscatter values of the respective child objects. Tiles with the highest values are chosen for $N$. Extensive testing yielded that $N = 5$ is a sufficient number of parent tiles for threshold computation. \n",
    "1. A multi-mode Expectation Maximization minimum error thresholding approach is then employed to derive local threshold values using a cost function which is based on the statistical parameterization of the sub-histograms of all selected tiles as bi-modal Gaussian mixture distributions. In order to derive a global (i.e. scenebased) threshold, the locally derived thresholds are combined by computing their arithmetic mean. \n",
    "1. Using the dynamically calculated threshold, both the VV and VH scenes are thresholded for water detection\n",
    "1. The detected water maps are combined for arrive at an intial water mask that can be further refined in post processing\n",
    "\n",
    "**Here some additional refinement steps that could be added to the notebook in the future:**\n",
    "\n",
    "1. **Calculation of attributes for fuzzy-logic post processing:** Based on the preliminary classification, the mean elevation of water objects and the size of all individual flood objects should be calculated. Together with the earlier derived landâ€“water threshold, these parameters calculated from the initial classification can later be used to define fuzzy thresholds for the standard $S$ and $Z$ membership functions (see Section on Post Processing). This means that the initial classification based on the automatic thresholding procedure is mandatory to build elements for the fuzzy-logic-based refinement.\n",
    "\n",
    "**Now Let's do the Work:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define some variables you might want to change\n",
    "precentile = 0.95        # Standard deviation percentile threshold for pivotal tile selection\n",
    "tilesize = 100           # Setting tile size to use in thresholding algorithm\n",
    "tilesize2 = 50\n",
    "Hpick = 0.8              # Threshold for required fraction of valid HAND-EM pixels per tile\n",
    "vv_corr = -17.0          # VV threshold to use if threshold calculation did not succeed\n",
    "vh_corr = -24.0          # VH threshold to use if threshold calculation did not succeed\n",
    "\n",
    "# Tile up HAND-EM data\n",
    "handem_p = pad_image(handem, tilesize)\n",
    "hand_tiles = tile_image(handem_p,width=tilesize,height=tilesize)\n",
    "Hsum = np.sum(hand_tiles, axis=(1,2))\n",
    "Hpercent = Hsum/(tilesize*tilesize)\n",
    "\n",
    "# Now do adaptive threshold selection\n",
    "vv_thresholds = np.array([])\n",
    "vh_thresholds = np.array([])\n",
    "floodarea = np.array([])\n",
    "vh_thresholds_corr = np.array([])\n",
    "vv_thresholds_corr = np.array([])\n",
    "\n",
    "for pair in grouped_pths:\n",
    "    for tiff in grouped_pths[pair]:\n",
    "        f = gdal.Open(tiff)\n",
    "        img_array = f.ReadAsArray()\n",
    "        original_shape = img_array.shape\n",
    "        n_rows, n_cols = get_tile_row_col_count(*original_shape, tile_size=tilesize)\n",
    "        print(f'tiff: {tiff}')\n",
    "        if 'vv' in tiff or 'VV' in tiff:\n",
    "            vv_array = pad_image(f.ReadAsArray(), tilesize)\n",
    "            invalid_pixels = np.nonzero(vv_array == 0.0)\n",
    "            vv_tiles = tile_image(vv_array,width=tilesize,height=tilesize)\n",
    "            a = np.shape(vv_tiles)\n",
    "            vv_std = np.zeros(a[0])\n",
    "            vvt_masked = np.ma.masked_where(vv_tiles==0, vv_tiles)\n",
    "            vv_picktiles = np.zeros_like(vv_tiles)\n",
    "            for k in range(a[0]):\n",
    "                vv_subtiles = tile_image(vvt_masked[k,:,:],width=tilesize2,height=tilesize2)\n",
    "                vvst_mean = np.ma.mean(vv_subtiles, axis=(1,2))\n",
    "                vvst_std = np.ma.std(vvst_mean)\n",
    "                vv_std[k] = np.ma.std(vvst_mean) \n",
    "            \n",
    "            # find tiles with largest standard deviations\n",
    "            vv_mean = np.ma.median(vvt_masked, axis=(1,2))\n",
    "            x_vv = np.sort(vv_std/vv_mean)\n",
    "            y_vv = np.arange(1, x_vv.size+1) / x_vv.size\n",
    "            \n",
    "            percentile2 = precentile\n",
    "            sort_index = 0\n",
    "            while np.size(sort_index) < 5: \n",
    "                threshold_index_vv = np.ma.min(np.where(y_vv>percentile2))\n",
    "                threshold_vv = x_vv[threshold_index_vv]\n",
    "                #sd_select_vv = np.nonzero(vv_std/vv_mean>threshold_vv)\n",
    "                s_select_vv = np.nonzero(vv_std/vv_mean>threshold_vv) \n",
    "                h_select_vv = np.nonzero(Hpercent > Hpick)               # Includes HAND-EM in selection\n",
    "                sd_select_vv = np.intersect1d(s_select_vv, h_select_vv)\n",
    "            \n",
    "                # find tiles with mean values lower than the average mean\n",
    "                omean_vv = np.ma.median(vv_mean[h_select_vv])\n",
    "                mean_select_vv = np.nonzero(vv_mean<omean_vv)\n",
    "            \n",
    "                # Intersect tiles with large std with tiles that have small means\n",
    "                msdselect_vv = np.intersect1d(sd_select_vv, mean_select_vv)\n",
    "                sort_index = np.flipud(np.argsort(vv_std[msdselect_vv]))\n",
    "                percentile2 = percentile2 - 0.01\n",
    "            finalselect_vv = sort_index[0:5]\n",
    "            \n",
    "            # find local thresholds for 5 \"best\" tiles in the image\n",
    "            l_thresh_vv = np.zeros(5)\n",
    "            EMthresh_vv = np.zeros(5)\n",
    "            temp = np.ma.masked_where(vv_array==0, vv_array)\n",
    "            dbvv = np.ma.log10(temp)+30\n",
    "            scaling = 256/(np.mean(dbvv) + 3*np.std(dbvv))\n",
    "            #scaling = 256/(np.mean(vv_array) + 3*np.std(vv_array))\n",
    "            dbtile = np.ma.log10(vvt_masked)+30\n",
    "            for k in range(5):\n",
    "                test = dbtile[msdselect_vh[finalselect_vh[k]]] * scaling\n",
    "                #test = vvt_masked[msdselect_vv[finalselect_vv[k]]] * scaling\n",
    "                A = np.around(test)\n",
    "                A = A.astype(int)\n",
    "                #t_thresh = Kittler(A)\n",
    "                [posterior, cm, cv, cp] = EMSeg_opt(A, 3)\n",
    "                sorti = np.argsort(cm)\n",
    "                cms = cm[sorti]\n",
    "                cvs = cv[sorti]\n",
    "                cps = cp[sorti]\n",
    "                xvec = np.arange(cms[0],cms[1],step=.05)\n",
    "                x1 = make_distribution(cms[0], cvs[0], cps[0], xvec)\n",
    "                x2 = make_distribution(cms[1], cvs[1], cps[1], xvec)\n",
    "                dx = np.abs(x1 - x2)\n",
    "                diff1 = posterior[:,:,0] - posterior[:,:,1]\n",
    "                t_ind = np.argmin(dx)\n",
    "                EMthresh_vv[k] = xvec[t_ind]/scaling\n",
    "                \n",
    "                #l_thresh_vv[k] = t_thresh / scaling\n",
    "                #dbtile = np.ma.log10(vvt_masked)+30\n",
    "                \n",
    "                # Mark Tiles used for Threshold Estimation\n",
    "                vv_picktiles[msdselect_vh[finalselect_vh[k]],:,:]= np.ones_like(vv_tiles[msdselect_vh[finalselect_vh[k]],:,:])\n",
    "            \n",
    "            # Calculate best threshold for VV and VH as the mean of the 5 thresholds calculated in the previous section \n",
    "            #m_thresh_vv = np.median(l_thresh_vv)\n",
    "            #print(EMthresh_vv-30)\n",
    "            EMts = np.sort(EMthresh_vv)\n",
    "            #m_thresh_vv = np.median(EMthresh_vv)\n",
    "            m_thresh_vv = np.median(EMts[0:4])\n",
    "            print(\"Best VV Flood Mapping Threshold [dB]: %.2f\" % (10*(m_thresh_vv-30)))\n",
    "            print(\" \")\n",
    "            \n",
    "            # Derive flood mask using the best threshold\n",
    "            if m_thresh_vv < (vv_corr/10.0+30):\n",
    "                change_mag_mask_vv = np.ma.masked_where(dbvv==0, dbvv) < m_thresh_vv\n",
    "                vv_thresholds_corr = np.append(vv_thresholds_corr, 10.0*(m_thresh_vv-30))\n",
    "                #change_mag_mask_vv = np.ma.masked_where(vv_array==0, vv_array) < m_thresh_vv\n",
    "            else:\n",
    "                change_mag_mask_vv = np.ma.masked_where(dbvv==0, dbvv) < (vv_corr/10.0+30)\n",
    "                vv_thresholds_corr = np.append(vv_thresholds_corr, vv_corr)\n",
    "            \n",
    "            # Create Binary masks showing flooded pixels as \"1\"s\n",
    "            flood_vv = np.zeros_like(vv_array)\n",
    "            sel = np.ones_like(vv_array)\n",
    "            flood_vv[change_mag_mask_vv] = sel[change_mag_mask_vv]\n",
    "            np.putmask(flood_vv,vv_array==0 , 0)\n",
    "            \n",
    "            # Export flood maps as GeoTIFFs\n",
    "            filename, ext = Path(tiff).name.split('.')\n",
    "            outfile = str(mask_directory/f\"{filename}_water_mask.{ext}\")\n",
    "            write_mask_to_file(flood_vv, outfile, f.GetProjection(), f.GetGeoTransform())\n",
    "        \n",
    "        else:\n",
    "            vh_array = pad_image(f.ReadAsArray(), tilesize)\n",
    "            invalid_pixels = np.nonzero(vh_array == 0.0)\n",
    "            vh_tiles = tile_image(vh_array,width=tilesize,height=tilesize)\n",
    "            a = np.shape(vh_tiles)\n",
    "            vh_std = np.zeros(a[0])\n",
    "            vht_masked = np.ma.masked_where(vh_tiles==0, vh_tiles)\n",
    "            vh_picktiles = np.zeros_like(vh_tiles)\n",
    "            for k in range(a[0]):\n",
    "                vh_subtiles = tile_image(vht_masked[k,:,:],width=tilesize2,height=tilesize2)\n",
    "                vhst_mean = np.ma.mean(vh_subtiles, axis=(1,2))\n",
    "                vhst_std = np.ma.std(vhst_mean)\n",
    "                vh_std[k] = np.ma.std(vhst_mean)\n",
    "            \n",
    "            # find tiles with largest standard deviations\n",
    "            vh_mean = np.ma.median(vht_masked, axis=(1,2))\n",
    "            x_vh = np.sort(vh_std/vh_mean)\n",
    "            xm_vh = np.sort(vh_mean)\n",
    "            #x_vh = np.sort(vh_std)            \n",
    "            y_vh = np.arange(1, x_vh.size+1) / x_vh.size\n",
    "            ym_vh = np.arange(1, xm_vh.size+1) / xm_vh.size\n",
    "            \n",
    "            percentile2 = precentile\n",
    "            sort_index = 0\n",
    "            while np.size(sort_index) < 5:\n",
    "                threshold_index_vh = np.ma.min(np.where(y_vh>percentile2))\n",
    "                threshold_vh = x_vh[threshold_index_vh]\n",
    "                #sd_select_vh = np.nonzero(vh_std/vh_mean>threshold_vh)\n",
    "                s_select_vh = np.nonzero(vh_std/vh_mean>threshold_vh) \n",
    "                h_select_vh = np.nonzero(Hpercent > Hpick)               # Includes HAND-EM in selection\n",
    "                sd_select_vh = np.intersect1d(s_select_vh, h_select_vh)\n",
    "    \n",
    "                # find tiles with mean values lower than the average mean \n",
    "                omean_vh = np.ma.median(vh_mean[h_select_vh])\n",
    "                mean_select_vh = np.nonzero(vh_mean<omean_vh)\n",
    "            \n",
    "                # Intersect tiles with large std with tiles that have small means\n",
    "                msdselect_vh = np.intersect1d(sd_select_vh, mean_select_vh)\n",
    "                sort_index = np.flipud(np.argsort(vh_std[msdselect_vh]))\n",
    "                percentile2 = percentile2 - 0.01\n",
    "            finalselect_vh = sort_index[0:5]\n",
    "    \n",
    "    \n",
    "            # find local thresholds for 5 \"best\" tiles in the image\n",
    "            l_thresh_vh = np.zeros(5)\n",
    "            EMthresh_vh = np.zeros(5)\n",
    "            temp = np.ma.masked_where(vh_array==0, vh_array)\n",
    "            dbvh = np.ma.log10(temp)+30\n",
    "            scaling = 256/(np.mean(dbvh) + 3*np.std(dbvh))\n",
    "            #scaling = 256/(np.mean(vh_array) + 3*np.std(vh_array))\n",
    "            dbtile = np.ma.log10(vht_masked)+30\n",
    "            for k in range(5):\n",
    "                test = dbtile[msdselect_vh[finalselect_vh[k]]] * scaling\n",
    "                #test = vht_masked[msdselect_vh[finalselect_vh[k]]] * scaling\n",
    "                A = np.around(test)\n",
    "                A = A.astype(int)\n",
    "                #t_thresh = Kittler(A)\n",
    "                [posterior, cm, cv, cp] = EMSeg_opt(A, 3)\n",
    "                sorti = np.argsort(cm)\n",
    "                cms = cm[sorti]\n",
    "                cvs = cv[sorti]\n",
    "                cps = cp[sorti]\n",
    "                xvec = np.arange(cms[0],cms[1],step=.05)\n",
    "                x1 = make_distribution(cms[0], cvs[0], cps[0], xvec)\n",
    "                x2 = make_distribution(cms[1], cvs[1], cps[1], xvec)\n",
    "                dx = np.abs(x1 - x2)\n",
    "                diff1 = posterior[:,:,0] - posterior[:,:,1]\n",
    "                t_ind = np.argmin(dx)\n",
    "                EMthresh_vh[k] = xvec[t_ind]/scaling\n",
    "                \n",
    "                #l_thresh_vh[k] = t_thresh / scaling   \n",
    "                \n",
    "                # Mark Tiles used for Threshold Estimation\n",
    "                vh_picktiles[msdselect_vh[finalselect_vh[k]],:,:]= np.ones_like(vh_tiles[msdselect_vh[finalselect_vh[k]],:,:])\n",
    "    \n",
    "            # Calculate best threshold for VV and VH as the mean of the 5 thresholds calculated in the previous section \n",
    "            #m_thresh_vh = np.median(l_thresh_vh)\n",
    "            #print(EMthresh_vh-30)\n",
    "            EMts = np.sort(EMthresh_vh)\n",
    "            #m_thresh_vh = np.median(EMthresh_vh)\n",
    "            m_thresh_vh = np.median(EMts[0:4])\n",
    "            print(\"Best VH Flood Mapping Threshold [dB]: %.2f\" % (10*(m_thresh_vh-30)))\n",
    "            print(\" \")\n",
    "    \n",
    "            # Derive flood mask using the best threshold\n",
    "            maskedarray = np.ma.masked_where(dbvh==0, dbvh)\n",
    "            \n",
    "            #maskedarray = np.ma.masked_where(vh_array==0, vh_array)\n",
    "            if m_thresh_vh < (vh_corr/10.0+30):\n",
    "                change_mag_mask_vh = maskedarray < m_thresh_vh\n",
    "                vh_thresholds_corr = np.append(vh_thresholds_corr, 10.0*(m_thresh_vh-30)) \n",
    "                #change_mag_mask_vv = np.ma.masked_where(vv_array==0, vv_array) < m_thresh_vv\n",
    "            else:\n",
    "                change_mag_mask_vh = maskedarray < (vh_corr/10.0+30)\n",
    "                vh_thresholds_corr = np.append(vh_thresholds_corr, vh_corr) \n",
    "            # change_mag_mask_vh = vh_array < m_thresh_vh\n",
    "    \n",
    "            # Create Binary masks showing flooded pixels as \"1\"s\n",
    "            sel = np.ones_like(vh_array)\n",
    "            flood_vh = np.zeros_like(vh_array)\n",
    "            flood_vh[change_mag_mask_vh] = sel[change_mag_mask_vh]\n",
    "            np.putmask(flood_vh,vh_array==0 , 0)\n",
    "\n",
    "            # Export flood maps as GeoTIFFs\n",
    "            filename, ext = Path(tiff).name.split('.')\n",
    "            outfile = str(mask_directory/f\"{filename}_water_mask.{ext}\")\n",
    "            write_mask_to_file(flood_vh, outfile, f.GetProjection(), f.GetGeoTransform())\n",
    "        \n",
    "    \n",
    "    # Create Maps (Pickfiles) that show which tiles were used for adaptive threshold calculation\n",
    "    vv_picks = vv_picktiles.reshape((n_rows, n_cols, tilesize, tilesize)) \\\n",
    "                .swapaxes(1, 2) \\\n",
    "                .reshape(n_rows * tilesize, n_cols * tilesize)  # yapf: disable\n",
    "    vh_picks = vh_picktiles.reshape((n_rows, n_cols, tilesize, tilesize)) \\\n",
    "                .swapaxes(1, 2) \\\n",
    "                .reshape(n_rows * tilesize, n_cols * tilesize)  # yapf: disable\n",
    "    \n",
    "    # Write Pickfiles to GeoTIFFs\n",
    "    outfile = str(mask_directory/f\"{filename[:-3]}_vv_pickfile.{ext}\")\n",
    "    write_mask_to_file(vv_picks, outfile, f.GetProjection(), f.GetGeoTransform())\n",
    "    outfile = str(mask_directory/f\"{filename[:-3]}_vh_pickfile.{ext}\")\n",
    "    write_mask_to_file(vh_picks, outfile, f.GetProjection(), f.GetGeoTransform())\n",
    "\n",
    "    # Combine VV and VH flood maps to produce a combined flood mapping product\n",
    "    comb = flood_vh + flood_vv\n",
    "    comb_mask = comb > 0\n",
    "    flood_comb = np.zeros_like(vv_array)\n",
    "    flood_comb[comb_mask] = sel[comb_mask]\n",
    "    filename, ext = Path(tiff).name.split('.')\n",
    "    outfile = str(mask_directory/f\"{filename[:-3]}_water_mask_combined.{ext}\")\n",
    "    write_mask_to_file(flood_comb, outfile, f.GetProjection(), f.GetGeoTransform())\n",
    "    \n",
    "    # Create Information on Thresholds used as well as Flood extent information in km2\n",
    "    vv_thresholds = np.append(vv_thresholds, 10.0*(m_thresh_vv-30))\n",
    "    vh_thresholds = np.append(vh_thresholds, 10.0*(m_thresh_vh-30)) \n",
    "    floodarea = np.append(floodarea,(np.sum(flood_comb)*30**2./(1000**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Flood Mapping Results\n",
    "\n",
    "**The code cell below plots the time series of flooded area that was found in the analyzed SAR scenes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = path/'plots'\n",
    "if not plots.exists():\n",
    "    plots.mkdir()\n",
    "\n",
    "dates = get_dates(tiff_dir, '*.tiff')\n",
    "time_index = pd.DatetimeIndex(dates)\n",
    "\n",
    "fig = plt.figure(figsize=(9, 6))\n",
    "ax1 = fig.add_subplot(311)  # 121 determines: 2 rows, 2 plots, first plot\n",
    "ax2 = fig.add_subplot(312)\n",
    "ax3 = fig.add_subplot(313)\n",
    "fig.suptitle('Plots of Water Mapping Thresholds over Time')\n",
    "ax1.plot(np.unique(time_index), vv_thresholds_corr, color='0.5', marker='o', markersize=3, linewidth=1, label='Corrected Thresholds')\n",
    "ax1.plot(np.unique(time_index), vv_thresholds, color='k', marker='o', markersize=3, label='Adaptive Thresholds')\n",
    "ax1.set_ylim([np.min(vv_thresholds)-.1,np.max(vv_thresholds)+.1])\n",
    "ax1.axhline(y=np.mean(vv_thresholds), color='r', linestyle='--')\n",
    "ax1.axhline(y=np.mean(vv_thresholds_corr), color='0.5', linestyle='--')\n",
    "ax1.set_ylabel('VV Thresholds [log]')\n",
    "ax1.grid()\n",
    "ax1.legend(loc='upper right')\n",
    "\n",
    "ax2.plot(np.unique(time_index), vh_thresholds_corr, color='0.5', marker='o', markersize=3, linewidth=1, label='Corrected Thresholds')\n",
    "ax2.plot(np.unique(time_index), vh_thresholds, color='k', marker='o', markersize=3, label='Adaptive Thresholds')\n",
    "ax2.set_ylim([np.min(vh_thresholds)-.1,np.max(vh_thresholds)+.1])\n",
    "ax2.axhline(y=np.mean(vh_thresholds), color='r', linestyle='--')\n",
    "ax2.axhline(y=np.mean(vh_thresholds_corr), color='0.5', linestyle='--')\n",
    "ax2.set_ylabel('VH Thresholds [log]')\n",
    "ax2.grid()\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "ax3.plot(np.unique(time_index), floodarea, color='b', marker='o', markersize=3, label='Flood Area [$km^2$]')\n",
    "ax3.set_ylim([np.min(floodarea)-10,np.max(floodarea)+10])\n",
    "ax3.set_xlabel('Date')\n",
    "ax3.axhline(y=np.mean(floodarea), color='r', linestyle='--')\n",
    "ax3.set_ylabel('Flood Area [$km^2$]')\n",
    "ax3.grid()\n",
    "figname = ('ThresholdAndAreaTS.png')\n",
    "ax3.legend(loc='upper right')\n",
    "plt.savefig(plots/f'{figname}', dpi=300, transparent='true')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following code cells allow you to visualize individual flood maps superimposed on the respective SAR image they were derived from.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpaths = list((path/f\"Water_Masks\").rglob(\"*combined.tif*\"))\n",
    "wpaths_cmd = ' '.join(str(w) for w in wpaths)\n",
    "\n",
    "vrtcommand = f\"gdalbuildvrt -separate {path}/Water.vrt {wpaths_cmd}\"\n",
    "!{vrtcommand}\n",
    "water_file = path/\"Water.vrt\"\n",
    "\n",
    "spaths = list(tiff_dir.rglob(f\"*VV.tif*\"))\n",
    "spaths_cmd = ' '.join(str(s) for s in spaths)\n",
    "vrtcommand = f\"gdalbuildvrt -separate {path}/SAR.vrt {spaths_cmd}\"\n",
    "!{vrtcommand}\n",
    "SAR_file = path/\"SAR.vrt\"\n",
    "\n",
    "img = gdal.Open(str(SAR_file))\n",
    "wm = gdal.Open(str(water_file))\n",
    "SARstack = img.ReadAsArray(5, 20, 5, 5)\n",
    "SARsize = np.shape(SARstack)\n",
    "SARbands = SARsize[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please change the `band_num` setting in the next code cell** to visualize flood mapping results for different SAR image acquisition dates.\n",
    "\n",
    "Note the tool bar in the bottom left corner of the image that's created. Feel free to use the toolbar to zoom into the image and navigate around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_num = 7# Change the band number to visualize different SAR acquisitions and respective flood mapping results.\n",
    "if band_num > SARbands:\n",
    "    band_num = SARbands\n",
    "\n",
    "SARraster = img.GetRasterBand(band_num).ReadAsArray()\n",
    "waterraster = wm.GetRasterBand(band_num).ReadAsArray()\n",
    "water_masked = np.ma.masked_where(waterraster==0, waterraster)\n",
    "waterraster = 0\n",
    "plt.figure(figsize=(9, 6))\n",
    "vmin = np.percentile(SARraster, 5)  #vh_array\n",
    "vmax = np.percentile(SARraster, 95)\n",
    "plt.imshow(SARraster, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "plt.suptitle(f'Water Mask on SAR Image: {time_index.year[band_num]} / {time_index.month[band_num]} / {time_index.day[band_num]}')\n",
    "plt.grid()\n",
    "_ = plt.imshow(water_masked, cmap='Blues',vmin=0, vmax=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>EXERCISE</u>:  </font> Analyze the Quality of the Water Masks</b></font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Look at different Flood Maps for your 16 dates and evaluate the performance of the flood map. To do so, use the toolbar in the bottom left corner of the image above to zoom in and navigate around: \n",
    "- Zoom into the map and look at the details. Are there some pxiels that you would have added to the mask? \n",
    "- If you think flood areas were missed, do you seen anything in the underlying image that may explain why a pixel was not detected? </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Summary Statistics\n",
    "\n",
    "Once flood maps for each individual image acquisition date were created, summary statistics can be derived that describe the severity and duration of an event. In the following, **we will be deriving a metric describing how many days each image pixel was inundated during an analyzed event**. This should provide a template for other metrics to be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rasterstack = wm.ReadAsArray()\n",
    "srs = np.shape(rasterstack)\n",
    "floodcount = np.sum(rasterstack,0)\n",
    "floodpercent = floodcount / srs[0] * 100\n",
    "dt = time_index.dayofyear[SARbands] - time_index.dayofyear[0]\n",
    "flooddays = floodpercent / 100 * dt\n",
    "rasterstack = 0\n",
    "fd_masked = np.ma.masked_where(flooddays==0, flooddays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SARraster = img.GetRasterBand(SARbands).ReadAsArray()\n",
    "plt.figure(figsize=(9, 6))\n",
    "vmin = np.percentile(SARraster, 5)  #vh_array\n",
    "vmax = np.percentile(SARraster, 95)\n",
    "plt.suptitle('Number of Inundated Days Per Pixel - Minimum SAR Image as Background')\n",
    "plt.imshow(SARraster, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "im = plt.imshow(fd_masked, cmap='jet')\n",
    "plt.colorbar(im, orientation='vertical')\n",
    "plt.grid()\n",
    "outfile = mask_directory/f\"flooddays.tif\"\n",
    "write_mask_to_file(flooddays, str(outfile), img.GetProjection(), img.GetGeoTransform())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>EXERCISE</u>:  </font> Analyze the Summary Statistic Plot</b></font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Look at different colors in the plot above and try to understand what they mean and whether or not they make sense to you. To do so, use the toolbar in the bottom left corner of the image above to zoom in and navigate around. </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*FloodMappingFromSARImages.ipynb - version 1.5.1 February 2024*\n",
    "\n",
    "*Version Changes:*\n",
    "\n",
    "- *Don't hardcode path to data directory*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.local-hydrosar]",
   "language": "python",
   "name": "conda-env-.local-hydrosar-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
