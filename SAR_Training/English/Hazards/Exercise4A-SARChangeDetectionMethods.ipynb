{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "hide_input": false
   },
   "source": [
    "![OpenSARlab notebook banner](NotebookAddons/blackboard-banner.png)\n",
    "\n",
    "# An Introduction to Simple SAR Change Detection Methods\n",
    "<img src=\"NotebookAddons/UAFLogo_A_647.png\" style=\"padding:7px;\" width=\"170\" align=\"right\" />\n",
    "\n",
    "### Franz J Meyer; University of Alaska Fairbanks\n",
    "\n",
    "This notebook introduces you to a some popular change detection methods that can be applied to SAR time series data. SAR is an excellent tool for change detection. As SAR sensors are weather and illumination independent and carry their own illumination source (active sensor). Differences between repeated images are a direct indication of changes on the surface. This fact is exploited by the change detection methods introduced below. \n",
    "    \n",
    "The exercise is done in the framework of *Jupyter Notebooks*. The Jupyter Notebook environment is easy to launch in any web browser for interactive data exploration with provided or new training data. Notebooks are comprised of text written in a combination of executable python code and markdown formatting including latex style mathematical equations. Another advantage of Jupyter Notebooks is that they can easily be expanded, changed, and shared with new data sets or newly available time series steps. Therefore, they provide an excellent basis for collaborative and repeatable data analysis.\n",
    "\n",
    "<img style=\"padding:7px;\" src=\"NotebookAddons/OpenSARlab_logo.svg\" width=\"170\" align=\"right\" />\n",
    "\n",
    "**This notebook covers the following data analysis concepts:**\n",
    "\n",
    "- Time series metrics  95$^{th}$ and 5$^{th}$ percentile difference thresholding\n",
    "- Time series coefficient of variation thresholding\n",
    "- Log Ratio-based change detection from image pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "---\n",
    "**Important Note about JupyterHub**\n",
    "\n",
    "Your JupyterHub server will automatically shutdown when left idle for more than 1 hour. Your notebooks will not be lost but you will have to restart their kernels and re-run them from the beginning. You will not be able to seamlessly continue running a partially run notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import url_widget as url_w\n",
    "notebookUrl = url_w.URLWidget()\n",
    "display(notebookUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "\n",
    "notebookUrl = notebookUrl.value\n",
    "user = !echo $JUPYTERHUB_USER\n",
    "env = !echo $CONDA_PREFIX\n",
    "if env[0] == '':\n",
    "    env[0] = 'Python 3 (base)'\n",
    "if env[0] != '/home/jovyan/.local/envs/rtc_analysis':\n",
    "    display(Markdown(f'<text style=color:red><strong>WARNING:</strong></text>'))\n",
    "    display(Markdown(f'<text style=color:red>This notebook should be run using the \"rtc_analysis\" conda environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>It is currently using the \"{env[0].split(\"/\")[-1]}\" environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Select the \"rtc_analysis\" from the \"Change Kernel\" submenu of the \"Kernel\" menu.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>If the \"rtc_analysis\" environment is not present, use <a href=\"{notebookUrl.split(\"/user\")[0]}/user/{user[0]}/notebooks/conda_environments/Create_OSL_Conda_Environments.ipynb\"> Create_OSL_Conda_Environments.ipynb </a> to create it.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Note that you must restart your server after creating a new environment before it is usable by notebooks.</text>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "---\n",
    "## 0. Importing Relevant Python Packages\n",
    "\n",
    "In this notebook we will use the following scientific libraries:\n",
    "\n",
    "- [Pandas](https://pandas.pydata.org/) is a Python library that provides high-level data structures and a vast variety of tools for analysis. The great feature of this package is the ability to translate rather complex operations with data into one or two commands. Pandas contains many built-in methods for filtering and combining data, as well as the time-series functionality.\n",
    "- [GDAL](https://www.gdal.org/) is a software library for reading and writing raster and vector geospatial data formats. It includes a collection of programs tailored for geospatial data processing. Most modern GIS systems (such as ArcGIS or QGIS) use GDAL in the background.\n",
    "- [NumPy](http://www.numpy.org/) is one of the principal packages for scientific applications of Python. It is intended for processing large multidimensional arrays and matrices, and an extensive collection of high-level mathematical functions and implemented methods makes it possible to perform various operations with these objects.\n",
    "- [Matplotlib](https://matplotlib.org/index.html) is a low-level library for creating two-dimensional diagrams and graphs. With its help, you can build diverse charts, from histograms and scatterplots to non-Cartesian coordinates graphs. Moreover, many popular plotting libraries are designed to work in conjunction with matplotlib.\n",
    "- [SciPy](https://www.scipy.org/about.html) is a library that provides functions for numerical integration, interpolation, optimization, linear algebra and statistics.\n",
    "\n",
    "**Our first step is to import them:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import datetime # for date\n",
    "from pathlib import Path\n",
    "from os import system\n",
    "\n",
    "import pandas as pd # for DatetimeIndex\n",
    "from osgeo import gdal # for Info\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from matplotlib import rc\n",
    "\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import opensarlab_lib as asfn\n",
    "asfn.jupytertheme_matplotlib_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "---\n",
    "## 1. Load Data Stack\n",
    "\n",
    "<img src=\"NotebookAddons/mapfuego.png\" width=\"250\" style=\"padding:5px;\" align=\"right\" /> \n",
    "\n",
    "This notebook will use a dense 12-day repeat Sentinel-1 C-band SAR data stack. It contains imagery acquired during the year 2018 in Guatemala. The data are already prepared for you. In a later lecture, you will learn how to download and pre-process Sentinel-1 images using the services of the [Alaska Satellite Facility](https://www.asf.alaska.edu/). \n",
    "\n",
    "**2018 Volcán de Fuego eruption**\n",
    "\n",
    "On June 03, 2018, Volcán de Fuego in Guatemala erupted suddenly. 190 people lost their lives. Eruptions continued in June, and November saw a phase of renewed activity. The **pyroclastic flows and lahars** (mudflow) associated with the eruptive episodes also caused great damage to property and crops. \n",
    "\n",
    " <table><tr>\n",
    "<td> <img src=\"NotebookAddons/fuegoash.jpg\" style=\"width: 300px;\"/> </td>\n",
    "<td> <img src=\"NotebookAddons/fuegoash2.jpg\" style=\"width: 300px;\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "*Getty Images*\n",
    "\n",
    "We will use the Sentinel-1 data stack to map land surface changes throughout this period. \n",
    "\n",
    "Before we get started, let's first **create a working directory for this analysis and change into it:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "name = 'fuego'\n",
    "path = Path(f'/home/jovyan/notebooks/SAR_Training/English/Hazards/{name}')\n",
    "\n",
    "if not path.exists():\n",
    "    path.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "We will **retrieve the relevant data** [Amazon Web Service (AWS)](https://aws.amazon.com/) cloud storage bucket **using the following command:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "time_series_path = 's3://asf-jupyter-data/fuego.tar.gz'\n",
    "time_series = path/Path(time_series_path).name\n",
    "!aws --region=us-east-1 --no-sign-request s3 cp $time_series_path $time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Now, let's **unzip the file (overwriting previous extractions) and clean up after ourselves:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "!tar -xvzf {time_series} -C {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## 2. Define Some Python Helper Functions for this Notebook\n",
    "\n",
    "We are defining two helper functions for this notebook:\n",
    "\n",
    "- **CreateGeoTiff()** to write out images\n",
    "- **timeseries_metrics()** to compute various metrics from a time series data stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def create_geotiff(name, array, data_type, ndv, bandnames=None, \n",
    "                   ref_image=None, geo_t=None, projection=None):\n",
    "    # If it's a 2D image we fake a third dimension:\n",
    "    if len(array.shape) == 2:\n",
    "        array = np.array([array])\n",
    "    if ref_image == None and (geo_t == None or projection == None):\n",
    "        raise RuntimeWarning('ref_image or settings required.')\n",
    "    if bandnames != None:\n",
    "        if len(bandnames) != array.shape[0]:\n",
    "            raise RuntimeError(f'Need {Array.shape[0]} bandnames. {len(bandnames)} given')\n",
    "    else:\n",
    "        bandnames = [f'Band {i+1}' for i in range(array.shape[0])]\n",
    "    if ref_image != None:\n",
    "        if not isinstance(ref_image, str):\n",
    "            ref_image = str(ref_image)\n",
    "            \n",
    "        refimg = gdal.Open(ref_image)\n",
    "        geo_t = refimg.GetGeoTransform()\n",
    "        Projection = refimg.GetProjection()\n",
    "    driver = gdal.GetDriverByName('GTIFF')\n",
    "    array[np.isnan(array)] = ndv\n",
    "    dataset = driver.Create(name, array.shape[2], array.shape[1], \n",
    "                            array.shape[0], data_type)\n",
    "    dataset.SetGeoTransform(geo_t)\n",
    "    dataset.SetProjection(projection)\n",
    "    for i, image in enumerate(array, 1):\n",
    "        dataset.GetRasterBand(i).WriteArray(image)\n",
    "        dataset.GetRasterBand(i).SetNoDataValue(ndv)\n",
    "        dataset.SetDescription(bandnames[i-1])\n",
    "    dataset.FlushCache()\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def timeseries_metrics(raster, ndv=np.nan): \n",
    "    # Make us of numpy nan functions\n",
    "    # Check if type is a float array\n",
    "    if not raster.dtype.name.find('float')>-1:\n",
    "        raster = raster.astype(np.float64)\n",
    "    # Set ndv to nan\n",
    "    if not np.isnan(ndv):\n",
    "        raster[np.equal(raster,ndv)] = np.nan\n",
    "    # Build dictionary of the metrics\n",
    "    tsmetrics={}\n",
    "    rperc = np.nanpercentile(raster,[5,50,95], axis=0)\n",
    "    tsmetrics['mean'] = np.nanmean(raster, axis=0)\n",
    "    tsmetrics['max'] = np.nanmax(raster, axis=0)\n",
    "    tsmetrics['min'] = np.nanmin(raster, axis=0)\n",
    "    tsmetrics['range'] = tsmetrics['max'] - tsmetrics['min']\n",
    "    tsmetrics['median'] = rperc[1]\n",
    "    tsmetrics['p5'] = rperc[0]\n",
    "    tsmetrics['p95'] = rperc[2]\n",
    "    tsmetrics['prange'] = rperc[2]-rperc[0]\n",
    "    tsmetrics['var'] = np.nanvar(raster, axis=0)\n",
    "    tsmetrics['std'] = np.sqrt(tsmetrics['var'])\n",
    "    tsmetrics['CV'] = np.abs(tsmetrics['var'] / tsmetrics['mean'])\n",
    "    return tsmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## 3. Define Data Directory and Path to VRT\n",
    "\n",
    "**Create a variable containing the VRT filename and the image acquisition dates:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "pol = 'VH' # you can also try 'VV' later\n",
    "imagefile = path/f'stack{name}_{pol}.vrt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "**Create an index of timedelta64 data with Pandas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "datefile = path/f'dates{name}_{pol}.csv'\n",
    "tindex = pd.DatetimeIndex(open(datefile).read().split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "**Print the bands and dates for all images in the virtual raster table (VRT):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "j = 1\n",
    "print(f\"Bands and dates for {imagefile}\")\n",
    "for i in tindex:\n",
    "    print(\"{:4d} {}\".format(j, i.date()), end=' ')\n",
    "    j += 1\n",
    "    if j%5 == 1:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "---\n",
    "## 4. Create a Time Series Animation to get an Idea of the Dynamics at the Site\n",
    "\n",
    "### 4.1 Load Time Series Stack\n",
    "\n",
    "Now we are ready to create a time series animation from the calibrated SAR data.\n",
    "\n",
    "**First, create a raster from band 0 and a raster stack from all the images:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "img = gdal.Open(str(imagefile))\n",
    "band = img.GetRasterBand(1)\n",
    "raster0 = band.ReadAsArray()\n",
    "band_number = 0 # Needed for updates\n",
    "rasterstack = img.ReadAsArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "print(rasterstack.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "**Print the bands, pixels, and lines:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "print(f\"Number of  bands: {img.RasterCount}\")\n",
    "print(f\"Number of pixels: {img.RasterXSize}\")\n",
    "print(f\"Number of  lines: {img.RasterYSize}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## 4.2 Data Conversion between dB and Power Scales\n",
    "\n",
    "The data at hand are radiometrically terrain corrected images, which are often expressed as terrain flattened $\\gamma^0$ backscattering coefficients. For forest and land cover monitoring applications $\\gamma^0$ is the preferred metric.\n",
    "\n",
    "To use a logarithmic scale instead of the natural power scale, **you can set the following variable to True:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "todB = True\n",
    "\n",
    "labeldB = 'dB' if todB else 'linear'\n",
    "\n",
    "def convert(raster, todB=todB):\n",
    "    if todB:\n",
    "        return 10 * np.ma.log10(raster)\n",
    "    else:\n",
    "        return raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## 4.3 Create Time Series Animation\n",
    "\n",
    "**Create and move into a directory in which to store our plots and animations:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "product_path = path/'plots_and_animations'\n",
    "\n",
    "if not product_path.exists():\n",
    "    product_path.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Now we can **create the information needed to animate our data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = fig.subplots()\n",
    "ax.axis('off')\n",
    "vmin = np.nanpercentile(convert(rasterstack), 1)\n",
    "vmax = np.nanpercentile(convert(rasterstack), 99)\n",
    "\n",
    "im = ax.imshow(convert(raster0), cmap='inferno', vmin=vmin, vmax=vmax)\n",
    "cbar = fig.colorbar(im)\n",
    "cbar.set_label(labeldB)\n",
    "ax.set_title(\"{}\".format(tindex[0].date()))\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "def animate(i):\n",
    "    ax.set_title(\"{}\".format(tindex[i].date()))\n",
    "    im.set_data(convert(rasterstack[i]))\n",
    "\n",
    "# Interval is given in milliseconds\n",
    "ani = animation.FuncAnimation(fig, animate, frames=rasterstack.shape[0], interval=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "**Configure matplotlib's RC settings for the animation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "rc('animation', embed_limit=40971520.0)  # We need to increase the limit maybe to show the entire animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "**Create a javascript animation of the time-series running inline in the notebook:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "**Delete the dummy png** that was saved to the current working directory while generating the javascript animation in the last code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    Path('None0000000.png').unlink()\n",
    "except FileNotFoundError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "**Save the animation (animation.gif):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "ani.save(product_path/f'animation_{labeldB}.gif', writer='pillow', fps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>EXERCISE #1</u>:  </font> Can You See the Impact of the Eruption?</b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Can you see the impact of the ongoing eruption in the SAR images? Can you identify the lahar flows? When did they occur and how far did they reach?\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "---\n",
    "## 5. Computation and Visualization of Time Series Metrics\n",
    "\n",
    "Once a time-series was constructed, we can compute **a set of metrics** for each pixel in the stack:\n",
    "\n",
    "- Mean \n",
    "- Median\n",
    "- Maximum\n",
    "- Minimum\n",
    "- Range (Maximum - Minimum)\n",
    "- 5th Percentile\n",
    "- 95th Percentile\n",
    "- PRange (95th - 5th Percentile)\n",
    "- Variance\n",
    "- Coefficient of Variation (Variance/Mean)\n",
    "\n",
    "---\n",
    "First, we **mask out pixels** that are zero (e.g. beyond the edge of the swath). Then we **calculate the time series metrics:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "mask = (rasterstack == 0)\n",
    "raster = np.ma.array(convert(rasterstack), mask=mask, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "metrics = timeseries_metrics(raster.filled(np.nan), ndv=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "set(metrics.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Let's look at the histograms for the time series variance and coeficient of variation to aid displaying those images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(16,4))\n",
    "ax[0].hist(metrics['var'].flatten(), bins=100, range=np.nanpercentile(metrics['var'], [1,99]))\n",
    "ax[1].hist(metrics['CV'].flatten(), bins=100, range=np.nanpercentile(metrics['CV'], [1,99]))\n",
    "_ = ax[0].set_title('Variance')\n",
    "_ = ax[1].set_title('Coefficient of Variation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# List the metrics keys you want to plot\n",
    "metric_keys=['mean', 'median', 'max', 'min', \n",
    "             'p95', 'p5', 'prange', 'var', 'std', 'CV']\n",
    "fig= plt.figure(figsize=(16,40))\n",
    "idx=1\n",
    "for i in metric_keys:\n",
    "    ax = fig.add_subplot(5,2,idx)\n",
    "    vmin, vmax = np.nanpercentile(metrics[i], [1, 99])\n",
    "    ax.imshow(metrics[i],vmin=vmin,vmax=vmax,cmap='inferno')\n",
    "    ax.set_title(i.upper())\n",
    "    ax.axis('off')\n",
    "    idx+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>EXERCISE #2:</u> </font></b> \n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Can you group the metrics in terms of what they are most sensitive to? How would you expect the sensitivity of each metric to change if you switched from dB to linearly scaled images?\n",
    "</font></font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "You might have noticed white patches in the images above. These do not contain any data. The reason is that they are in the radar shadow of terrain that is closer to the satellite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "You might have noticed white patches in the images above. These do not contain any data. The reason is that they are in the radar shadow of terrain that is closer to the satellite.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Some Popular SAR Change Detection Methods\n",
    "\n",
    "This section will introduce you to the following popular and simple change detection methods:\n",
    "\n",
    "- Time series metrics  95$^{th}$ and 5$^{th}$ percentile difference and standard deviation thresholding\n",
    "- Time series coefficient of variation thresholding\n",
    "\n",
    "---\n",
    "### 6.1 Change Detection with the Percentile Difference and the Variance Threshold Method\n",
    "\n",
    "In this method we find thresholds on the **95$^{th}$ and 5$^{th}$ percentile difference** or the **temporal pixel-by-pixel gray value cariance**. Let's start with the 95$^{th}$ and 5$^{th}$ percentile difference. The advantage to look at percentiles verus maximum minus minimum is that it is more robust to outliers.\n",
    "\n",
    "First, let us define a **function for plotting histograms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def plot_histogram_cdf(metric):\n",
    "    plt.rcParams.update({'font.size': 12})\n",
    "    fig = plt.figure(figsize=(14, 4)) # Initialize figure with a size\n",
    "    ax1 = fig.add_subplot(121)  # 121 determines: 2 rows, 2 plots, first plot\n",
    "    ax2 = fig.add_subplot(122)\n",
    "\n",
    "    h = ax1.hist(\n",
    "        metrics[metric].flatten(), bins=200, range=np.nanpercentile(metrics[metric], [1, 99]))\n",
    "    ax1.xaxis.set_label_text(f'{metric} {labeldB}')\n",
    "    ax1.set_title('Histogram')\n",
    "\n",
    "    n, bins, patches = ax2.hist(\n",
    "        metrics[metric].flatten(), bins=200, range=np.nanpercentile(metrics[metric], [1, 99]),\n",
    "        cumulative='True', density='True', histtype='step', label='Empirical')\n",
    "    ax2.xaxis.set_label_text(f'{metric} {labeldB}')\n",
    "    ax2.set_title('CDF')\n",
    "\n",
    "    outind = np.where(n > 0.95)\n",
    "    threshind = np.min(outind)\n",
    "    thresh = bins[threshind]\n",
    "    ax1.axvline(thresh,color='red')\n",
    "    _ = ax2.axvline(thresh,color='red')\n",
    "    plt.savefig(product_path/f'{metric}_{labeldB}_histogram.png',\n",
    "            dpi=200, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "**Now let's look at the 95th - 5th percentile range**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "plot_histogram_cdf(metric='prange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Let's visualize the 5% of all pixels with the largest (95th - 5th percentile) difference in the time series. We will refer to the pixels (x,y) that exceed this threshold $t$ as likely **change pixels (cp):**\n",
    "\n",
    "${cp}_{x,y} = P_{x,y}^{95th} - P_{x,y}^{5th} > t$ \n",
    "\n",
    "If we define $t$ to correspond to the 5% of pixels with highest (95th - 5th percentile) difference, the image looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def plot_threshold_classifier(metric='prange', percentage_cutoff=5):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    thresh = np.nanpercentile(metrics[metric], 100 - percentage_cutoff)\n",
    "    mask = metrics[metric] < thresh # For display we prepare the inverse mask\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    _=plt.title(f'Threshold Classifier on {metric} > %1.3f' % thresh)\n",
    "    plt.savefig(product_path/f'changes_{metric}_{labeldB}.png',\n",
    "                dpi=200, transparent='true')\n",
    "    return np.logical_not(mask)\n",
    "\n",
    "metric = 'prange'\n",
    "masks = {metric: plot_threshold_classifier(metric=metric)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>EXERCISE #3:</u> </font></b> \n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Discuss what you see in this figure. What are the black areas? What are the white areas? What kind of changes may be included in this map?\n",
    "</font></font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Instead of applying a threshold on the 95th - 5th percentile difference data, we can also attempt to threshold other metrics. The **standard deviation** (or variance) variable seems a useful indicator for change as it identifies pixels for which radar brightness has changed strongly within the time series. Hence, in the following we use this metric for change identification according to:\n",
    "\n",
    "${cp}_{x,y} = \\sigma > t$ \n",
    "\n",
    "with $t=CDF_{\\sigma} > 0.95$ (5% pixels with highest standard deviation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "plot_histogram_cdf(metric='std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "metric = 'std'\n",
    "masks[metric] = plot_threshold_classifier(metric=metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## 6.2 Change Detection with the Coefficient of Variation Method\n",
    "\n",
    "We can also set a threshold $t$ for the **coefficient of variation image**\n",
    "to classify change in the time series:\n",
    "    \n",
    "${CV}_{x,y} = \\frac{\\sigma_{x,y}}{\\overline{X}_{x,y}} > t$ \n",
    "\n",
    "Let's look at the histogram and the Cumulative Distribution Function (CDF) of the coefficient of variation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "plot_histogram_cdf(metric='CV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "With a threshold of $t=CDF_{CV} > 0.95$ (5% pixels with highest variance) the change pixels would look like the following image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "metric = 'CV'\n",
    "masks[metric] = plot_threshold_classifier(metric=metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## 6.3 Pair-wise change detection\n",
    "\n",
    "To analyze temporal changes between two images, it is useful to compute metrics that are sensitive to discrepancies between the two images. In radar remote sensing, the standard way is to look at ratios (in the linearly scaled power domain) or, equivalently, at differences in the logarithmic dB domain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "dates = ('2018-05-27', '2018-06-08') # around first eruption\n",
    "\n",
    "# convert to datetime objects\n",
    "dates_ = [datetime.datetime.strptime(date, '%Y-%m-%d') for date in dates]\n",
    "\n",
    "# get the indices in one line\n",
    "dates_ind = [np.argmin(np.abs(date - tindex)) for date in dates_]\n",
    "print(f'Comparing image {dates_ind[0]} from {tindex[dates_ind[0]].date()} with {dates_ind[1]} from {tindex[dates_ind[1]].date()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "**Compute the log ratio in dB**, corresponding to the difference in dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "ratiodB = 10 * np.ma.log10(np.ma.divide(rasterstack[dates_ind[1], ...], rasterstack[dates_ind[0], ...]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "**Let us manually choose a threshold this time**\n",
    "\n",
    "thresh is the threshold, e.g. -2 dB\n",
    "thresh_type determines whether we mask everything below that (lower) or above (upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "thresh = -2\n",
    "thresh_type = 'lower' #'lower': mask everything below thresh, 'upper': mask everything above\n",
    "\n",
    "dynamic_range = np.nanpercentile(np.abs(ratiodB), 99)\n",
    "fig, axs = plt.subplots(ncols=3, nrows=1)\n",
    "fig.suptitle(f'{tindex[dates_ind[0]].date()} to {tindex[dates_ind[-1]].date()}     ', ha='right', fontsize='15')\n",
    "fig.set_size_inches(20, 4)\n",
    "plt.subplots_adjust(hspace=0.4, right=0.85)\n",
    "h = axs[0].hist(\n",
    "        ratiodB.flatten(), bins=200, range=np.nanpercentile(ratiodB, [0.1, 99.9]))\n",
    "axs[0].xaxis.set_label_text(f'difference [dB]')\n",
    "axs[0].set_title('Histogram')\n",
    "mask = (ratiodB > thresh if thresh_type == 'lower' else ratiodB < thresh).astype(np.int8)\n",
    "axs[1].imshow(mask, cmap='gray')\n",
    "axs[1].set_title('Mask')\n",
    "im0 = axs[2].imshow(ratiodB, cmap='RdBu', vmin=-dynamic_range, vmax=dynamic_range)\n",
    "cbar = fig.colorbar(im0, orientation='vertical', ax=axs.ravel().tolist())\n",
    "cbar.set_label('[dB]')\n",
    "axs[2].set_title('Image')\n",
    "logratiolabel = f'logratio_{tindex[dates_ind[0]].date()}_{tindex[dates_ind[0]].date()}'\n",
    "plt.savefig(product_path/f'{logratiolabel}.png',\n",
    "            dpi=200, transparent='true')\n",
    "masks[logratiolabel] = np.logical_not(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "**Do you think the threshold is appropriate?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>EXERCISE #4:</u> </font></b> \n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Discuss what you see in this figure: \n",
    "    <ul>\n",
    "        <li>What kind of changes are detected?</li>\n",
    "        <li>How does this change map compare to the previous one? Note that you are only looking at one specific pair of images here.</li>\n",
    "        <li>Feel free to look at other image pairs and analyze identified changes!</li>\n",
    "    </ul>\n",
    "    </font></font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "---\n",
    "## 7. Write Our Change Detection Results and Metrics Images to GeoTIFF files\n",
    "\n",
    "### 7.1 Determine Output Geometry\n",
    "\n",
    "First, we need to **set the correct geotransformation and projection information**. We retrieve the values from the input images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "proj = img.GetProjection()\n",
    "geotrans = list(img.GetGeoTransform())\n",
    "geotrans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### 7.2 Output Time Series Metrics Images\n",
    "\n",
    "We use the root of the time series data stack name and append a _ts_metrics_&lt;metric&gt;.tif ending as filenames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Time Series Metrics as image image:\n",
    "# We make a new subdirectory where we will store the images\n",
    "dirname = path/f'{name}_tsmetrics'\n",
    "\n",
    "if not dirname.exists():\n",
    "    dirname.mkdir()\n",
    "    \n",
    "print(dirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Now we can **output the individual metrics as GeoTIFF images:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "names=[] # List to keep track of all the names\n",
    "for metric in metrics:\n",
    "    name_ = str(dirname/f'{metric}_{labeldB}.tif')\n",
    "    create_geotiff(name_,metrics[metric], gdal.GDT_Float64, np.nan,[metric],\n",
    "                  geo_t=geotrans, projection=proj)\n",
    "    names.append(name_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### 7.3 Build a Virtual Raster Table on the Metrics GeoTIFF images\n",
    "\n",
    "To tie the images into one new raster stack of time series metrics we build a virtual raster table with all the metrics. \n",
    "\n",
    "Trick: Use ' '.join(names) to build one long string of names separated by a space as input to *gdalbuildvrt*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "cmd='gdalbuildvrt -separate -overwrite -vrtnodata nan '+\\\n",
    "   f'{dirname}_{labeldB}.vrt '+\\\n",
    "    ' '.join(names)\n",
    "# print(cmd)\n",
    "_ = system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### 7.4 Create GeoTIFFs for the Change Images from our Four Change Detection Attempts\n",
    "\n",
    "We are going to write GeoTIFF output files that store the results from the classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "for metric in masks:\n",
    "    fnmetric = str(dirname/f'{name}_{labeldB}_{metric}_thresholds.tif')\n",
    "    create_geotiff(fnmetric, masks[metric], gdal.GDT_Byte, np.nan, \n",
    "                  geo_t=geotrans, projection=proj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>EXERCISE #5:</u> </font></b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Explore the data stack a bit more. Answer the following questions for yourself:\n",
    "\n",
    "<ul>\n",
    "  <li> Which metrics are more appropriate for logarithic (dB) or linearly (power) transformed images?</li>\n",
    "  <li> Change the thresholds and dates in this notebook to see the effects on detected changes.</li>\n",
    "  <li> Load created change masks into QGIS and compare the detected areas with your time series plots and image data.</li>\n",
    "</ul>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>EXERCISE #6:</u> </font></b></font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"4\"><b>2016-2017 flooding</b></font><br>\n",
    "<font face=\"Calibri\" size=\"3\"><br>Explore the flooding data stack from Lab 3 at VV and VH polarization. What can you detect? Compare the minimum method for flood detection from Lab 3 with the results obtained with this notebook.\n",
    "<br><br>\n",
    "To this end, we advise you to restart the notebook (or duplicate it first) by going to 'Kernel' and 'Restart'\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "*Exercise4A-SARChangeDetectionMethods - Version 1.5.0 - November 2021*\n",
    "\n",
    "*Version Changes:*\n",
    "\n",
    "- *asf_notebook -> opensarlab_lib*\n",
    "- *url_widget*\n",
    "- *html -> markdown*"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "rtc_analysis [conda env:.local-rtc_analysis]",
   "language": "python",
   "name": "conda-env-.local-rtc_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
