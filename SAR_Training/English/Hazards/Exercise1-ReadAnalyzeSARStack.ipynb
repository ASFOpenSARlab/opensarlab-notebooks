{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "![OpenSARlab notebook banner](NotebookAddons/blackboard-banner.png)\n",
    "\n",
    "# Exploring SAR Data and SAR Time Series Analysis using Jupyter Notebooks\n",
    "<img style=\"padding:7px;\" src=\"NotebookAddons/UAFLogo_A_647.png\" width=\"170\" align=\"right\" /></font>\n",
    "\n",
    "### Franz J Meyer; University of Alaska Fairbanks & Josef Kellndorfer, [Earth Big Data, LLC](http://earthbigdata.com/)\n",
    "\n",
    "This notebook will introduce you to the analysis of deep multi-temporal SAR image data stacks in the framework of *Jupyter Notebooks*. The Jupyter Notebook environment is easy to launch in any web browser for interactive data exploration with provided or new training data. Notebooks are comprised of text written in a combination of executable python code and markdown formatting including latex style mathematical equations. Another advantage of Jupyter Notebooks is that they can easily be expanded, changed, and shared with new data sets or newly available time series steps. Therefore, they provide an excellent basis for collaborative and repeatable data analysis. <br>\n",
    "\n",
    "**We introduce the following data analysis concepts:**\n",
    "\n",
    "<img style=\"padding:7px;\" src=\"NotebookAddons/OpenSARlab_logo.svg\" width=\"170\" align=\"right\" />\n",
    "\n",
    "- How to load SAR data into Jupyter Notebooks and create a time series stack \n",
    "- How to create a time series of your subset data.\n",
    "- How to explore the time-series information in SAR data stacks for environmental analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Important Note about JupyterHub**\n",
    "\n",
    "Your JupyterHub server will automatically shutdown when left idle for more than 1 hour. Your notebooks will not be lost but you will have to restart their kernels and re-run them from the beginning. You will not be able to seamlessly continue running a partially run notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**0. Importing Relevant Python Packages**\n",
    "\n",
    "In this notebook we will use the following scientific libraries:\n",
    "\n",
    "- [Pandas](https://pandas.pydata.org/) is a Python library that provides high-level data structures and a vast variety of tools for analysis. The great feature of this package is the ability to translate rather complex operations with data into one or two commands. Pandas contains many built-in methods for filtering and combining data, as well as the time-series functionality.\n",
    "- [GDAL](https://www.gdal.org/) is a software library for reading and writing raster and vector geospatial data formats. It includes a collection of programs tailored for geospatial data processing. Most modern GIS systems (such as ArcGIS or QGIS) use GDAL in the background.\n",
    "- [NumPy](http://www.numpy.org/) is one of the principal packages for scientific applications of Python. It is intended for processing large multidimensional arrays and matrices, and an extensive collection of high-level mathematical functions and implemented methods makes it possible to perform various operations with these objects.\n",
    "- [Matplotlib](https://matplotlib.org/index.html) is a low-level library for creating two-dimensional diagrams and graphs. With its help, you can build diverse charts, from histograms and scatterplots to non-Cartesian coordinates graphs. Moreover, many popular plotting libraries are designed to work in conjunction with matplotlib.\n",
    "- [SciPy](https://www.scipy.org/about.html) is a library that provides functions for numerical integration, interpolation, optimization, linear algebra and statistics.\n",
    "\n",
    "**Our first step is to import them:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import url_widget as url_w\n",
    "notebookUrl = url_w.URLWidget()\n",
    "display(notebookUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "\n",
    "notebookUrl = notebookUrl.value\n",
    "user = !echo $JUPYTERHUB_USER\n",
    "env = !echo $CONDA_PREFIX\n",
    "if env[0] == '':\n",
    "    env[0] = 'Python 3 (base)'\n",
    "if env[0] != '/home/jovyan/.local/envs/rtc_analysis':\n",
    "    display(Markdown(f'<text style=color:red><strong>WARNING:</strong></text>'))\n",
    "    display(Markdown(f'<text style=color:red>This notebook should be run using the \"rtc_analysis\" conda environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>It is currently using the \"{env[0].split(\"/\")[-1]}\" environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Select the \"rtc_analysis\" from the \"Change Kernel\" submenu of the \"Kernel\" menu.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>If the \"rtc_analysis\" environment is not present, use <a href=\"{notebookUrl.split(\"/user\")[0]}/user/{user[0]}/notebooks/conda_environments/Create_OSL_Conda_Environments.ipynb\"> Create_OSL_Conda_Environments.ipynb </a> to create it.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Note that you must restart your server after creating a new environment before it is usable by notebooks.</text>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from pathlib import Path\n",
    "from math import ceil\n",
    "\n",
    "import pandas as pd # for DatetimeIndex\n",
    "from osgeo import gdal # for Info\n",
    "import numpy as np # for copy, isnan, log10, ma.masked_where, max, mean, min, percentile, power, unique, var, where \n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from matplotlib import rc\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import opensarlab_lib as asfn\n",
    "asfn.jupytertheme_matplotlib_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Analyzing a data stack: La Amazon√≠a\n",
    "\n",
    "<img src='NotebookAddons/map.png' align='right' width=230><br><br>\n",
    "\n",
    "### 1.1. Overview\n",
    "\n",
    "We will study a small subset of a Sentinel-1 stack along the Napo River, 30 km east of Coca.\n",
    "\n",
    "The stack consists of 76 VV and VH (cross-pol) images each from July 2017 to July 2019.\n",
    "\n",
    "<img src='NotebookAddons/tree.png' align='center' width=400>\n",
    "\n",
    "<font face=\"Calibri\" size=\"1\" align='left'><div style=\"text-align: left\">Picture by Josselyn Encarnacion.</div></font>\n",
    "\n",
    "### 1.2. Background\n",
    "\n",
    "The low-lying area is covered by a mosaic of tropical rainforest and cleared areas, including plantations.  \n",
    "\n",
    "<img src='NotebookAddons/lagoagrio.png' align='center' width=400>\n",
    "\n",
    "The region receives more than 3000mm of rainfall per year. Although there are clear seasonal variations, precipitation is elevated throughout the year (see the observations from Lago Agrio/Nueva Loja, taken from the WMO website). There are no strong seasonal variations in temperature. \n",
    "\n",
    "---\n",
    "\n",
    "## 2. Load the data\n",
    "\n",
    "First, let us **create a directory to hold our data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'tropical'\n",
    "analysis_dir = Path(f\"/home/jovyan/notebooks/SAR_Training/English/Hazards/{name}\")\n",
    "if not analysis_dir.exists():\n",
    "    analysis_dir.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download the prepared stack**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = 's3://asf-jupyter-data/tropical.tar.gz'\n",
    "time_series_path = Path(s3_path).name\n",
    "!aws --region=us-east-1 --no-sign-request s3 cp $s3_path {analysis_dir/time_series_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract all files from the arcive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tar -xvzf {analysis_dir/'tropical.tar.gz'} -C {analysis_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Define Data Directory and Path to VRT\n",
    "\n",
    "A VRT file is a virtual image that groups together multiple images as bands. In our case, the bands correspond to acquisition times.\n",
    "    \n",
    "**Create a variable containing the VRT filename for each polarization:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarizations = ['VV', 'VH']\n",
    "imagefile = {pol: analysis_dir/f'stacktropical_{pol}.vrt' for pol in polarizations}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create an index of timedelta64 data with Pandas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'dates{name}_VV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some indices for plotting\n",
    "datefile = {pol: analysis_dir/f'dates{name}_{pol}.csv' for pol in polarizations}\n",
    "tindex = {pol: pd.DatetimeIndex(open(datefile[pol]).read().split(',')) for pol in polarizations}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the bands and dates for all images in the virtual raster table (VRT):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 1\n",
    "print(f\"Bands and dates for {imagefile[polarizations[0]]}\")\n",
    "for i in tindex[polarizations[0]]:\n",
    "    print(\"{:4d} {}\".format(j, i.date()), end=' ')\n",
    "    j += 1\n",
    "    if j%5 == 1:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.2 Open Your Data Stack\n",
    "\n",
    "We will store the **opened VRT** of each polarization in a dictionary data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = {pol: gdal.Open(str(imagefile[pol])) for pol in polarizations}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the bands (time instances), pixels, and lines:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarization = 'VV' # we will focus on VV for now\n",
    "print(f\"{polarization}: Number of  bands: {img[polarization].RasterCount}\")\n",
    "print(f\"{polarization}: Number of pixels: {img[polarization].RasterXSize}\")\n",
    "print(f\"{polarization}: Number of  lines: {img[polarization].RasterYSize}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Reading Data from an Image Band\n",
    "\n",
    "**To access any band in the image, use GDAL's *GetRasterBand(x)* function. Replace the band_num value with the number of the band you wish to access.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_num = 4 # starts at 1\n",
    "print(f'Accessing band {tindex[polarization][band_num - 1]}') # index starts at zero\n",
    "band = img[polarization].GetRasterBand(band_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a band is seleted, several functions associated with the band are available for further processing, e.g., *band.ReadAsArray(xoff=0,yoff=0,xsize=None,ysize=None)*\n",
    "\n",
    "**Let's read the entire raster layer for the band:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster = band.ReadAsArray()\n",
    "print(f'This is a two-dimensional array of size {raster.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Extracting Subsets from a Larger Image Frame\n",
    "\n",
    "Because of the potentially large data volume when dealing with time series data stacks, it may be prudent to read only a subset of data. \n",
    "\n",
    "Using GDAL's *ReadAsArray()* function, subsets can be requested by defining pixel offsets and subset size:\n",
    "\n",
    "**img.ReadAsArray(xoff=0, yoff=0, xsize=None, ysize=None)**\n",
    "\n",
    "- *xoff, yoff* are the offsets from the upper left corner in pixel/line coordinates. \n",
    "- *xsize, ysize* specify the size of the subset in x-direction (left to right) and y-direction (top to bottom).\n",
    "\n",
    "For example, we can **read only a subset of 5x5 pixels with an offset of 5 pixels and 20 lines:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_sub = band.ReadAsArray(5, 20, 50, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a two dimensional numpy array in the datatpye the data were stored in. **We can inspect these data in python by typing the array name on the commandline**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Visualize single images\n",
    "\n",
    "### 3.1. Write a Plotting Function\n",
    "\n",
    "Matplotlib's plotting functions allow for powerful options to display imagery. We are following some standard approaches for setting up figures.\n",
    "First we are looking at a **raster band** and it's associated **histogram**.\n",
    "\n",
    "Our function, *show_image()* takes several parameters:\n",
    "    \n",
    "- raster = a numpy two dimensional array \n",
    "- tindex = a panda index array for dates\n",
    "- bandnbr = the band number the corresponds to the raster \n",
    "- vmin = minimim value to display \n",
    "- vmax = maximum value to display\n",
    "- output_filename = name of output file, if saving the plot\n",
    "\n",
    "It then calls a function called plot_image_histogram that does the actual plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_histogram(axs, raster, tindex, band_nbr, vmin=None, vmax=None, polarization='Band'):\n",
    "    # plot image\n",
    "    vmin = np.percentile(raster, 1) if vmin==None else vmin\n",
    "    vmax = np.percentile(raster, 99) if vmax==None else vmax\n",
    "    axs[0].imshow(raster, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    axs[0].set_title('Image {} {} {}'.format(polarization, band_nbr, tindex[band_nbr-1].date()))\n",
    "    \n",
    "    #plot histogram\n",
    "    h = axs[1].hist(raster.flatten(), bins=200, range=(vmin, vmax))\n",
    "    axs[1].xaxis.set_label_text('Intensity ($\\\\gamma^0$)')\n",
    "    axs[1].set_title('Histogram {} {} {}'.format(polarization, band_nbr, tindex[band_nbr-1].date()))\n",
    "\n",
    "def show_image_histogram(raster, tindex, band_nbr, vmin=None, vmax=None, output_filename=None):  \n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2)\n",
    "    fig.set_size_inches((14,7), forward=True)\n",
    "    plt.subplots_adjust(wspace=0.3)\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    plot_image_histogram(axs, raster, tindex, band_nbr, vmin=vmin, vmax=vmax)\n",
    "    if output_filename:\n",
    "        plt.savefig(output_filename, dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Visualize VV image:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarization = 'VV' # you can change this to VH\n",
    "\n",
    "band_num = 50 # feel free to change them\n",
    "\n",
    "raster = img[polarization].GetRasterBand(band_num).ReadAsArray()  \n",
    "print(f'Band {band_num} is from {tindex[polarization][band_num - 1]}')\n",
    "show_image_histogram(raster, tindex[polarization], band_num, vmin=0.1, vmax=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Compare VV and VH:\n",
    "\n",
    "One channel is much smaller than the other. Which one? Do you have to change vmin and vmax to display it properly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=len(polarizations), ncols=2)\n",
    "fig.set_size_inches((12,12), forward=True)\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "vmin = 0.0\n",
    "vmax = 0.4\n",
    "for jpolariztion, polarization in enumerate(polarizations):\n",
    "    raster = img[polarization].GetRasterBand(band_num).ReadAsArray()  \n",
    "    plot_image_histogram(\n",
    "        axs[jpolariztion,:], raster, tindex[polarization], band_num, \n",
    "        vmin=vmin, vmax=vmax, polarization=polarization)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Compare scaling normalizations:\n",
    "\n",
    "The data at hand are radiometrically terrain corrected images, which are often expressed as terrain flattened $\\gamma^0$ backscattering coefficients. For forest and land cover monitoring applications $\\gamma^o$ is the preferred metric.\n",
    "    \n",
    "There are two common ways of scaling the $\\gamma^0$ data.\n",
    "\n",
    "So far, we have looked at the **power scale**, the natural scale in which the intensity is measured. For most mathematical operations such as speckle filtering, this is the appropriate scale. However, its large dynamic range is sometimes an issue for statistical analyses and visualization purposes.<br>\n",
    "\n",
    "The **dB scale** is a logarithmic scale:\n",
    "     $\\gamma^0_{dB} = 10 \\log_{10} (\\gamma^0)$\n",
    "The dynamic range is greatly reduced: A doubling of $\\gamma^0$ corresponds to an additive increase of 3 in $\\gamma^0_{dB}$. The distribution tends to become less skewed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster = img['VV'].GetRasterBand(band_num).ReadAsArray() # gamma 0, power scale\n",
    "rasterdB = 10*np.log10(raster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us look at images in the power and dB scale**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2)\n",
    "fig.set_size_inches((14,7), forward=True)\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "vmin = np.percentile(raster, 2)\n",
    "vmax = np.percentile(raster, 98)\n",
    "axs[0].imshow(raster, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "axs[0].set_title('Power scale')\n",
    "axs[1].imshow(rasterdB, cmap='gray', vmin=10*np.log10(vmin), vmax=10*np.log10(vmax))\n",
    "_ = axs[1].set_title('dB scale')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us look at histograms.**\n",
    "\n",
    "How does the shape of the data distribution compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2)\n",
    "fig.set_size_inches((14,5), forward=True)\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "labels = ['power', 'dB']\n",
    "for jr, r in enumerate([raster, rasterdB]):\n",
    "    rvalid = r[np.isfinite(r)]\n",
    "    axs[jr].hist(rvalid.flatten(), range=np.percentile(rvalid, (0.5, 99.9)), bins=100)\n",
    "    axs[jr].axvline(np.mean(rvalid),color='k',label='Mean')\n",
    "    axs[jr].axvline(np.mean(rvalid)-np.std(rvalid),color='gray',label='1 $\\sigma$')\n",
    "    axs[jr].axvline(np.mean(rvalid)+np.std(rvalid),color='gray')\n",
    "    axs[jr].set_title(labels[jr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Time series\n",
    "\n",
    "### 4.1. Animation\n",
    "\n",
    "**Let us choose the polarization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarization = 'VV'\n",
    "band = img[polarization].GetRasterBand(1)\n",
    "raster0 = band.ReadAsArray() # Needed for initialization\n",
    "band_number = 0 # Needed for initialization\n",
    "rasterstack = img[polarization].ReadAsArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and move into a directory in which to store our plots and animations:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_path = analysis_dir/f\"plots_and_animations\"\n",
    "\n",
    "if not product_path.exists():\n",
    "    product_path.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = fig.subplots()\n",
    "ax.axis('off')\n",
    "rasterstackdB = 10 * np.log10(rasterstack)\n",
    "\n",
    "im = ax.imshow(rasterstackdB[0,...], cmap='gray', vmin=np.nanpercentile(rasterstackdB, 3), \n",
    "               vmax=np.nanpercentile(rasterstackdB, 97))\n",
    "ax.set_title(\"{}\".format(tindex[polarization][0].date()))\n",
    "\n",
    "def animate(i):\n",
    "    ax.set_title(\"{}\".format(tindex[polarization][i].date()))\n",
    "    im.set_data(rasterstackdB[i,...])\n",
    "\n",
    "# Interval is given in milliseconds\n",
    "ani = animation.FuncAnimation(fig, animate, frames=rasterstackdB.shape[0], interval=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configure matplotlib's RC settings for the animation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc('animation', embed_limit=40971520.0)  # We need to increase the limit maybe to show the entire animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a javascript animation of the time-series running inline in the notebook:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Delete the dummy png** that was saved to the current working directory while generating the javascript animation in the last code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    Path('None0000000.png').unlink()\n",
    "except FileNotFoundError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the animation (animation.gif):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.save(f\"{product_path}/animation.gif\", writer='pillow', fps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4.2 Plot the Time Series of Means Calculated Across the Image\n",
    "\n",
    "To create the time series of means, we will go through the following steps:\n",
    "\n",
    "1. Ensure that you use the data in **power scale** ($\\gamma^o_{pwr}$) for your mean calculations.\n",
    "1. Compute means.\n",
    "1. Convert the resulting mean values into dB scale for visualization.\n",
    "1. Plot time series of means.\n",
    "\n",
    "**Compute the means:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_means_pwr = np.nanmean(rasterstack, axis=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert resulting mean value time-series to dB scale for visualization:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_means_dB = 10.*np.log10(rs_means_pwr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot and save the time series of means (RCSoverTime.png):**\n",
    "\n",
    "How does the temporal variability relate to the meteorlogical variability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "ax1 = fig.subplots()\n",
    "window_length = len(rs_means_dB)-1\n",
    "if window_length % 2 == 0:\n",
    "    window_length -= 1\n",
    "polyorder = ceil(window_length*0.1)\n",
    "yhat = savgol_filter(rs_means_dB, window_length, polyorder) \n",
    "ax1.plot(tindex[polarization], yhat, color='red', marker='o', markerfacecolor='white', linewidth=3, markersize=6)\n",
    "ax1.plot(tindex[polarization], rs_means_dB, color='gray', linewidth=0.5)\n",
    "plt.grid()\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('$\\overline{\\gamma^o}$ [dB]')\n",
    "plt.savefig(f\"{product_path}/RCSoverTime.png\", dpi=72, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Create Two-Panel Animation with Global Mean\n",
    "\n",
    "We use a few Matplotlib functions to **create a side-by-side animation of the dB-scaled imagery and the respective global means.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 4), gridspec_kw={'width_ratios':[1, 3]})\n",
    "\n",
    "vmin = np.percentile(rasterstackdB, 1)\n",
    "vmax = np.percentile(rasterstackdB, 99)\n",
    "im = ax1.imshow(rasterstackdB[0, ...], cmap='gray', vmin=vmin, vmax=vmax)\n",
    "ax1.set_title(\"{}\".format(tindex[polarization][0].date()))\n",
    "ax1.set_axis_off()\n",
    "\n",
    "ax2.axis([tindex[polarization][0].date(), tindex[polarization][-1].date(), rs_means_dB.min(), rs_means_dB.max()])\n",
    "ax2.set_ylabel('$\\overline{\\gamma^0}$ [dB]')\n",
    "ax2.set_xlabel('Date')\n",
    "l, = ax2.plot([], [])\n",
    "\n",
    "def animate(i):\n",
    "    ax1.set_title(\"{}\".format(tindex[polarization][i].date()))\n",
    "    im.set_data(rasterstackdB[i,...])\n",
    "    ax2.set_title(\"{}\".format(tindex[polarization][i].date()))\n",
    "    l.set_data(tindex[polarization][0:(i+1)], rs_means_dB[0:(i+1)])\n",
    "\n",
    "# Interval is given in milliseconds\n",
    "ani = animation.FuncAnimation(fig, animate, frames=rasterstackdB.shape[0], interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the animated time-series and histogram (animation_histogram.gif):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.save(f\"{product_path}/animation_histogram.gif\", writer='pillow', fps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise1-ReadAnalyzeSARStack.ipynb - Version 1.5.1 - November 2021*\n",
    "\n",
    "*Version Changes*\n",
    "\n",
    "- *asf_notebook -> opensarlab-lib*\n",
    "- *url-widget*\n",
    "- *html -> markdown*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtc_analysis [conda env:.local-rtc_analysis]",
   "language": "python",
   "name": "conda-env-.local-rtc_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
