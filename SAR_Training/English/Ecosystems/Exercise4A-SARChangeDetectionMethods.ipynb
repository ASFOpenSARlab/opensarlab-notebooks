{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "<img src=\"NotebookAddons/blackboard-banner.jpg\" width=\"100%\" />\n",
    "<font face=\"Calibri\">\n",
    "<br>\n",
    "<font size=\"5\"> <b>An Introduction to Simple SAR Change Detection Methods</b></font>\n",
    "\n",
    "<br>\n",
    "<font size=\"4\"> <b> Franz J Meyer; University of Alaska Fairbanks & Josef Kellndorfer, <a href=\"http://earthbigdata.com/\" target=\"_blank\">Earth Big Data, LLC</a> </b> <br>\n",
    "<img src=\"NotebookAddons/UAFLogo_A_647.png\" style=\"padding:5px;\" width=\"170\" align=\"right\" /></font>\n",
    "\n",
    "<font size=\"3\">This notebook introduces you to a some popular change detection methods that can be applied on SAR time series data. SAR is an excellent tool for change detection. As SAR sensors are weather and illumination independent, and as SAR's carry their own illumination source (active sensor), differences between repeated images are a direct indication of changes on the surface. This fact is exploited by the change detection methods introduced below. \n",
    "    \n",
    "The exercise is done in the framework of *Jupyter Notebooks*. The Jupyter Notebook environment is easy to launch in any web browser for interactive data exploration with provided or new training data. Notebooks are comprised of text written in a combination of executable python code and markdown formatting including latex style mathematical equations. Another advantage of Jupyter Notebooks is that they can easily be expanded, changed, and shared with new data sets or newly available time series steps. Therefore, they provide an excellent basis for collaborative and repeatable data analysis. <br>\n",
    "\n",
    "<b>This notebook covers the following data analysis concepts:</b>\n",
    "\n",
    "- Time series metrics  95$^{th}$ and 5$^{th}$ percentile difference thresholding\n",
    "- Time series coefficient of variation thresholding\n",
    "- Log Ratio-based change detection from image pairs\n",
    "\n",
    "<font color='rgba(200,0,0,0.2)'> <b>Note</b>:</font> The next notebook will add Time Series Change Point Detection as an additional useful method.\n",
    "\n",
    "</font>\n",
    "\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"5\" color='rgba(200,0,0,0.2)'> <b>Important Note about JupyterHub</b> </font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"> <b>Your JupyterHub server will automatically shutdown when left idle for more than 1 hour. Your notebooks will not be lost but you will have to restart their kernels and re-run them from the beginning. You will not be able to seamlessly continue running a partially run notebook.</b> </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\">\n",
    "\n",
    "<font size=\"5\"> <b> 0. Importing Relevant Python Packages </b> </font>\n",
    "\n",
    "<font size=\"3\">In this notebook we will use the following scientific libraries:\n",
    "<ol type=\"1\">\n",
    "    <li> <b><a href=\"https://pandas.pydata.org/\" target=\"_blank\">Pandas</a></b> is a Python library that provides high-level data structures and a vast variety of tools for analysis. The great feature of this package is the ability to translate rather complex operations with data into one or two commands. Pandas contains many built-in methods for filtering and combining data, as well as the time-series functionality. </li>\n",
    "    <li> <b><a href=\"https://www.gdal.org/\" target=\"_blank\">GDAL</a></b> is a software library for reading and writing raster and vector geospatial data formats. It includes a collection of programs tailored for geospatial data processing. Most modern GIS systems (such as ArcGIS or QGIS) use GDAL in the background.</li>\n",
    "    <li> <b><a href=\"http://www.numpy.org/\" target=\"_blank\">NumPy</a></b> is one of the principal packages for scientific applications of Python. It is intended for processing large multidimensional arrays and matrices, and an extensive collection of high-level mathematical functions and implemented methods makes it possible to perform various operations with these objects. </li>\n",
    "    <li> <b><a href=\"https://matplotlib.org/index.html\" target=\"_blank\">Matplotlib</a></b> is a low-level library for creating two-dimensional diagrams and graphs. With its help, you can build diverse charts, from histograms and scatterplots to non-Cartesian coordinates graphs. Moreover, many popular plotting libraries are designed to work in conjunction with matplotlib. </li>\n",
    "    <li> The <b><a href=\"https://www.pydoc.io/pypi/asf-hyp3-1.1.1/index.html\" target=\"_blank\">asf-hyp3 API</a></b> provides useful functions and scripts for accessing and processing SAR data via the Alaska Satellite Facility's Hybrid Pluggable Processing Pipeline, or HyP3 (pronounced \"hype\"). </li>\n",
    "<li><b><a href=\"https://www.scipy.org/about.html\" target=\"_blank\">SciPY</a></b> is a library that provides functions for numerical integration, interpolation, optimization, linear algebra and statistics. </li>\n",
    "\n",
    "</font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Our first step is to <b>import them:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # for chdir, getcwd, path.exists\n",
    "import datetime # for date\n",
    "\n",
    "import pandas as pd # for DatetimeIndex\n",
    "from osgeo import gdal # for Info\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "import matplotlib.patches as patches  # for Rectangle\n",
    "from matplotlib import rc\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "from asf_notebook import path_exists\n",
    "from asf_notebook import asf_unzip\n",
    "from asf_notebook import new_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Setup matplotlib plotting</b> inside the notebook:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\">\n",
    "\n",
    "<font size=\"5\"> <b> 1. Load Data Stack</b> </font> <img src=\"NotebookAddons/Deforest-MadreDeDios.jpg\" width=\"350\" style=\"padding:5px;\" align=\"right\" /> \n",
    "\n",
    "<font size=\"3\"> This notebook will again be using a 78-image deep dual-polarization C-band SAR data stack over Madre de Dios in Peru to demonstrate how to create color composites from multi temporal and dual-polarization SAR data and how to derive higher level parameters such as the multi-temporal mean, the coefficient of variation, and others. The C-band data were acquired by ESA's Sentinel-1 SAR sensor constellation and are available to you through the services of the <a href=\"https://www.asf.alaska.edu/\" target=\"_blank\">Alaska Satellite Facility</a>. \n",
    "\n",
    "The site in question is interesting as it has experienced extensive logging over the last 10 years (see image to the right; <a href=\"https://blog.globalforestwatch.org/\" target=\"_blank\">Monitoring of the Andean Amazon Project</a>). Since the 1980s, people have been clearing forests in this area for farming, cattle ranching, logging, and (recently) gold mining. Creating RGB color composites is an easy way to visualize ongoing changes in the landscape.\n",
    "</font></font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\">Before we get started, let's first <b>create a working directory for this analysis and change into it:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/jovyan/notebooks/SAR_Training/English/Ecosystems/data_Ex2-4_S1-MadreDeDios\"\n",
    "new_directory(path)\n",
    "os.chdir(path)\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">We will <b>retrieve the relevant data</b> from an <a href=\"https://aws.amazon.com/\" target=\"_blank\">Amazon Web Service (AWS)</a> cloud storage bucket <b>using the following command</b>:</font></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_path = 's3://asf-jupyter-data/MadreDeDios.zip'\n",
    "time_series = os.path.basename(time_series_path)\n",
    "!aws s3 cp $time_series_path $time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"> Now, let's <b>unzip the file (overwriting previous extractions) and clean up after ourselves:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if path_exists(time_series):\n",
    "    asf_unzip(os.getcwd(), time_series)\n",
    "    os.remove(time_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"5\"> <b> 2. Define Some Python Helper Functions for this Notebook </b> </font> \n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\">We are defining two helper functions for this notebook:\n",
    "\n",
    "- **create_geotiff()** to write out images\n",
    "- **timeseries_metrics()** to compute various metrics from a time series data stack</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_geotiff(name, array, data_type, ndv, bandnames=None, ref_image=None, \n",
    "                  geo_t=None, projection=None):\n",
    "    # If it's a 2D image we fake a third dimension:\n",
    "    if len(array.shape) == 2:\n",
    "        array = np.array([array])\n",
    "    if ref_image == None and (geo_t == None or projection == None):\n",
    "        raise RuntimeWarning('ref_image or settings required.')\n",
    "    if bandnames != None:\n",
    "        if len(bandnames) != array.shape[0]:\n",
    "            raise RuntimeError('Need {} bandnames. {} given'\n",
    "                               .format(array.shape[0],len(bandnames)))\n",
    "    else:\n",
    "        bandnames = ['Band {}'.format(i+1) for i in range(array.shape[0])]\n",
    "    if ref_image != None:\n",
    "        refimg = gdal.Open(ref_image)\n",
    "        geo_t = refimg.GetGeoTransform()\n",
    "        projection = refimg.GetProjection()\n",
    "    driver = gdal.GetDriverByName('GTIFF')\n",
    "    array[np.isnan(array)] = ndv\n",
    "    DataSet = driver.Create(name, array.shape[2], \n",
    "                            array.shape[1], array.shape[0], \n",
    "                            data_type)\n",
    "    DataSet.SetGeoTransform(geo_t)\n",
    "    DataSet.SetProjection(projection)\n",
    "    for i, image in enumerate(array, 1):\n",
    "        DataSet.GetRasterBand(i).WriteArray( image )\n",
    "        DataSet.GetRasterBand(i).SetNoDataValue(ndv)\n",
    "        DataSet.SetDescription(bandnames[i-1])\n",
    "    DataSet.FlushCache()\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_metrics(raster, ndv=0): \n",
    "    # Make us of numpy nan functions\n",
    "    # Check if type is a float array\n",
    "    if not raster.dtype.name.find('float') > -1:\n",
    "        raster = raster.astype(np.float32)\n",
    "    # Set ndv to nan\n",
    "    if ndv != np.nan:\n",
    "        raster[np.equal(raster, ndv)] = np.nan\n",
    "    # Build dictionary of the metrics\n",
    "    tsmetrics = {}\n",
    "    rperc = np.nanpercentile(raster, [5, 50, 95], axis=0)\n",
    "    tsmetrics['mean'] = np.nanmean(raster, axis=0)\n",
    "    tsmetrics['max'] = np.nanmax(raster, axis=0)\n",
    "    tsmetrics['min'] = np.nanmin(raster, axis=0)\n",
    "    tsmetrics['range'] = tsmetrics['max'] - tsmetrics['min']\n",
    "    tsmetrics['median'] = rperc[1]\n",
    "    tsmetrics['p5'] = rperc[0]\n",
    "    tsmetrics['p95'] = rperc[2]\n",
    "    tsmetrics['prange'] = rperc[2] - rperc[0]\n",
    "    tsmetrics['var'] = np.nanvar(raster, axis=0)\n",
    "    tsmetrics['cov'] = tsmetrics['var'] / tsmetrics['mean']\n",
    "    return tsmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"5\"> <b> 3. Define Data Directory and Path to VRT </b> </font> \n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>Create a variable containing the VRT filename and the image acquisition dates:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdalbuildvrt -separate raster_stack.vrt tiffs/*_VH.tiff\n",
    "image_file_VH = \"raster_stack.vrt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create an index of timedelta64 data with Pandas:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls tiffs/*_VH.tiff | sort | cut -c 7-21 > raster_stack_VH.dates\n",
    "datefile_VH = 'raster_stack_VH.dates'\n",
    "with open(datefile_VH) as f:\n",
    "    dates_VH = f.readlines()\n",
    "tindex_VH = pd.DatetimeIndex(dates_VH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Print the bands and dates for all images in the virtual raster table (VRT):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Bands and dates for {image_file_VH}\")\n",
    "for i, t in enumerate(tindex_VH):\n",
    "    print(\"{:4d} {}\".format(i+1, t.date()), end=' ')\n",
    "    if (i+1) % 5 == 1:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>\n",
    "<font face=\"Calibri\" size=\"5\"> <b> 4. Create a Time Series Animation to get an Idea of the Dynamics at the Site </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 4.1 Load Time Series Stack </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\">Now we are ready to create a time series animation from the calibrated SAR data.\n",
    "<br><br>\n",
    "<b>First, create a raster from band 0 and a raster stack from all the images:</b>\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = gdal.Open(image_file_VH)\n",
    "band = img.GetRasterBand(1)\n",
    "raster0 = band.ReadAsArray()\n",
    "band_number = 0 # Needed for updates\n",
    "rasterstack_VH = img.ReadAsArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Print the bands, pixels, and lines:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of  bands: {img.RasterCount}\")\n",
    "print(f\"Number of pixels: {img.RasterXSize}\")\n",
    "print(f\"Number of  lines: {img.RasterYSize}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 4.2 Calibration and Data Conversion between dB and Power Scales </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> <font color='rgba(200,0,0,0.2)'> <b>Note, that if your data were generated by HyP3, this step is not necessary!</b> HyP3 performs the full data calibration and provides you with calibrated data in power scale. </font>\n",
    "    \n",
    "If, your data is from a different source, however, calibration may be necessary to ensure that image gray values correspond to proper radar cross section information. \n",
    "\n",
    "Calibration coefficients for SAR data are often defined in the decibel (dB) scale due to the high dynamic range of the imaging system. For the L-band ALOS PALSAR data at hand, the conversion from uncalibrated DN values to calibrated radar cross section values in dB scale is performed by applying a standard **calibration factor of -83 dB**. \n",
    "<br> <br>\n",
    "$\\gamma^0_{dB} = 20 \\cdot log10(DN) -83$\n",
    "\n",
    "The data at hand are radiometrically terrain corrected images, which are often expressed as terrain flattened $\\gamma^0$ backscattering coefficients. For forest and land cover monitoring applications $\\gamma^o$ is the preferred metric.\n",
    "\n",
    "<b>To apply the calibration constant for your data and export in *dB* scale, uncomment the following code cell</b>: </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #caldB=20*np.log10(rasterstack)-83"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"> While **dB**-scaled images are often \"visually pleasing\", they are often not a good basis for mathematical operations on data. For instance, when we compute the mean of observations, it makes a difference whether we do that in power or dB scale. Since dB scale is a logarithmic scale, we cannot simply average data in that scale. \n",
    "    \n",
    "Please note that the **correct scale** in which operations need to be performed **is the power scale.** This is critical, e.g. when speckle filters are applied, spatial operations like block averaging are performed, or time series are analyzed.\n",
    "\n",
    "To **convert from dB to power**, apply: $\\gamma^o_{pwr} = 10^{\\frac{\\gamma^o_{dB}}{10}}$ </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calPwr=np.power(10.,caldB/10.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 4.3 Create Time Series Animation </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"><b>Create and move into a directory in which to store our plots and animations:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_path = 'plots_and_animations'\n",
    "new_directory(product_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">Now we can <b>create the information needed to animate our data:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "fig = plt.figure(figsize=(14, 7))\n",
    "ax = fig.subplots()\n",
    "ax.axis('off')\n",
    "vmin = np.percentile(rasterstack_VH.flatten(), 5)\n",
    "vmax = np.percentile(rasterstack_VH.flatten(), 95)\n",
    "\n",
    "r0dB = 20 * np.log10(raster0) - 83\n",
    "\n",
    "im = ax.imshow(raster0, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "ax.set_title(\"{}\".format(tindex_VH[0].date()))\n",
    "\n",
    "def animate(i):\n",
    "    ax.set_title(\"{}\".format(tindex_VH[i].date()))\n",
    "    im.set_data(rasterstack_VH[i])\n",
    "\n",
    "# Interval is given in milliseconds\n",
    "ani = animation.FuncAnimation(fig, animate, frames=rasterstack_VH.shape[0], interval=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Configure matplotlib's RC settings for the animation:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc('animation', embed_limit=40971520.0)  # We need to increase the limit maybe to show the entire animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create a javascript animation of the time-series running inline in the notebook:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Delete the dummy png</b> that was saved to the current working directory while generating the javascript animation in the last code cell.</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove('None0000000.png')\n",
    "except FileNotFoundError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Save the animation (animation.gif):</b> </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.save(f'{product_path}/animation_VH.gif', writer='pillow', fps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>\n",
    "<font face=\"Calibri\" size=\"5\"> <b> 5. Computation and Visualization of Time Series Metrics</b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\">Once a time-series was constructed, we can compute <b>a set of metrics</b> that will aid us later in applications such as <i>change detection and active agriculture detection</i>. In the next code cells, we will compute the following variables for each pixel in the stack:\n",
    "\n",
    "- Mean \n",
    "- Median\n",
    "- Maximum\n",
    "- Minimum\n",
    "- Range (Maximum - Minimum)\n",
    "- 5th Percentile\n",
    "- 95th Percentile\n",
    "- PRange (95th - 5th Percentile)\n",
    "- Variance\n",
    "- Coefficient of Variation (Variance/Mean)\n",
    "\n",
    "<hr>\n",
    "First, we <b>mask out pixels</b> without relevant information to be unbiased in statical number we calculate later. Then we <b>calculate the time series metrics</b>:\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = rasterstack_VH == 0\n",
    "rasterPwr = np.ma.array(rasterstack_VH, mask=mask, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = timeseries_metrics(rasterPwr.filled(np.nan), ndv=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_keys = metrics.keys()\n",
    "print(metric_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">Let's look at the histograms for the time series variance and coeficient of variation to aid displaying those images:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 4))\n",
    "ax[0].hist(metrics['var'].flatten(), bins=100, range=(0, 0.0001))\n",
    "ax[1].hist(metrics['cov'].flatten(), bins=100, range=(0, 0.004))\n",
    "_ = ax[0].set_title('Variance')\n",
    "_ = ax[1].set_title('Coefficient of Variation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\">We use thresholds determined from those histograms to set the scaling in the time series visualization. For the backscatter metrics we choose a typical range appropriate for this ecosystem, the C-band radar sensor, and the VH polarization. A typical range is -30 dB (0.0001) to -10 dB (0.1).</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# List the metrics keys you want to plot\n",
    "fig = plt.figure(figsize=(16, 40))\n",
    "for i, key in enumerate(metric_keys):\n",
    "    ax = fig.add_subplot(5, 2, i+1)\n",
    "    if key == 'var':\n",
    "        vmin, vmax = (0.0, 0.0001)\n",
    "    elif key == 'cov': \n",
    "        vmin, vmax = (0.0, 0.002)\n",
    "    else:\n",
    "        vmin, vmax = (0.0, 0.1)\n",
    "    ax.imshow(metrics[key], vmin=vmin, vmax=vmax, cmap='gray')\n",
    "    ax.set_title(key.upper())\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>\n",
    "<font face=\"Calibri\" size=\"5\"> <b> 6. Some Popular SAR Change Detection Methods</b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\">This section will introduce you to the following popular and simple change detection methods:\n",
    "\n",
    "- Time series metrics  95$^{th}$ and 5$^{th}$ percentile difference thresholding\n",
    "- Time series coefficient of variation thresholding\n",
    "- Log Ratio-based change detection from image pairs\n",
    "</font> \n",
    "\n",
    "<hr>\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 6.1 Change Detection with the Percentile Difference and the Variance Threshold Method</b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\">In this method we find thresholds on the <b>95$^{th}$ and 5$^{th}$ percentile difference</b> or the <b>temporal pixel-by-pixel gray value cariance</b>. Let's start with the 95$^{th}$ and 5$^{th}$ percentile difference. The advantage to look at percentiles verus maximum minus minimum is that outliers and extremas in the time series are not influencing the result.\n",
    "\n",
    "For our example, the historgram and the Cumulative Distribution Function (CDF) of the 95$^{th}$ and 5$^{th}$ percentile difference image looks like this:\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "fig = plt.figure(figsize=(14, 4)) # Initialize figure with a size\n",
    "ax1 = fig.add_subplot(121)  # 121 determines: 2 rows, 2 plots, first plot\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "h = ax1.hist(metrics['range'].flatten(), bins=200, range=(0, 0.1))\n",
    "ax1.xaxis.set_label_text('Percentile Range Metric')\n",
    "ax1.set_title('Histogram')\n",
    "\n",
    "n, bins, patches = ax2.hist(metrics['range'].flatten(), \n",
    "                            bins=200, range=(0, 0.1), \n",
    "                            cumulative='True', density='True', \n",
    "                            histtype='step', label='Empirical')\n",
    "ax2.xaxis.set_label_text('Percentile Range Metric')\n",
    "ax2.set_title('CDF')\n",
    "plt.savefig(os.path.join(product_path, 'thresh_percentilerange_histogram.png'), \n",
    "            dpi=200, transparent='true')\n",
    "\n",
    "outind = np.where(n > 0.95)\n",
    "threshind = np.min(outind)\n",
    "thresh = bins[threshind]\n",
    "ax1.axvline(thresh, color='red')\n",
    "_ = ax2.axvline(thresh, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"3\">Let's visualize the 5% of all pixels with the largest (95th - 5th percentile) difference in the time series. We will refer to the pixels (x,y) that exceed this threshold $t$ as likely <b>change pixels (cp)</b>:\n",
    "\n",
    "${cp}_{x,y} = P_{x,y}^{95th} - P_{x,y}^{5th} > t$ \n",
    "\n",
    "If we define $t$ to correspond to the 5% of pixels with highest (95th - 5th percentile) difference, the image looks like:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "mask = metrics['range'] < thresh # For display we prepare the inverse mask\n",
    "maskpdiffrange=~mask # Store this for later output\n",
    "plt.imshow(mask, cmap='gray')\n",
    "_ = plt.title('Threshold Classifier on Range > %1.3f' % thresh)\n",
    "plt.savefig(os.path.join(product_path,'changes_percentilerange_threshold.png'), dpi=200, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>EXERCISE</u> </font></b> \n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Discuss what you see in this figure. What are the black areas? What are the white areas? What kind of changes may be included in this map?\n",
    "</font>\n",
    "</div>\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"3\">Instead of applying a threshold on the 95th - 5th percentile difference data, we can also attempt to threshold other metrics. The <b>Variance</b> variable seems a useful indicator for change as it identifies pixels for which radar brightness has changed strongly within the time series. Hence, in the following we use this metric for change identification according to:\n",
    "\n",
    "${cp}_{x,y} = \\sigma^2 > t$ \n",
    "\n",
    "with $t=CDF_{\\sigma^2} > 0.95$ (5% pixels with highest variance):</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "fig = plt.figure(figsize=(14, 4)) # Initialize figure with a size\n",
    "ax1 = fig.add_subplot(121)  # 121 determines: 2 rows, 2 plots, first plot\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "h = ax1.hist(metrics['var'].flatten(), bins=200, range=(0, 0.0001))\n",
    "ax1.xaxis.set_label_text('Variance Metric')\n",
    "ax1.set_title('Histogram')\n",
    "\n",
    "n, bins, patches = ax2.hist(metrics['var'].flatten(), bins=200, range=(0, 0.0001), cumulative='True', density='True', histtype='step', label='Empirical')\n",
    "ax2.xaxis.set_label_text('Variance Metric')\n",
    "ax2.set_title('CDF')\n",
    "plt.savefig(os.path.join(product_path,'thresh_var_histogram.png'), dpi=200, transparent='true')\n",
    "\n",
    "outind = np.where(n > 0.95)\n",
    "threshind = np.min(outind)\n",
    "threshvar = bins[threshind]\n",
    "ax1.axvline(threshvar,color='red')\n",
    "_ = ax2.axvline(threshvar,color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "mask = metrics['var'] < threshvar # For display we prepare the inverse mask\n",
    "maskvar = ~mask # Store this for later output\n",
    "plt.imshow(mask, cmap='gray')\n",
    "_ = plt.title('Threshold Classifier on Variance > %1.5f' % threshvar )\n",
    "plt.savefig(f'{product_path}/changes_var_threshold.png', dpi=200, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>EXERCISE</u> </font></b> \n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Discuss what you see in this figure. What kind of changes are detected? How does this change map compare to the previous one?\n",
    "</font>\n",
    "</div>\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 6.2 Change Detection with the Coefficient of Variation Method </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\">We can also set a threshold $t$ for the <b>coefficient of variation image</b>\n",
    "to classify change in the time series:\n",
    "    \n",
    "${cp}_{x,y} = \\frac{\\sigma_{x,y}^2}{\\overline{X}_{x,y}} > t$ \n",
    "\n",
    "Let's look at the histogram and the Cumulative Distribution Function (CDF) of the coefficient of variation:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "fig = plt.figure(figsize=(14, 4)) # Initialize figure with a size\n",
    "ax1 = fig.add_subplot(121)  # 121 determines: 2 rows, 2 plots, first plot\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "h = ax1.hist(metrics['cov'].flatten(), bins=200, range=(0, 0.002))\n",
    "ax1.xaxis.set_label_text('Coefficient of Variation Metric')\n",
    "ax1.set_title('Histogram')\n",
    "\n",
    "n, bins, patches = ax2.hist(metrics['cov'].flatten(), bins=200, range=(0, 0.002), cumulative='True', density='True', histtype='step', label='Empirical')\n",
    "ax2.xaxis.set_label_text('Coefficient of Variation Metric')\n",
    "ax2.set_title('CDF')\n",
    "plt.savefig(os.path.join(product_path,'thresh_cov_histogram.png'), dpi=200, transparent='true')\n",
    "\n",
    "outind = np.where(n > 0.95)\n",
    "threshind = np.min(outind)\n",
    "threshcov = bins[threshind]\n",
    "ax1.axvline(threshcov,color='red')\n",
    "_ = ax2.axvline(threshcov,color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"3\">With a threshold of $t=CDF_{cov^2} > 0.95$ (5% pixels with highest variance) the change pixels would look like the following image:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "mask = metrics['cov'] < threshcov # For display we prepare the inverse mask\n",
    "maskcov = ~mask # Store this for later output\n",
    "plt.imshow(mask, cmap='gray')\n",
    "_ = plt.title('Threshold Classifier on Coefficient of Variation > %1.3f' % threshcov )\n",
    "plt.savefig(f\"{product_path}/changes_CV_threshold.png\", dpi=200, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>EXERCISE</u> </font></b> \n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Discuss what you see in this figure. What kind of changes are detected? How is this change map different from the previous two? What are the similarities?\n",
    "</font>\n",
    "</div>\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 6.3 Change Detection with the Log Ratio Method </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\">In this method, we compare two images from the same season in different years. First we <b>look at global means of the backscatter images building a time series object of acquisition dates and global image means of backscatter.</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsmean = 10*np.log10(np.nanmean(rasterPwr.filled(np.nan), axis=(1, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"3\">We make a time series object to list the dates, mean backscatter in dB and band index number for the rasterPwr array:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.Series(tsmean, index=tindex_VH)\n",
    "for i in range(len(ts)):\n",
    "    print(i, ts.index[i].date(), ts[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"3\"><font color='rgba(200,0,0,0.2)'> <b>To compare two dates for change detection with the log ratio approach we pick two dates of relatively similar backscatter and from similar times of the year.</b></font> Two such candidate dates are:</font> \n",
    "\n",
    "For our cross-polarized data\n",
    "\n",
    "- 2017-09-10 -13.0938015 (index 21)\n",
    "- 2018-09-17 -13.282042 (index 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cross-polarized\n",
    "cross_pol_ref = rasterPwr[21]   # Reference Image\n",
    "cross_pol_new = rasterPwr[51]  # New Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"3\">The Log ratio between the images is \n",
    "\n",
    "$r  = log_{10}(\\frac{X_i}{X_r})$\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.log10(cross_pol_new / cross_pol_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>To find a threshold for change</b>, we can display the absolute ratio image $abs(r)$ and the historgram of $r$. We adjust the scale factors for the display to enhance visualization of change areas with largest backscatter change between this image pair. Brighter values show larger change. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display r\n",
    "fig, ax = plt.subplots(2, 2, figsize=(16, 16))\n",
    "ax[0][0].axis('off')\n",
    "ax[0][1].axis('off')\n",
    "ax[1][0].axis('off')\n",
    "ax[0][0].set_title('C-VH')\n",
    "ax[0][0].imshow(cross_pol_ref, vmin=0, vmax=0.1, cmap='gray')\n",
    "ax[0][1].imshow(cross_pol_new, vmin=0, vmax=0.1, cmap='gray')\n",
    "ax[1][0].imshow(np.abs(r), vmin=0, vmax=0.3, cmap='gray')\n",
    "_ = ax[1][1].hist(r.flatten(), bins=100, range=(-0.4, 0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"3\">Let's define change pixels as those falling outside the range of <b>three</b> times the standard deviation of the ration image $\\sigma_r$ from the image mean $\\bar{r}$:\n",
    "\n",
    "${cp}_{x,y} = (r_{x,y} < \\overline{r} - 3\\sigma_r) \\ \\textrm{or} \\ (r_{x,y} > \\overline{r} + 3\\sigma_r)$ \n",
    "\n",
    "We are using the numpy masking to set the non-changing pixels inside the range:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stddev = np.std(r)\n",
    "thres = 3 * stddev\n",
    "mask = np.logical_and(r>-1*thres, r<thres)\n",
    "masklr = ~mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"3\">Let's display pixels that fall outside 3 times the standard deviation.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(8,16))\n",
    "ax.imshow(mask, cmap='gray')\n",
    "ax.xaxis.set_ticks([])\n",
    "ax.yaxis.set_ticks([])\n",
    "_ = ax.set_title('Log Ratio Classifier of the September 2017/2018 Log Ratio Images')\n",
    "plt.savefig(f\"{product_path}/changes_LR_threshold.png\", dpi=200, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>EXERCISE</u> </font></b> \n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Discuss what you see in this figure. What kind of changes are detected? How is this change map different from the previous three? What are the similarities? Note that this change map is based on pairs of images and not on the full time series as the previous three. How does this affect your results?\n",
    "</font>\n",
    "</div>\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>\n",
    "<font face=\"Calibri\" size=\"5\"> <b> 7. Write Our Change Detection Results and Metrics Images to GeoTIFF files</b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 7.1 Determine Output Geometry </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\">First, we need to <b>set the correct geotransformation and projection information</b>. We retrieve the values from the input images:\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = img.GetProjection()\n",
    "geotrans = list(img.GetGeoTransform())\n",
    "geotrans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 7.2 Output Time Series Metrics Images </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\">We use the root of the time series data stack name and append a _ts_metrics_&lt;metric&gt;.tif ending as filenames:\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Metrics as image image:\n",
    "# We make a new subdirectory where we will store the images\n",
    "dirname = image_file_VH.replace('.vrt', '_tsmetrics')\n",
    "os.makedirs(dirname, exist_ok=True)\n",
    "print(dirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"3\">Now we can <b>output the individual metrics as GeoTIFF images</b>:\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=[] # List to keep track of all the names\n",
    "for i in metrics:\n",
    "    name = os.path.join(dirname, image_file_VH.replace('.vrt','_'+i+'.tif'))\n",
    "    create_geotiff(name, metrics[i], gdal.GDT_Float32, np.nan,[i], geo_t=geotrans, projection=proj)\n",
    "    names.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 7.3 Build a Virtual Raster Table on the Metrics GeoTIFF images </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\">To tie the images into one new raster stack of time series metrics we build a virtual raster table with all the metrics. \n",
    "\n",
    "Trick: Use ' '.join(Names) to build one long string of names separated by a space as input to *gdalbuildvrt*:\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = 'gdalbuildvrt -separate -overwrite -vrtnodata nan ' + \\\n",
    "   dirname + '.vrt ' + ' '.join(names)\n",
    "# print(cmd)\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Time Series Metrics VRT File:\\n', f\"{dirname}.vrt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Calibri\" size=\"4\"> <b> 7.4 Create GeoTIFFs for the Change Iamges from our Four Change Detection Attempts </b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\">We are going to write GeoTIFF output files that stores the results from the classifiers:\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenamepdiff = os.path.join(product_path, image_file_VH.replace('.vrt', '_pdiff_thresholds.tif'))\n",
    "imagenamevar = os.path.join(product_path, image_file_VH.replace('.vrt', '_var_thresholds.tif'))\n",
    "imagenamecov = os.path.join(product_path, image_file_VH.replace('.vrt', '_cov_thresholds.tif'))\n",
    "imagenamelr = os.path.join(product_path,image_file_VH.replace('.vrt', '_lr_thresholds.tif'))\n",
    "\n",
    "create_geotiff(imagenamepdiff, maskpdiffrange, gdal.GDT_Byte, np.nan, [i], geo_t=geotrans, projection=proj)\n",
    "create_geotiff(imagenamevar, maskvar, gdal.GDT_Byte, np.nan, [i], geo_t=geotrans, projection=proj)\n",
    "create_geotiff(imagenamecov, maskcov, gdal.GDT_Byte, np.nan, [i], geo_t=geotrans, projection=proj)\n",
    "_ = create_geotiff(imagenamelr, masklr, gdal.GDT_Byte, np.nan, [i], geo_t=geotrans, projection=proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>\n",
    "<font face=\"Calibri\" size=\"5\"> <b> 8. Conclusion</b> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\">Thresholds for the three methods are necessarily site dependent and need to be identified with calibration data or visual post-classification interpretation, and can subsequently be adjusted to maximize classification accuracy. Also, some methods will have advantages in different scenarios. \n",
    "\n",
    "For a bit more information on change detection and SAR in general, please look at the recently published <a href=\"https://gis1.servirglobal.net/TrainingMaterials/SAR/SARHB_FullRes.pdf\" target=\"_blank\">SAR Handbook: Comprehensive Methodologies for Forest Monitoring and Biomass Estimation</a>.\n",
    "</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>EXERCISES</u> </font></b> \n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Explore the 78 image deep data stack a bit more. Pick different time steps for the log-ratio change detection to create additional change maps. Answer the following questions for yourself:\n",
    "\n",
    "<ul>\n",
    "  <li>Change the threshold and band choices in this notebook to see the effects on detected changes.</li>\n",
    "  <li>Load created change masks into QGIS and compare the detected areas with your time series plots and image data.</li>\n",
    "</ul>\n",
    "\n",
    "</font>\n",
    "</div>\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"2\"> <i>SAR Training Materials - Version 1.1 - June 2019 </i>\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
