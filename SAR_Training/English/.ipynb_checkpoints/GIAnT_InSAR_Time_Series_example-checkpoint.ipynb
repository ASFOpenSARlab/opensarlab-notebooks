{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"NotebookAddons/blackboard-banner.jpg\" width=\"100%\" />\n",
    "<font face=\"Calibri\">\n",
    "<br>\n",
    "<font size=\"5\"> <b>InSAR Time Series Analysis using GIAnT within Jupyter Notebooks</b> </font>\n",
    "\n",
    "<br>\n",
    "<font size=\"4\"> <b> Franz J Meyer & Joshua J C Knicely; University of Alaska Fairbanks</b> <br>\n",
    "<img src=\"NotebookAddons/UAFLogo_A_647.png\" width=\"170\" align=\"right\" /><font color='rgba(200,0,0,0.2)'> <b>Due Date: </b>NONE</font>\n",
    "</font>\n",
    "\n",
    "<font size=\"3\"> This notebook demonstrates how to process InSAR data, specifically interferograms, using the Generic InSAR Analysis Toolbox (<a href=\"http://earthdef.caltech.edu/projects/giant/wiki\" target=\"_blank\">GIAnT</a>) in the framework of *Jupyter Notebooks*.<br>\n",
    "\n",
    "<b>Our specific objectives for this notebook are to:</b>\n",
    "\n",
    "- Learn how to prepare data for GIAnT. \n",
    "- Use GIAnT to create maps of surface deformation. \n",
    "    -  Understand its capabilities. \n",
    "    -  Understand its limitations. \n",
    "</font>\n",
    "\n",
    "<br>\n",
    "<font face=\"Calibri\">\n",
    "\n",
    "<font size=\"5\"> <b> Target Description </b> </font>\n",
    "\n",
    "<font size=\"3\"> In this notebook, we will analyze the volcano Sierra Negra. This is a highly active volcano on the Galapagos hotpsot. The most recent eruption occurred from 29 June to 23 August 2018. The previous eruption occurred in October 2005, prior to the launch of the Sentinel-1 satellites, which will be the source of data we use for this notebook. We will be looking at the deformation that occurred prior to the volcano's 2018 eruption. </font>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri'><font size='5'><b>Overview</b></font>\n",
    "<br><br>\n",
    "<font size='3'><b>About GIAnT</b>\n",
    "<br>\n",
    "GIAnT is a Python framework that allows rapid time series analysis of low amplitude deformation signals. It allows users to use multiple time series analysis technqiues: Small Baseline Subset (SBAS), New Small Baseline Subset (N-SBAS), and Multiscale InSAR Time-Series (MInTS). As a part of this, it includes the ability to correct for atmospheric delays by assuming a spatially uniform stratified atmosphere. \n",
    "<br><br>\n",
    "<b>Limitations</b>\n",
    "<br>\n",
    "GIAnT has a number of limitations that are important to keep in mind as these can affect its effectiveness for certain applications. It implements the simplest time-series inversion methods. Its single coherence threshold is very conservative in terms of pixel selection. It does not include any consistency checks for unwrapping errors. It has a limited dictionary of temporal model functions. It cannot correct for atmospheric effects due to differing surface elevations. \n",
    "<br><br>\n",
    "<b>Steps to use GIAnT</b><br>\n",
    "Although GIAnT is an incredibly powerful tool, it requires very specific input. Because of the input requirements, the majority of one's effort goes to getting the data into a form that GIAnT can manipulate and to creating files that tell GIAnT what to do. The general steps to use GIAnT are below. \n",
    "\n",
    "- Download Data\n",
    "- Identify Area of Interest\n",
    "- Subset (Crop) Data to Area of Interest\n",
    "- Prepare Data for GIAnT\n",
    "    - Adjust file names\n",
    "    - Remove potentially disruptive default values (optional)\n",
    "    - Convert data from '.tiff' to '.flt' format\n",
    "- Create Input Files for GIAnT\n",
    "    - Create 'ifg.list'\n",
    "    - Create 'date.mli.par'\n",
    "    - Make prepxml_SBAS.py\n",
    "    - Run prepxml_SBAS.py\n",
    "    - Make userfn.py\n",
    "- Run GIAnT\n",
    "    - PrepIgramStack.py*\n",
    "    - ProcessStack.py\n",
    "    - SBASInvert.py\n",
    "    - SBASxval.py\n",
    "- Data Visualization\n",
    "\n",
    "<br>\n",
    "The steps from PrepIgramStack.py and above have been completed for you in order to save disk space and computation time. This allows us to concentrate on the usage of GIAnT and data visualization. Some of the code to create the prepatory files (e.g., 'ifg.list', 'date.mli.par', etc.) have been incldued for your potential use. More information about GIAnT can be found here: (<a href=\"http://earthdef.caltech.edu/projects/giant/wiki\" target=\"_blank\">http://earthdef.caltech.edu/projects/giant/wiki</a>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"5\" color=\"red\"> <b>Important Note about JupyterHub</b> </font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"> <b>Your JupyterHub server will automatically shutdown when left idle for more than 1 hour. Your notebooks will not be lost but you will have to restart their kernels and re-run them from the beginning. You will not be able to seamlessly continue running a partially run notebook.</b> </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri'><font size='5'><b>0. Import Python Libraries:</b></font><br><br>\n",
    "<font size='3'><b>Import the Python libraries and modules we will need to run this lab:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import zipfile\n",
    "import glob\n",
    "import h5py # for is_hdf5\n",
    "import os\n",
    "import osr\n",
    "import shutil\n",
    "\n",
    "import gdal\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "from matplotlib import rc\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "from asf_notebook import path_exists\n",
    "from asf_notebook import new_directory\n",
    "from asf_notebook import asf_unzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri'><font size='5'><b>1. Transfer data to a local directory</b></font><br>\n",
    "    <font size='3'>The data cube (referred to as a stack in the GIAnT documentation and code) and several other needed files have been created and stored in the GIAnT server. We will download this data to a local directory and unzip it. </font></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"> Before we download anything, <b>create a working directory for this analysis and change into it:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/jovyan/notebooks/SAR_Training/English/data_GIAnT_InSAR_Time_Series_example\"\n",
    "new_directory(path)\n",
    "os.chdir(path)\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face = 'Calibri' size='3'>First step is to find the zip file and download it to a local directory. This zip file has been placed in the S3 bucket for this class.\n",
    "<br><br>\n",
    "<b>Display the contents of the S3 bucket:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!aws s3 ls s3://asf-jupyter-data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face = 'Calibri' size='3'><b>Copy the desired file ('Lab9Files.zip') to your data directory:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://asf-jupyter-data/Lab9Files.zip ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri'><font size='3'><b>Create the directories where we will perform the GIAnT analysis and store the data:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_path = f\"{os.getcwd()}/Stack\" # directory GIAnT prefers to access and store data steps. \n",
    "new_directory(stack_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri'><font size='3'><b>Extract the zipped file to path and delete it:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped = 'Lab9Files.zip'\n",
    "asf_unzip(path, zipped)\n",
    "if path_exists(zipped):\n",
    "    os.remove(zipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='3'>The files have been extracted and placed in a folder called 'Lab9Files'. <b>Move the amplitude image, data.xml, date.mli.par, and sbas.xml files to path and RAW-STACK.h5 to stack_path:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir = f\"{path}/Lab9Files\"\n",
    "if not os.path.exists(f\"{stack_path}/RAW-STACK.h5\"):\n",
    "    shutil.move(f\"{temp_dir}/RAW-STACK.h5\", stack_path) \n",
    "files = glob.glob(f\"{temp_dir}/*.*\")\n",
    "for file in files:\n",
    "    if not os.path.exists(file):\n",
    "        shutil.move(file, path)\n",
    "if path_exists(temp_dir):\n",
    "    shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri'><font size='5'><b>2. Create Input Files And Code for GIAnT</b></font>\n",
    "    <br>\n",
    "    <font size ='3'>The code below shows how to create the input files and specialty code that GIAnT requires. For this lab, 'ifg.list' is not needed, 'date.mli.par' has already been provided, 'prepxml_SBAS.py' is not needed as the 'sbas.xml' and 'data.xml' files it would create have already been provided, and 'userfn.py' is not needed as we are skipping the step in which it would be used. <br>The files that would be created are listed below. \n",
    "        <br>\n",
    "        \n",
    "- ifg.list\n",
    "    - List of the interferogram properties including master and slave date, perpendicular baseline, and sensor. \n",
    "- date.mli.par\n",
    "    - File from which GIAnT pulls requisite information about the sensor. \n",
    "    - This is specifically for GAMMA files. When using other interferogram processing techniques, an alternate file is required. \n",
    "- prepxml_SBAS.py\n",
    "    - Python function to create an xml file that specifies the processing options to GIAnT. \n",
    "    - This must be modified by the user for their particular application. \n",
    "- userfn.py\n",
    "    - Python function to map the interferogram dates to a phyiscal file on disk. \n",
    "    - This must be modified by the user for their particular application. \n",
    "    </font>\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='4'> <b>2.1 Create 'ifg.list' File </b> </font> </font>\n",
    "<br>\n",
    "<font face='Calibri' size='3'> This will create simple 4 column text file will communicate network information to GIAnT. It will be created within the <b>GIAnT</b> folder.\n",
    "<br><br>\n",
    "<b>This step has already been done, so we will not actually create the 'ifg.list' file. This code is displayed for your potential future use.</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Get one of each file name. This assumes the unwrapped phase geotiff has been converted to a '.flt' file\n",
    "files = [f for f in os.listdir(datadirectory) if f.endswith('_unw_phase.flt')] \n",
    "\n",
    "# Get all of the master and slave dates. \n",
    "masterDates,slaveDates = [],[]\n",
    "for file in files:\n",
    "    masterDates.append(file[0:8])\n",
    "    slaveDates.append(file[9:17])\n",
    "# Sort the dates according to the master dates. \n",
    "master_dates,sDates = (list(t) for t in zip(*sorted(zip(masterDates,slaveDates))))\n",
    "\n",
    "with open( os.path.join('GIAnT', 'ifg.list'), 'w') as fid:\n",
    "    for i in range(len(master_dates)):\n",
    "        masterDate = master_dates[i] # pull out master Date (first set of numbers)\n",
    "        slaveDate = sDates[i] # pull out slave Date (second set of numbers)\n",
    "        bperp = '0.0' # according to JPL notebooks\n",
    "        sensor = 'S1' # according to JPL notebooks\n",
    "        fid.write(f'{masterDate}  {slaveDate}  {bperp}  {sensor}\\n') # write values to the 'ifg.list' file. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri'><font size='3'>You may notice that the code above sets the perpendicular baseline to a value of 0.0 m. This is not the true perpendicular baseline. That value can be found in metadata file (titled '$<$master timestamp$>$_$<$slave timestamp$>$.txt') that comes with the original interferogram. Generally, we would want the true baseline for each interferogram. However, since Sentinel-1 has such a short baseline, a value of 0.0 m is sufficient for our purposes. </font></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='4'> <b>2.2 Create 'date.mli.par' File </b></font> \n",
    "<br>\n",
    "<font face='Calibri' size='3'>As we are using GAMMA products, we must create a 'date.mli.par' file from which GIAnT will pull necessary information. If another processing technique is used to create the interferograms, an alterante file name and file inputs are required.\n",
    "<br><br>\n",
    "<b>Again, this step has already been completed and the code is only displayed for your potential future use.</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Create file 'date.mli.par'\n",
    "\n",
    "# Get file names\n",
    "files = [f for f in os.listdir(datadirectory) if f.endswith('_unw_phase.flt')]\n",
    "\n",
    "# Get WIDTH (xsize) and FILE_LENGTH (ysize) information\n",
    "ds = gdal.Open(datadirectory+files[0], gdal.GA_ReadOnly)\n",
    "type(ds)\n",
    "\n",
    "nLines = ds.RasterYSize\n",
    "nPixels = ds.RasterXSize\n",
    "\n",
    "trans = ds.GetGeoTransform()\n",
    "ds = None\n",
    "\n",
    "# Get the center line UTC time stamp; can also be found inside <date>_<date>.txt file and hard coded\n",
    "dirName = os.listdir('ingrams')[0] # get original file name (any file can be used; the timestamps are different by a few seconds)\n",
    "vals = dirName.split('-') # break file name into parts using the separator '-'\n",
    "tstamp = vals[2][9:16] # extract the time stamp from the 2nd datetime (could be the first)\n",
    "c_l_utc = int(tstamp[0:2])*3600 + int(tstamp[2:4])*60 + int(tstamp[4:6])\n",
    "\n",
    "rfreq = 299792548.0 / 0.055465763 # radar frequency; speed of light divided by radar wavelength of Sentinel1 in meters\n",
    "\n",
    "# write the 'date.mli.par' file\n",
    "with open(os.path.join(path, 'date.mli.par'), 'w') as fid:\n",
    "    # Method 1\n",
    "    fid.write(f'radar_frequency: {rfreq} \\n') # when using GAMMA products, GIAnT requires the radar frequency. Everything else is in wavelength (m) \n",
    "    fid.write(f'center_time: {c_l_utc} \\n') # Method from Tom Logan's prepGIAnT code; can also be found inside <date>_<date>.txt file and hard coded\n",
    "    fid.write( 'heading: -11.9617913 \\n') # inside <date>_<date>.txt file; can be hardcoded or set up so code finds it. \n",
    "    fid.write(f'azimuth_lines: {nLines} \\n') # number of lines in direction of the satellite's flight path\n",
    "    fid.write(f'range_samples: {nPixels} \\n') # number of pixels in direction perpendicular to satellite's flight path\n",
    "    fid.close() # close the file\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri'><font size='4'><b>2.3 Make prepxml_SBAS.py</b> </font>\n",
    "<br>\n",
    "<font size='3'>We will create a prepxml_SBAS.py function and put it into our GIAnT working directory. Again, this is shown for anyone that may want to use GIAnT on their own.<br>If we do wish to change 'sbas.xml' or 'data.xml', this can be done by creating and running a new 'prepxml_SBAS.py'. </font>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri'> <font size='3'><b>2.3.1 Necessary prepxml_SBAS.py edits</b></font>\n",
    "<br>\n",
    "<font size='3'> GIAnT comes with an example prepxml_SBAS.py, but requries significant edits for our purposes. These alterations have already been made, so we don't have to do anything now, but it is good to know the kinds of things that have to be altered. The details of some of these options can be found in the GIAnT documentation. The rest must be found in the GIAnT processing files themselves, most notably the tsxml.py and tsio.py functions. <br>The following alterations were made:\n",
    "<br>\n",
    "- Changed 'example' &#9658; 'date.mli.par'\n",
    "- Removed 'xlim', 'ylim', 'ref_x_lim', and 'ref_y_lim'\n",
    "    - These are used for clipping the files in GIAnT. As we have already done this, it is not necessary. \n",
    "- Removed latfile='lat.map' and lonfile='lon.map'\n",
    "    - These are optional inputs for the latitude and longitude maps. \n",
    "- Removed hgtfile='hgt.map'\n",
    "    - This is an optional altitude file for the sensor. \n",
    "- Removed inc=21.\n",
    "    - This is the optional incidence angle information. \n",
    "    - It can be a constant float value or incidence angle file. \n",
    "    - For Sentinel1, it varies from 29.1-46.0&deg;.\n",
    "- Removed masktype='f4'\n",
    "    - This is the mask designation. \n",
    "    - We are not using any masks for this. \n",
    "- Changed unwfmt='RMG' &#9658; unwfmt='GRD'\n",
    "    - Read data using GDAL. \n",
    "- Removed demfmt='RMG'\n",
    "- Changed corfmt='RMG' &#9658; corfmt='GRD'\n",
    "    - Read data using GDAL. \n",
    "- Changed nvalid=30 -> nvalid=1\n",
    "    - This is the minimum number of interferograms in which a pixel must be coherent. A particular pixel will be included only if its coherence is above the coherence threshold, cohth, in more than nvalid number of interferograms. \n",
    "- Removed atmos='ECMWF'\n",
    "    - This is an amtospheric correction command. It depends on a library called 'pyaps' developed for GIAnT. This library has not been installed yet. \n",
    "- Changed masterdate='19920604' &#9658; masterdate='20161119'\n",
    "    - Use our actual masterdate. \n",
    "    - I simply selected the earliest date as the masterdate. \n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='3'>Defining a reference region is a potentially important step. This is a region at which there should be no deformation. For a volcano, this should be some significant distance away from the volcano. GIAnT has the ability to automatically select a reference region which we will use for this exercise. <br>Below is an example of how the reference region would be defined. If we look at the prepxml_SBAS.py code below, ref_x_lim and ref_y_lim, the pixel based location of the reference region, is within the code, but has been commented out. \n",
    "<br><br>\n",
    "<b>Define reference region:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_x_lim, ref_y_lim = [0, 10], [95, 105]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='3'>Below is an example of how the reference region would be defined. Look at the prepxml_SBAS.py code below. Note that ref_x_lim and ref_y_lim (the pixel based location of the reference region) are within the code.\n",
    "<br><br>\n",
    "<b>This has already been completed but the code is here as an example script for creating XML files for use with the SBAS processing chain.</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import tsinsar as ts\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "def parse():\n",
    "    parser= argparse.ArgumentParser(description='Preparation of XML files for setting up the processing chain. Check tsinsar/tsxml.py for details on the parameters.')\n",
    "    parser.parse_args()\n",
    "\n",
    "parse()\n",
    "g = ts.TSXML('data')\n",
    "g.prepare_data_xml(\n",
    "    'date.mli.par', proc='GAMMA', \n",
    "    #ref_x_lim = [{1},{2}], ref_y_lim=[{3},{4}],\n",
    "    inc = 21., cohth=0.10, \n",
    "    unwfmt='GRD', corfmt='GRD', chgendian='True', endianlist=['UNW','COR'])\n",
    "g.writexml('data.xml')\n",
    "\n",
    "\n",
    "g = ts.TSXML('params')\n",
    "g.prepare_sbas_xml(nvalid=1, netramp=True, demerr=False, uwcheck=False, regu=True, masterdate='{5}', filt=1.0)\n",
    "g.writexml('sbas.xml')\n",
    "\n",
    "\n",
    "############################################################\n",
    "# Program is part of GIAnT v1.0                            #\n",
    "# Copyright 2012, by the California Institute of Technology#\n",
    "# Contact: earthdef@gps.caltech.edu                        #\n",
    "############################################################\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='3'><b>Set the master date and create a script for creating XML files for use with the SBAS processing chain: </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files = [f for f in os.listdir(datadirectory) if f.endswith('_unw_phase.flt')]\n",
    "#master_date = min([files[i][0:8] for i in range(len(files))], key=int)\n",
    "\n",
    "master_date = '20161119'\n",
    "\n",
    "prepxml_SBAS_Template = '''\n",
    "#!/usr/bin/env python\n",
    "\"\"\"Example script for creating XML files for use with the SBAS processing chain. This script is supposed to be copied to the working directory and modified as needed.\"\"\"\n",
    "\n",
    "\n",
    "import tsinsar as ts\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "def parse():\n",
    "    parser= argparse.ArgumentParser(description='Preparation of XML files for setting up the processing chain. Check tsinsar/tsxml.py for details on the parameters.')\n",
    "    parser.parse_args()\n",
    "\n",
    "parse()\n",
    "g = ts.TSXML('data')\n",
    "g.prepare_data_xml(\n",
    "    'date.mli.par', proc='GAMMA', \n",
    "    #ref_x_lim = [{1},{2}], ref_y_lim=[{3},{4}],\n",
    "    inc = 21., cohth=0.10, \n",
    "    unwfmt='GRD', corfmt='GRD', chgendian='True', endianlist=['UNW','COR'])\n",
    "g.writexml('data.xml')\n",
    "\n",
    "\n",
    "g = ts.TSXML('params')\n",
    "g.prepare_sbas_xml(nvalid=1, netramp=True, demerr=False, uwcheck=False, regu=True, masterdate='{5}', filt=1.0)\n",
    "g.writexml('sbas.xml')\n",
    "\n",
    "\n",
    "############################################################\n",
    "# Program is part of GIAnT v1.0                            #\n",
    "# Copyright 2012, by the California Institute of Technology#\n",
    "# Contact: earthdef@gps.caltech.edu                        #\n",
    "############################################################\n",
    "\n",
    "'''\n",
    "with open(os.path.join(path,'prepxml_SBAS.py'), 'w') as fid:\n",
    "    fid.write(prepxml_SBAS_Template.format(path,ref_x_lim[0],ref_x_lim[1],ref_y_lim[0],ref_y_lim[1],master_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri'><font size='3'>To create a new 'sbas.xml' and 'data.xml' file, we would modify the above code to give new parameters and to write to the appropriate folder (e.g., to change the time filter from 1 year to none and to write to the directory in which we are working; 'filt=1.0' -> 'filt=0.0'; and 'os.path.join(path,'prepxml_SBAS.py') -> 'prepxml_SBAS.py' OR '%cd ~' into your home directory). Then we would run it below. </font></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='4'> <b>2.4 Run prepxml_SBAS.py </b> </font>\n",
    "<br>\n",
    "<font face='Calibri' size='3'> Here we run <b>prepxml_SBAS.py</b> to create the 2 needed files</font>\n",
    "\n",
    "- data.xml \n",
    "- sbas.xml\n",
    "\n",
    "<font face='Calibri' size='3'> To use MinTS, we would run <b>prepxml_MinTS.py</b> to create</font>\n",
    "\n",
    "- data.xml\n",
    "- mints.xml\n",
    "        \n",
    "<font face='Calibri' size='3'> These files are needed by <b>PrepIgramStack.py</b>. \n",
    "<br>\n",
    "We must first switch to the GIAnT folder in which <b>prepxml_SBAS.py</b> is contained, then call it. Otherwise, <b>prepxml_SBAS.py</b> will not be able to find the file 'date.mli.par', which holds necessary processing information. \n",
    "<br><br>\n",
    "<b>Create a variable holding the general path to the GIAnT code base.</b> Rumor has it the need to do this will be deprecated in future versions of GIAnT.\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_path = \"/usr/local/GIAnT/SCR\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='3'><b>Run prepxml_SBAS.py in python 2.7 and check the output to confirm that your input values are correct:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python2.7 prepxml_SBAS.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='3'><b>Make sure the two requisite xml files (data.xml and sbas.xml) were produced after running prepxml_SBAS.py.</b></font>\n",
    "<br><br>\n",
    "<font face='Calibri' size='3'><b>Display the contents of data.xml:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if path_exists('data.xml'):\n",
    "    !cat data.xml "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='3'><b>Display the contents of sbas.xml:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if path_exists('sbas.xml'):\n",
    "    !cat sbas.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri'><font size='4'><b>2.5 Create userfn.py</b></font>\n",
    "<br>\n",
    "<font size='3'>Before running the next piece of code, <b>PrepIgramStack.py</b>, we must create a python file called <b>userfn.py</b>. This file maps the interferogram dates to a physical file on disk. This python file must be in our working directory, <b>/GIAnT</b>. We can create this file from within the notebook using python. \n",
    "<br><br>\n",
    "<b>Again, this step has already been preformed and is unnecessary, but the code is provided as an example.</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userfnTemplate = \"\"\"\n",
    "#!/usr/bin/env python\n",
    "import os \n",
    "\n",
    "def makefnames(dates1, dates2, sensor):\n",
    "    dirname = '{0}'\n",
    "    root = os.path.join(dirname, dates1+'-'+dates2)\n",
    "    #unwname = root+'_unw_phase.flt' # for potentially disruptive default values kept. \n",
    "    unwname = root+'_unw_phase_no_default.flt' # for potentially disruptive default values removed. \n",
    "    corname = root+'_corr.flt'\n",
    "    return unwname, corname\n",
    "\"\"\"\n",
    "\n",
    "with open('userfn.py', 'w') as fid:\n",
    "    fid.write(userfnTemplate.format(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri'><font size='5'><b>3. Run GIAnT</b></font>\n",
    "    <br>\n",
    "    <font size='3'>We have now created all of the necessary files to run GIAnT. The full GIAnT process requires 3 function calls.\n",
    "- PrepIgramStack.py\n",
    "    - After PrepIgramStack.py, we will actually start running GIAnT. \n",
    "- ProcessStack.py\n",
    "- SBASInvert.py\n",
    "- SBASxval.py\n",
    "    - This 4th function call is not necessary and we will skip it, but provides some error estimation that can be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='4'> <b>3.1 Run PrepIgramStack.py </b> </font>\n",
    "<br>\n",
    "<font face='Calibri' size='3'> Here we would run <b>PrepIgramStack.py</b> to create the files for GIAnT. This would read in the input data and the files we previously created and output an HDF5 file. As we do not actually need to call this, it is currently set up to display some help information.<br>\n",
    "Inputs:       \n",
    "- ifg.list\n",
    "- data.xml\n",
    "- sbas.xml  \n",
    "- interferograms\n",
    "- coherence files        \n",
    "\n",
    "Outputs:\n",
    "- RAW-STACK.h5\n",
    "- PNG previews under 'GIAnT/Figs/Igrams'\n",
    "    \n",
    "</font>\n",
    "<br>\n",
    "<font size='3'><b>Display some help information for PrepIgramStack.py:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python2.7 $giant_path/PrepIgramStack.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='3'><b>Run PrepIgramStack.py (in our case, this has already been done):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python2.7 $giant_path/PrepIgramStack.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face='Calibri'><font size='3'>PrepIgramStack.py creates a file called 'RAW-STACK.h5'.\n",
    "<br><br>\n",
    "<b>Verify that RAW-STACK.h5 is an HDF5 file as required by the rest of GIAnT.</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_h5 = f\"{stack_path}/RAW-STACK.h5\"\n",
    "if not h5py.is_hdf5(raw_h5):\n",
    "    print(f\"Not an HDF5 file: {raw_h5}\")\n",
    "else:\n",
    "    print(f\"Confirmed: {raw_h5} is an HDF5 file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='4'> <b>3.2 Run ProcessStack.py </b> </font>\n",
    "<br>\n",
    "<font face='Calibri' size='3'> This seems to be an optional step. Does atmospheric corrections and estimation of orbit residuals. <br>\n",
    "Inputs:\n",
    "\n",
    "- HDF5 files from PrepIgramStack.py, RAW-STACK.h5\n",
    "- data.xml \n",
    "- sbas.xml\n",
    "- GPS Data (optional; we don't have this)\n",
    "- Weather models (downloaded automatically)\n",
    "\n",
    "Outputs: \n",
    "\n",
    "- HDF5 files, PROC-STACK.h5\n",
    "        \n",
    "These files are then fed into SBAS. \n",
    "</font> \n",
    "<br><br>\n",
    "<font face='Calibri' size='3'><b>Display the help information for ProcessStack.py:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python2.7 $giant_path/ProcessStack.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='3'><b>Run ProcessStack.py:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python2.7 $giant_path/ProcessStack.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face='Calibri'><font size='3'>ProcessStack.py creates a file called 'PROC-STACK.h5'.\n",
    "<br><br>\n",
    "<b>Verify that PROC-STACK.h5 is an HDF5 file as required by the rest of GIAnT:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_h5 = f\"{stack_path}/PROC-STACK.h5\"\n",
    "if not h5py.is_hdf5(proc_h5):\n",
    "    print(f\"Not an HDF5 file: {proc_h5}\")\n",
    "else:\n",
    "    print(f\"Confirmed: {proc_h5} is an HDF5 file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='4'> <b>3.3 Run SBASInvert.py </b></font>\n",
    "<br>\n",
    "<font face='Calibri' size='3'> Actually do the time series. \n",
    " \n",
    "Inputs\n",
    "\n",
    "- HDF5 file, PROC-STACK.h5\n",
    "- data.xml\n",
    "- sbas.xml\n",
    "\n",
    "Outputs\n",
    "\n",
    "- HDF5 file: LS-PARAMS.h5\n",
    "\n",
    "<b>Display the help information for SBASInvert.py:</b>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python2.7 $giant_path/SBASInvert.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='3'><b>Run SBASInvert.py:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python2.7 $giant_path/SBASInvert.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face='Calibri'><font size='3'>SBASInvert.py creates a file called 'LS-PARAMS.h5'.\n",
    "<br><br>\n",
    "<b>Verify that LS-PARAMS.h5 is an HDF5 file as required by the rest of GIAnT:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_h5 = f\"{stack_path}/LS-PARAMS.h5\"\n",
    "if not h5py.is_hdf5(params_h5):\n",
    "    print(f\"Not an HDF5 file: {params_h5}\")\n",
    "else:\n",
    "    print(f\"Confirmed: {params_h5} is an HDF5 file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='4'> <b>3.4 Run SBASxval.py </b></font>\n",
    "<br>\n",
    "<font face='Calibri' size='3'> Get an uncertainty estimate for each pixel and epoch using a Jacknife test. We are skipping this function as we won't be doing anything with its output and it takes a significant amount of time to run relative to the other GIAnT functions.\n",
    " \n",
    "Inputs: \n",
    "\n",
    "- HDF5 files, PROC-STACK.h5\n",
    "- data.xml\n",
    "- sbas.xml\n",
    "\n",
    "Outputs:\n",
    "\n",
    "- HDF5 file, LS-xval.h5\n",
    "\n",
    "<br>\n",
    "<b>Display the help information for SBASxval.py:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python2.7 $giant_path/SBASxval.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='3'><b>Run SBASxval.py:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python2.7 $giant_path/SBASxval.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face='Calibri'><font size='3'>SBASxval.py  creates a file called 'LS-xval.h5'.\n",
    "<br><br>\n",
    "<b>Verify that LS-xval.h5 is an HDF5 file as required by the rest of GIAnT:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "xval_h5 = f\"{stack_path}/LS-xval.h5\"\n",
    "if not h5py.is_hdf5(xval_h5):\n",
    "    print(f\"Not an HDF5 file: {xval_h5}\")\n",
    "else:\n",
    "    print(f\"Confirmed: {xval_h5} is an HDF5 file.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='5'><b>4. Data Visualization</b></font>\n",
    "<br>\n",
    "<font face='Calibri' size='3'>Now we visualize the data. This is largely copied from Lab 4.\n",
    "<br><br>\n",
    "<b>Create a directory in which to store our plots and move into it:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir = f\"{path}/plots\"\n",
    "new_directory(plot_dir)\n",
    "if path_exists(plot_dir):\n",
    "    os.chdir(plot_dir)\n",
    "print(f\"Current Working Directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='3'><b>Load the stack produced by GIAnT and read it into an array so we can manipulate and display it:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(params_h5, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='3'><b>List all groups ('key's) within the HDF5 file that has been loaded into the object 'f'</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Keys: %s\" %f.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='3'>Details on what each of these keys means can be found in the GIAnT documentation. For now, the only keys with which we are concerned are <b>'recons'</b> (the filtered time series of each pixel) and <b>'dates'</b> (the dates of acquisition). It is important to note that the dates are given in a type of Julian Day number called Rata Die number. This will have to be converted later, but this can easily be done via one of several different methods in Python.</font>\n",
    "<br><br>\n",
    "<font face='Calibri' size='3'><b>Get our data from the stack:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cube = f['recons'].value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='3'><b>Get the dates for each raster from the stack:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = list(f['dates']) # these dates appear to be given in Rata Die style: floor(Julian Day Number - 1721424.5). \n",
    "if data_cube.shape[0] is not len(dates):\n",
    "    print('Problem:')\n",
    "    print('Number of rasters in data_cube: ',data_cube.shape[0])\n",
    "    print('Number of dates: ',len(dates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='3'><b>Plot and save amplitude image with transparency determined by alpha (SierraNegra-dBScaled-AmplitudeImage.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "radar_tiff = f\"{path}/20161119-20170106_amp.tiff\"\n",
    "radar = gdal.Open(radar_tiff)\n",
    "im_radar = radar.GetRasterBand(1).ReadAsArray()\n",
    "radar = None\n",
    "dbplot = np.log10(im_radar)\n",
    "vmin=np.percentile(dbplot,3)\n",
    "vmax=np.percentile(dbplot,97)\n",
    "fig = plt.figure(figsize=(18,10)) # Initialize figure with a size\n",
    "ax1 = fig.add_subplot(111) # 221 determines: 2 rows, 2 plots, first plot\n",
    "ax1.imshow(dbplot, cmap='gray',vmin=vmin,vmax=vmax,alpha=1);\n",
    "plt.title('Example dB-scaled SAR Image for Ifgrm 20161119-20170106')\n",
    "plt.grid()\n",
    "plt.savefig('SierraNegra-dBScaled-AmplitudeImage.png',dpi=200,transparent='false')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='3'><b>Display and save an overlay of the clipped deformation map and amplitude image (SierraNegra-DeformationComposite.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will define a short function that can plot an overaly of our radar image and deformation map. \n",
    "def defNradar_plot(deformation, radar):\n",
    "    fig = plt.figure(figsize=(18, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    vmin = np.percentile(radar, 3)\n",
    "    vmax = np.percentile(radar, 97)\n",
    "    ax.imshow(radar, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    fin_plot = ax.imshow(deformation, cmap='RdBu', vmin=-50.0, vmax=50.0, alpha=0.75)\n",
    "    fig.colorbar(fin_plot, fraction=0.24, pad=0.02)\n",
    "    ax.set(title=\"Integrated Defo [mm] Overlain on Clipped db-Scaled Amplitude Image\")\n",
    "    plt.grid()\n",
    "    \n",
    "# Get deformation map and radar image we wish to plot\n",
    "deformation = data_cube[data_cube.shape[0]-1]\n",
    "\n",
    "# Call function to plot an overlay of our deformation map and radar image.\n",
    "defNradar_plot(deformation, dbplot)\n",
    "plt.savefig('SierraNegra-DeformationComposite.png', dpi=200, transparent='false')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='3'><b>Convert from Rata Die number (similar to Julian Day number) contained in 'dates' to Gregorian date:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tindex = []\n",
    "for d in dates:\n",
    "    tindex.append(date.fromordinal(int(d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri' size='3'><b>Create an animation of the deformation</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.axis('off')\n",
    "vmin=np.percentile(data_cube.flatten(), 5)\n",
    "vmax=np.percentile(data_cube.flatten(), 95)\n",
    "\n",
    "\n",
    "im = ax.imshow(data_cube[0], cmap='RdBu', vmin=-50.0, vmax=50.0)\n",
    "ax.set_title(\"Animation of Deformation Time Series - Sierra Negra, Galapagos\")\n",
    "fig.colorbar(im)\n",
    "plt.grid()\n",
    "\n",
    "def animate(i):\n",
    "    ax.set_title(\"Date: {}\".format(tindex[i]))\n",
    "    im.set_data(data_cube[i])\n",
    "    \n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=data_cube.shape[0], interval=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Configure matplotlib's RC settings for the animation:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc('animation', embed_limit=10.0**9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create a javascript animation of the time-series running inline in the notebook:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Save the animation as a 'gif' file (SierraNegraDeformationTS.gif):</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.save('SierraNegraDeformationTS.gif', writer='pillow', fps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri'><font size='5'><b>5. Alter the time filter parameter</b></font><br>\n",
    "    <font size='3'>Looking at the animation above, you may notice that the deformation has a very smoothed appearance. This may be because of our time filter which is currently set to 1 year ('filt=1.0' in the prepxml_SBAS.py code). Try repeating this portion of the notebook with a couple different time filters. <br>\n",
    "First, use no time filter ('filt=0.0') and then use a 1 month time filter ('filt=0.082'). Change the output file name for anything you want saved (e.g., 'SierraNegraDeformationTS.gif' to 'YourDesiredFileName.gif'). Otherwise, it will be overwritten. <br><br>How did these changes affect the output time series?<br>How might we figure out the right filter length?<br>What does this say about the parameters we select?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='Calibri'><font size='5'><b>6. Clear data (optional)</b></font>\n",
    "    <br>\n",
    "    <font size='3'>This lab has produced a large quantity of data. If you look at this notebook in your home directory, it should now be ~13 MB. This can take a long time to load in a Jupyter Notebook. It may be useful to clear the cell outputs. <br>To clear the cell outputs, go Cell->All Output->Clear. This will clear the outputs of the Jupyter Notebook and restore it to its original size of ~60 kB. This will not delete any of the files we have created. </font>\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"2\"> <i>GEOS 657 Microwave Remote Sensing - Version 1.0 - Feb 2019 </i>\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
